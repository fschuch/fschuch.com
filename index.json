[{"authors":["admin"],"categories":null,"content":"Possuo experiência na aplicação e também no desenvolvimento de ferramentas computacionais capazes de resolver problemas complexos, além de realizar o processamento, visualização e comunicação dos dados produzidos por essas soluções. Tais ferramentas são frequentemente impulsionadas por Computação de Alto Desempenho (HPC).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"pt","lastmod":1751736705,"objectID":"fc75ec11b87c7747ea809e4f02264745","permalink":"https://www.fschuch.com/author/felipe-n.-schuch/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/felipe-n.-schuch/","section":"authors","summary":"Possuo experiência na aplicação e também no desenvolvimento de ferramentas computacionais capazes de resolver problemas complexos, além de realizar o processamento, visualização e comunicação dos dados produzidos por essas soluções. Tais ferramentas são frequentemente impulsionadas por Computação de Alto Desempenho (HPC).","tags":null,"title":"Felipe N. Schuch","type":"authors"},{"authors":["m.tessmann"],"categories":null,"content":"Doutorando em Economia de Empresas com ênfase em Finanças pela Universidade Católica de Brasília, Mestre em Economia Aplicada pelo Programa de Pós Graduação em Organizações e Mercados da Universidade Federal de Pelotas e Bacharel em Ciências Econômicas pela Universidade Federal de Pelotas. Atualmente é assessor acadêmico, pesquisador e professor no IDP. Além disso, é o criador e um dos líderes do grupo de pesquisa Economia Empírica, criador e editor do Boletim Economia Empírica (ISSN: 2675-3391) e coordenador executivo do Laboratório de Avaliação e Inovação em Políticas Públicas - LAIPP. Possui experiência como Presidente em Comitê de Investimentos de Fundo Previdenciário e tem como principais interesses: economia aplicada, finanças, mercado de capitais, commodities e análises de equilíbrio geral computável.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"pt","lastmod":1751736705,"objectID":"260f077808a01f09d192a848219db817","permalink":"https://www.fschuch.com/author/mathias-s.-tessmann/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mathias-s.-tessmann/","section":"authors","summary":"Doutorando em Economia de Empresas com ênfase em Finanças pela Universidade Católica de Brasília, Mestre em Economia Aplicada pelo Programa de Pós Graduação em Organizações e Mercados da Universidade Federal de Pelotas e Bacharel em Ciências Econômicas pela Universidade Federal de Pelotas.","tags":null,"title":"Mathias S. Tessmann","type":"authors"},{"authors":null,"categories":null,"content":"","date":1693612800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"e2beb24a95b78eb9b0f7d9ce681e1fd9","permalink":"https://www.fschuch.com/project/figure-scale/","publishdate":"2023-09-02T00:00:00Z","relpermalink":"/project/figure-scale/","section":"project","summary":"Pacote Python projetado para ajudar você a criar figuras de qualidade de publicação com controle preciso de tamanho no Matplotlib","tags":["Python"],"title":"Figure Scale","type":"project"},{"authors":null,"categories":null,"content":"","date":1693612800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"7324a080115c4993705a1cd6d373f1d2","permalink":"https://www.fschuch.com/project/wizard-template/","publishdate":"2023-09-02T00:00:00Z","relpermalink":"/project/wizard-template/","section":"project","summary":"Um template de propósito geral que visa fornecer um início mágico para qualquer projeto Python","tags":["Python"],"title":"Wizard Template","type":"project"},{"authors":["A.E. Giannenas","N. Bempedelis","Felipe N. Schuch","S. Laizet"],"categories":null,"content":"","date":1662336e3,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"2abfab1f43e0c23dfdf86a49ae6ee75a","permalink":"https://www.fschuch.com/publication/2022-flow-turbulence-and-combustion/","publishdate":"2022-09-05T00:00:00Z","relpermalink":"/publication/2022-flow-turbulence-and-combustion/","section":"publication","summary":"The aim of the present numerical study is to show that the recently developed Alternating Direction Reconstruction Immersed Boundary Method (ADR-IBM) (Giannenas and Laizet in Appl Math Model 99:606–627, 2021) can be used for Fluid–Structure Interaction (FSI) problems and can be combined with an Actuator Line Model (ALM) and a Computer-Aided Design (CAD) interface for high-fidelity simulations of fluid flow problems with rotors and geometrically complex immersed objects. The method relies on 1D cubic spline interpolations to reconstruct an artificial flow field inside the immersed object while imposing the appropriate boundary conditions on the boundaries of the object. The new capabilities of the method are demonstrated with the following flow configurations: a turbulent channel flow with the wall modelled as an immersed boundary, Vortex Induced Vibrations (VIVs) of one-degree-of-freedom (2D) and two-degree-of-freedom (3D) cylinders, a helicopter rotor and a multi-rotor unmanned aerial vehicle in hover and forward motion. These simulations are performed with the high-order fluid flow solver Incompact3d which is based on a 2D domain decomposition in order to exploit modern CPU-based supercomputers. It is shown that the ADR-IBM can be used for the study of FSI problems and for high-fidelity simulations of incompressible turbulent flows around moving complex objects with rotors.","tags":["Xcompact3d"],"title":"A Cartesian Immersed Boundary Method Based on 1D Flow Reconstructions for High-Fidelity Simulations of Incompressible Turbulent Flows Around Moving Objects","type":"publication"},{"authors":null,"categories":null,"content":"","date":1634493600,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"b5405096fe7f0f42fd89902de51c2fa7","permalink":"https://www.fschuch.com/talk/acelerando-a-exploracao-de-dados-multidimensionais-com-xarray/","publishdate":"2021-10-17T15:00:00-03:00","relpermalink":"/talk/acelerando-a-exploracao-de-dados-multidimensionais-com-xarray/","section":"event","summary":"Tutorial introdutório para *Xarray*, um pacote Python de código aberto que é capaz de tornar o trabalho com arranjos de dados multidimensionais e catalogados uma tarefa simples e eficiente. Destaca-se a sua sinergia com outras ferramentas para I/O, plotagem interativa e computação paralela.","tags":["Python","Xarray","Matplotlib"],"title":"Acelerando a exploração de dados multidimensionais com Xarray","type":"event"},{"authors":["Felipe N. Schuch","E. Meiburg","J.H. Silvestrini"],"categories":null,"content":"","date":1625529600,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"e4fc0d6b4cd54f7eb9308f3227dcb4ff","permalink":"https://www.fschuch.com/publication/2021-computers-and-geosciences/","publishdate":"2021-07-06T00:00:00Z","relpermalink":"/publication/2021-computers-and-geosciences/","section":"publication","summary":"Hyperpycnal flows are observed when the density of a fluid entering into a quiescent environment is greater than that of the ambient fluid.\tThis difference can be due to salinity, temperature, concentration, turbidity, or a combination of them. Over a sloping bottom, the inflowing momentum decreases progressively until a critical stage is reached where the inflow plunges underneath the ambient and flows adjacent to the bed as an underflow density current. In the present work, a new equation is proposed in order to predict the critical depth for plunging, i.e., the plunging criterion. It differs from previous studies since it includes the role of the settling velocity and the bed slope. The high spatiotemporal resolution from twelve original numerical simulations allows us to validate the initial hypotheses established, in addition to numerical and experimental data available in the literature, and good agreement is found between them. A negative value for the mixing coefficient was observed for the first time for the hyperpycnal flow in a tilted channel. This indicates that if the settling velocity of the suspended material is high enough, the submerged flow may lose fluid to the environment (detrainment), instead of incorporating it. The proposed plunging criterion may assist in the design of future experimental or numerical works.","tags":["Plunging Flow","Xcompact3d"],"title":"Plunging condition for particle-laden flows over sloping bottoms: three-dimensional turbulence-resolving simulations","type":"publication"},{"authors":null,"categories":null,"content":"Esta palestra tem por objetivo introduzir os principais conceitos de programação e Python, empregando a didática interativa da plataforma Jupyter Notebook. Além disso, demonstra-se como solucionar problemas em métodos numéricos por meio de propostas computacionais. Para tanto, o material é dividido em duas aulas:\n  Ligeira Introdução à Python, contemplando:\n Introdução e revisão sobre conceitos de programação em Python; Manipulação de tensores em Python com Numpy; Produção de gráficos com o pacote Matplotlib; Cálculo Diferencial e Integral com Python; Resolvendo Equações Diferenciais;    Exemplos de aplicação em Fenômenos de Transporte (próxima semana).\n  Configurando o Tutorial Esse tutorial foi projetado para rodar no Binder. O serviço permite executar totalmente na nuvem, nenhuma instalação extra é necessária. Para tanto, basta clicar aqui: \nSe você prefere instalar o tutorial localmente, siga os seguintes passos:\n  Clone o repositório:\ngit clone https://github.com/fschuch/metodos-numericos-com-python    Instale o ambiente. O repositório inclui um arquivo environment.yaml que contém uma lista de todos os pacotes necessários para executar esse tutorial. Para instalá-los usando conda, use o comando:\nconda env create -f environment.yml conda activate metodos-numericos-python    Inicie uma seção Jupyter:\njupyter lab    ","date":1620153e3,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"3e3458473ff7f5c0476c578df4a76796","permalink":"https://www.fschuch.com/talk/metodos-numericos-em-python/","publishdate":"2021-05-04T09:00:00-03:00","relpermalink":"/talk/metodos-numericos-em-python/","section":"event","summary":"Aula como professor convidado, ministrada para as turmas de Métodos Numéricos e Turbulência do Programa de Pós-Graduação em Recursos Hídricos e Saneamento Ambiental do Instituto de Pesquisas Hidraulicas da Universidade Federal do Rio Grande do Sul.","tags":["Python","Métodos Numéricos","Matplotlib","NumPy","SciPy"],"title":"Métodos Numéricos em Python","type":"event"},{"authors":null,"categories":null,"content":"","date":1616159700,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"b14bc3f4dda76d62da56e7f29cf5f9ca","permalink":"https://www.fschuch.com/talk/python-and-xcompact3d/","publishdate":"2021-03-19T12:00:00-03:00","relpermalink":"/talk/python-and-xcompact3d/","section":"event","summary":"Palestra para o encontro anual da equipe de desenvolvimento do XCompact3d. Apresentando os avanços na integração do solver de Navier-Stokes com Python, para uma interface mais amigável com os usuários por meio do pacote Python *Xcompact3d Toolbox*, além dos planos futuros para embalar o código fonte em Fortan do XCompact3d com uma interface Python, aumentando a sinergia e facilidade para manutenção de ambas as ferramentas.","tags":["CFD","HPC","Python","Xcompact3d"],"title":"Python and XCompact3d","type":"event"},{"authors":null,"categories":null,"content":"Lista de Conteúdos  Introdução Metodologia  Normalizar Inspecionar Testar Obter Lista de Palavras Extrair Opções Válidas   Resultados Conclusão    Introdução Solucionar problemas é uma questão de prática. É claro que livros, cursos e vídeos são ótimos materiais complementares para melhorar a sua técnica, mas não há como realmente fixar o conhecimento se você não colocar a mão na massa. Mas mesmo compreendendo que devemos praticar, as vezes nos deparamos com outro ponto: Que problema vou resolver para praticar? Temos que prestar atenção, porque os problemas aparecem por todos os lados, e cada problema resolvido nos torna programadores melhores.\nCom isso surge esse desafio que eu propus lá no Intagram @aprenda.py: Você consegue programar uma solução em Python que encontre uma palavra na língua portuguesa que seja um anagrama para eugenie gut zaza?\nMas primeiro, vamos à definição do problema: Anagrama é um tipo de jogo de palavras, onde a reorganização das letras de uma palavra ou expressão resulta na obtenção de outras palavras ou expressões. Temos por exemplo Iracema e América, ou então Ator e Rota:\ngraph LR subgraph Rota R1(R) --- O1(O) --- T1(T) --- A1(A) end subgraph Ator A2(A) --- T2(T) --- O2(O) --- R2(R) end A2 -.-\u0026gt; A1 T2 -.-\u0026gt; T1 O2 -.-\u0026gt; O1 R2 -.-\u0026gt; R1  Agora que sabemos o que são anagramas, vamos ao próximo ponto, como é que encontramos eles para resolvermos a questão proposta? A prática em resolução de problemas mostra que o ideal é começarmos estabelecendo um passo a passo, dividindo o problema em parcelas menores, a assim termos uma ideia clara sobre como prosseguir até o objetivo, vejamos:\n Devemos procurar uma maneira de normalizar as palavras ou expressões com as quais estamos trabalhando, para facilitar a comparação entre elas. Podemos listar as seguintes operações:  Normalizar acentos e caracteres especiais; Remover espaços em branco; Transformar caracteres que porventura esteja em caixa alta, para caixa baixa;   Então, temos que inspecionar uma palavra ou expressão, e para caracteriza-las, obtendo uma listagem das letras e da sua contagem; Com isso, definimos um método para efetivamente testar se duas palavras ou expressões são anagramas entre si; Precisamos obter uma lista de palavras válidas na língua portuguesa para testar contra a nossa referência; Por fim, precisamos extrair dessa lista todas as palavras que satisfazem o problema.  Já sabemos como proceder, agora, te convido a praticar e tentar resolver o problema. Mas de qualquer maneira, a seguir temos a solução completa e comentada.\n Metodologia Como passo inicial, pode ser necessário instalar algumas das bibliotecas Python que vamos utilizar. Duas delas merecem destaque, beautifulsoup4 é uma ferramenta para Web Scraping, com ela vamos obter as palavras válidas de um site de terceiros, e unidecode será útil para a normalização das variáveis tipo str que usaremos nessa solução. Ambos pacotes podem ser instalados com a seguinte linha de comando:\npip install beautifulsoup4 Unidecode  Agora partimos para nossa aplicação Python própriamente dita, começamos com as importações:\nimport os.path import time from collections import Counter import requests from bs4 import BeautifulSoup from unidecode import unidecode  Normalizar Nós podemos deixar nossa solução mais robusta ao trabalhar com texto, se definirmos uma maneira de normalizar as palavras com as quais vamos lidar. Com unidecode, vamos remover acentos e caracteres especiais, por exemplo, ç será transformado em c, ã será simplesmente a, e assim por diante. A operação seguinte é remover os espaços, para isso, temos o método replace() das strings, que irá substituir cada espaço \u0026quot; \u0026quot; por um caractere vazio \u0026quot;\u0026quot;. Por fim, o método lower() converte todos os caracteres para caixa baixa, garantindo que nossa aplicação não seja sensível quanto à presença de letras maiúsculas e minúsculas. Tudo isso é feito com a seguinte função:\ndef normalizar_palavra(palavra: str) -\u0026gt; str: return unidecode(palavra).replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;).lower()  Vamos testar nossa normalização com a frase:\nnormalizar_palavra(\u0026quot;Canção da América\u0026quot;)   'cancaodaamerica'  Inspecionar Segundo passo, definimos como inspecionar a tarefa de obter um conjunto com as letras únicas que constituem uma palavra ou expressão, bem como a contagem de aparições de cada letra. Quando falamos em conjuntos de chave (cada caractere que compõem a palavra) e valor (o número de ocorrências), é natural pensar na utilização de um dicionário Python. Mas podemos ir um passo além se lembrarmos que Python tem embutido o módulo collections, com estruturas de dados especializadas em certas tarefas, e o dicionário com contagem é uma dessas estruturas, chama-se Counter. Com essa classe especializada, veremos que podemos resolver o problema com menos linhas de código, melhor legibilidade, e menos propensão a erros. O que definimos como inspecionar será obtido ao enviar uma palavra de entrada normalizada para o estrutura Counter, o código é como segue:\ndef inspecionar_palavra(palavra: str) -\u0026gt; Counter: return Counter(normalizar_palavra(palavra))  Hora de testar a nossa implementação:\ninspecionar_palavra(\u0026quot;Aprenda Python\u0026quot;)  Counter({'a': 2, 'p': 2, 'r': 1, 'e': 1, 'n': 2, 'd': 1, 'y': 1, 't': 1, 'h': 1, 'o': 1})  inspecionar_palavra(\u0026quot;eugenie gut zaza\u0026quot;)  Counter({'e': 3, 'u': 2, 'g': 2, 'n': 1, 'i': 1, 't': 1, 'z': 2, 'a': 2})  Testar Terceiro passo, dadas duas palavras ou expressões, devemos testar se são anagramas (retornando True) ou não (retornando False). Estabelecemos três critérios para isso:\n Ambas entradas devem ter o mesmo número total de letras únicas, que pode ser testado por meio da função len(); Sendo satisfeito o critério anterior, ambas entradas devem ser constituídas pelo mesmo conjunto de letras únicas. Como esses valores estão armazenados como as chaves do nosso dicionário, obtemos eles com o método keys(); Então, comparamos que a contagem de cada uma das letras é igual entre as duas entradas. Como a contagem é armazenada nos valores dos dicionários, obtemos com o método values().  Se as três condições acima forem satisfeitas, teremos um resultado positivo para anagrama. Acontece que estamos utilizando a estrutura especializada Counter, e aqui vemos as vantagens de estudar e conhecer as peculiaridades dos módulos embutidos em Python. Realizamos os três testes ao comparar se ambos contadores são iguais, todo o resto já está implementado na classe Counter. Veja como fica o código:\ndef testa_se_anagrama(inspecionada_1: Counter, inspecionada_2: Counter) -\u0026gt; bool: return inspecionada_1 == inspecionada_2  Vamos testar com três exemplos:\ntesta_se_anagrama( inspecionar_palavra(\u0026quot;Roma\u0026quot;), inspecionar_palavra(\u0026quot;amor\u0026quot;), )  True  testa_se_anagrama( inspecionar_palavra(\u0026quot;Iracema\u0026quot;), inspecionar_palavra(\u0026quot;América\u0026quot;), )  True  testa_se_anagrama( inspecionar_palavra(\u0026quot;Python\u0026quot;), inspecionar_palavra(\u0026quot;Fortran\u0026quot;), )  False  Note que a operação inspecionar_palavra poderia ter sido executada dentro de testa_se_anagrama, mas minha opção foi por não fazê-lo. Como nosso problema proposto envolve testar uma mesma palavra de referência contra uma lista de outras opções, podemos inspecionar a palavra de referências apenas umas vez e aproveitar esse valor nas demais comparações. Veremos mais detalhes sobre isso nos próximos tópicos.\nObter Lista de Palavras Quarto passo, temos que obter uma lista de palavras válidas na qual vamos buscar por anagramas. Aqui existe uma série de caminhos para serem seguidos, e algumas decisões a serem tomadas, dependendo das características do problema. Certamente, podemos começar recorrendo a uma ferramenta de busca sobre como conseguir uma lista de palavras na língua portuguesa dentro de nossa aplicação Python, mas devo dizer que não encontrei nada satisfatório em termos de custo (o tempo que eu levaria para implementar a solução) e benefício (solucionar o problema sem acrescentar demasiada complexidade).\nEm um segundo momento, procurei por sites com dicionários online, e foi aí que encontrei dicio.com.br. Vi dois pontos fortes no site, eu poderia pesquisar por palavras que começam com uma certa letra, além de poder restringir a busca para o número de letras na palavra. Veja que para o problema que queremos resolver, estamos procurando por palavras que comecem com a, e, g, i, n, t, u e z, para um total de 14 letras, e isso reduz drasticamente a nossa busca pela resposta.\nEntão veio a primeira opção do design da solução, eu pude visitar as 8 páginas do site, uma para cada letra, copiar e colar as listas de palavras e ter rapidamente um protótipo que de fato resolveu o problema. Obtive uma lista com 2010 palavras, e, felizmente, a solução estava entre elas. Em seguida eu pensei, essa é uma chance para mim praticar algo novo, como eu posso automatizar esse processo?\nE aqui entre o Web Scraping com o pacote beautifulsoup4, podemos vasculhar o site automaticamente em busca da informação que precisamos. Começamos requisitando a página para nossa aplicação, por exemplo, começando com a letra z:\npage = requests.get(\u0026quot;https://www.dicio.com.br/palavras-comecam-z-com-14-letras/\u0026quot;)  Em seguida, podemos analisar mais detalhadamente os elementos da página com:\nsoup = BeautifulSoup(page.content, \u0026quot;html.parser\u0026quot;)  E é uma verdadeira sopa de letrinhas, você pode imprimir na tela para testar com print(soup), mas o código é muito grande, não ficaria bem no blog, assim preferi não inclui-lo. Dentro de todo esse código HTML, precisamos encontrar o trecho de informação que nos interessa, e esse é um trabalho bem específico, pois cada site ou página tem sua própria estrutura e tags HTML. Então, por pura especificidade do site que estamos usando como referência, encontrei o que procuramos com na localidade soup.find_all(\u0026quot;p\u0026quot;)[1], além de encadear o retorno com get_text() como remover todas as tags e aumentar a legibilidade, strip() para remover espaçamentos extras e split() para quebrar o texto nos espaçamentos, a assim obtemos uma listagem das palavras válidas. Veja o exemplo:\nsoup.find_all(\u0026quot;p\u0026quot;)[1].get_text(separator=\u0026quot; \u0026quot;).strip().split()  ['ziguezagueante', 'zooterapêutica', 'zeugobrânquios', 'zooterapêutico', 'zoofitantráceo', 'zigomatolabial', 'zoocorográfico', 'zooiatrológico', 'zoologicamente']  O exemplo com a letra z funcionou satisfatoriamente, agora é hora de construírmos uma função que retorne para qualquer letra inicial, além do número de letras desejado na palavra. Mas antes de irmos ao código, vejamos algumas boas práticas sobre Web Scraping, lembre-se que estamos consumindo informações do servidor de um terceiro, e não queremos ser rudes e sobrecarregar o serviço. Então uma das ações do nosso código é sempre salvar para o nosso disco local as listas de palavras para uma dada letra inicial e números de palavras, assim, se solicitarmos a mesma lista, não precisamos de um novo acesso ao site externo, podemos simplesmente carregar nossa cópia local. Um outro cuidado foi implementar um intervalo de 2 segundos entre solicitações, para evitarmos qualquer problema com sobrecarga. Por fim, vale lembrar que esse método é restrito às características construtivas da URL e do código HTML, e vai parar de funcionar caso algum desses itens seja alterado pelos desenvolvedores do site. Por isso, sempre que possível, verifique se o serviço oferece alguma API para acesso, o que tende a ser mais robusto tanto para quem envia às informações, quanto para quem às consome.\nNota: O site que estamos usando para obter palavras válidas (dicio.com.br) limita o retorno em mil ocorrências para cada letra inicial, significando que nossa solução não cobrirá necessariamente todas as possibilidades da língua portuguesa, mas ainda assim, acho bastante satisfatório para esse estudo de caso.\nFinalmente veja como ficou nossa função:\ndef obtem_as_palavras_possiveis(primeira_letra: str, numero_de_letras: int) -\u0026gt; list: def verifica_se_arquivo_existe(nome_do_arquivo: str) -\u0026gt; bool: return os.path.isfile(nome_do_arquivo) def leia_o_arquivo(nome_do_arquivo: str) -\u0026gt; str: with open(nome_do_arquivo, \u0026quot;r\u0026quot;) as file_in: texto = file_in.read() return texto def escreva_o_arquivo(nome_do_arquivo: str, conteudo: str) -\u0026gt; None: with open(nome_do_arquivo, \u0026quot;w\u0026quot;) as file_out: file_out.write(conteudo) palavras_alvo = f\u0026quot;palavras-comecam-{primeira_letra}-com-{numero_de_letras}-letras\u0026quot; arquivo_backup = palavras_alvo + \u0026quot;.txt\u0026quot; # Se o arquivo existe, carregue do disco if verifica_se_arquivo_existe(arquivo_backup): lista_de_palavras = leia_o_arquivo(arquivo_backup) # Senão, obtenha as palavras e salve o arquivo para o disco # para que possa ser utilizado da próxima vez else: page = requests.get(f\u0026quot;https://www.dicio.com.br/{palavras_alvo}/\u0026quot;) soup = BeautifulSoup(page.content, \u0026quot;html.parser\u0026quot;) lista_de_palavras = soup.find_all(\u0026quot;p\u0026quot;)[1].get_text(separator=\u0026quot; \u0026quot;).strip() escreva_o_arquivo(arquivo_backup, lista_de_palavras) time.sleep(2) return map(normalizar_palavra, lista_de_palavras.split())  Um teste de funcionalidade:\nlist(obtem_as_palavras_possiveis(\u0026quot;z\u0026quot;, 14))  ['ziguezagueante', 'zooterapeutica', 'zeugobranquios', 'zooterapeutico', 'zoofitantraceo', 'zigomatolabial', 'zoocorografico', 'zooiatrologico', 'zoologicamente']  Extrair Opções Válidas Chegamos ao último passo que estabelecemos para a resolução do nosso problema, dada uma lista contendo inúmeras palavras, devemos encontrar aquelas que são anagramas de uma certa palavra ou expressão de referência. Isso envolve ainda alguns sub-passos utilizando todas as funções que construímos anteriormente:\n Dada uma palavra_referencia, realizamos a inspessão e armazenamos essa informação; Precisamos obter as listas de possibilidades válidas, mas lembre-se que podemos limitar o conjunto onde procuramos pela solução se lembrarmos que:  Usamos apenas aquelas que comecem com alguma letra que realmente faça parte de palavra_referencia; E apenas para aquelas que tenham o mesmo número de caracteres (descontando espaços) que palavra_referencia;   Por fim, dados todos os elementos em lista_possibilidades, precisamos filtrar aqueles elementos que sejam anagramas de palavra_referencia, a para tanto, usamos a função Python filter. Note que filter retorna um iterável, então o transformamos para uma lista para a visualização completa da resposta.  Vamos ao código:\ndef procurar_anagrama(palavra_referencia: str) -\u0026gt; list: def compara_contra_alvo(palavra_alvo: str) -\u0026gt; bool: return testa_se_anagrama( referencia_inspecionada, inspecionar_palavra(palavra_alvo), ) referencia_inspecionada = inspecionar_palavra(palavra_referencia) letras_na_referencia = referencia_inspecionada.keys() len_referencia = sum(referencia_inspecionada.values()) lista_possibilidades = [] for letra in letras_na_referencia: lista_possibilidades.extend(obtem_as_palavras_possiveis(letra, len_referencia)) print(f\u0026quot;Testando anagrama contra {len(lista_possibilidades)} possibilidades\u0026quot;) return list(filter(compara_contra_alvo, lista_possibilidades))   Resultados Chegamos ao momento tão aguardado. Após programar uma função para cada passo que estabelecemos para resolver o problema, é hora de conferir a solução. Sem mais delongas, vamos à ela:\nprocurar_anagrama(\u0026quot;eugenie gut zaza\u0026quot;)  Testando anagrama contra 2010 possibilidades ['ziguezagueante']  Legal, não? ziguezagueante é a nossa resposta, você conseguiu achar essa solução na sua própria implementação?\nMas depois de tantas linhas de código, não vamos nos ater somente a isso, vamos ver três testes extras:\nprocurar_anagrama(\u0026quot;Roma\u0026quot;)  Testando anagrama contra 632 possibilidades ['amor', 'mora', 'moar', 'maro', 'ramo', 'roma']  procurar_anagrama(\u0026quot;Aprenda\u0026quot;)  Testando anagrama contra 5078 possibilidades ['pernada', 'pandear']  procurar_anagrama(\u0026quot;Python\u0026quot;)  Testando anagrama contra 1005 possibilidades []  Conclusão Incrível como o que parecia uma proposta que parecia não ser tão complicada pode nos proporcionar em termos de aprendizado quando nos comprometemos à resolver o problema. E esse conhecimento acumulado vai sem dúvida contribuir para as próximas soluções que precisarmos resolver no futuro. Mesmo já trabalhando com Python por algum tempo, encontrei nesse exercício a chance de praticar alguns conceitos de design de código de uns livros que tenho lido recentemente, além de usar estruturas especializadas como o Counter, bem como foi a primeira vez que usei web scraping em um projeto real.\n","date":1615852800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"b88988670a7cf17c2c3f7d55013b27b3","permalink":"https://www.fschuch.com/blog/2021/03/16/desafio-de-programacao-encontre-o-anagrama/","publishdate":"2021-03-16T00:00:00Z","relpermalink":"/blog/2021/03/16/desafio-de-programacao-encontre-o-anagrama/","section":"post","summary":"Mais um desafio de programação. Temos a tarefa de encontrar um anagrama dentre as palavras da língua portuguesa, e claro, aprender muitos conceitos de programação em Python enquanto resolvemos o problema.","tags":["Desafio","Web Scraping","Python","Collections"],"title":"Desafio de Programação: Encontre o Anagrama","type":"post"},{"authors":null,"categories":null,"content":"XCompact3d é uma ferramenta acadêmica de alta precisão, voltado para a resolução de problemas em fluidodinâmica computacional (CFD), incluindo capacidade para resolver transporte de calor e/ou massa, bem como escoamentos ao redor de obstáculos. Ele é programado em Fortran, com código aberto, e projetado para rodar em super-computadores por meio da interface por troca de mensagens (MPI).\nA pesquisa na fronteira do conhecimento geralmente envolve extender as capacidades do código original, visando simular configurações de escoamento inéditas. Com isso, se faz necessário editar diretamente o código fonte, e todas as tarefas derivadas desse ato, como compilar o código, testar, corrigir possiveis falhas, executar e talvez repetir o ciclo. Essa atividade demanda conhecimentos especializados e tempo de deselvolvimento. Nesse contexto surge a motivação para esse trabalho:\n Como podemos acelerar o trabalho de desenvolvimentos de casos inéditos em nosso código? E também, como podemos acelerar o processo de aprendizagem para os que estão começando a estudar o código, ou mesmo tornar ele acessível para estudantes de CFD?  A solução para ambos os problemas acima foi proposta, confira mais detalhes abaixo:\n Veja a palestra no YouTube; Veja os Slides Online; Por fim, alguns exemplos da ferramenta que desenvolvemos.  ","date":1615564500,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"b899e4b39c7ca7682b1f9524b9ee2e4e","permalink":"https://www.fschuch.com/talk/sandbox-flow-configuration-a-rapid-prototyping-tool-inside-xcompact3d/","publishdate":"2021-03-09T15:00:00-03:00","relpermalink":"/talk/sandbox-flow-configuration-a-rapid-prototyping-tool-inside-xcompact3d/","section":"event","summary":"Uma ferramenta de prototipagem rápida incorporada ao XCompact3d, um código acadêmico para fluidodinâmica computacional. Isso visa aumentar a capacidade de trabalho dos desenvolvedores do código, ao mesmo tempo em que cria um ambiente mais amigável para estudantes em CDF.","tags":["CFD","HPC","Python","STEM","Xcompact3d"],"title":"Sandbox flow configuration: A rapid prototyping tool inside XCompact3d","type":"event"},{"authors":null,"categories":null,"content":"Lista de Conteúdos  Introdução O que é um Jupyter Notebook?  Formas de Acessar/Compartilhar   Conceitos Pedagógicos Curva de Progressão  Nível Inicial Nível Intermediário Nível Avançado   Leitura Recomendada Exemplos Conclusão    Introdução O ambiente Jupyter Notebook vem se consolidando como principal ferramenta de trabalho em Ciência de Dados, Aprendizado de Máquina e Inteligência Artificial. Muitas das características que o tornam tão popular nessas áreas também o colocam em uma posição de destaque para o campo educacional. As opções mais intuitivas seriam no ensino de engenharia ou ciência exatas em geral, mas não se engane, qualquer atividade que envolva o trabalho com dados pode se beneficiar, incluindo as ciências da saúde e as ciências humanas.\nEsse post apresenta uma contextualização sobre o Projeto Jupyter, uma explanação sobre a utilidade da ferramenta no cenário pedagógico, além da exemplificação de como se pode avançar progressivamente ao combinar Jupyter com diversas outras ferramentas do universo Python, para tornar a experiência mais agradável tanto para docentes quanto para estudantes. Ao final, apresenta-se a leitura recomendada e exemplos de aplicação.\n Essa própria postagem foi produzida a partir de um Jupyter Notebook, assim como muitas outras nesse blog, mostrando a flexibilidade da ferramenta para a produção de conteúdo em geral.    O que é um Jupyter Notebook? O Projeto Jupyter foi fundado em 2015, sendo uma organização sem fins lucrativos que visa desenvolver software aberto e serviços para computação interativa. A denominação do projeto é uma referências às três principais linguagens de programação suportadas por ele, Julia, Python e R (veja todas as linguagens suportadas aqui), e também uma homenagem aos cadernos onde Galileu Galilei tomava nota de suas descobertas sobre as luas de Júpiter.\nO Jupyter Notebook é uma das peças do projeto, compreendendo o software no qual se pode criar os cadernos de anotações Jupyter (Jupyter notebooks), que por sua vez são constituídos por um ambiente de programação que mistura blocos de código executável, visualizações e texto enriquecido com equações, figuras, animações, tabelas, links que redirecionem para recursos externos, títulos e subtítulos, listas e muitos outros recursos. Essa flexibilidade permite ao usuário unir código, dados e narrativa, para construir uma verdadeira história computacional e interativa. É possível executar o código, ver o que acontece, modificar e repetir, onde o usuário tem uma conversa com os dados que está analisando. Veja o exemplo a seguir:\n  Exemplo de um Jupyter Notebook, começando por um bloco de texto em markdown contendo um título, explicações e uma equação renderizada com LaTeX. Três blocos de código produzem o gráfico final. Fonte: Adaptado de L.A. Barba et al. (2019).  Além disso, Jupyter é uma ferramenta grátis e de código aberto. Está disponível para os principais sistemas operacionais do mercado e também por serviços remotos na nuvem, onde apenas o acesso a um navegador de internet é o suficiente para utilizar a ferramenta. Esse é um ponto importante frente à outras alternativas de software proprietário, que os alunos muitas vezes sequer conseguem ter acesso fora das instituições de ensino.\nFormas de Acessar/Compartilhar A maneira mais simples de testar o Jupyter é por meio Colaboratory, ou simplesmente Colab, um serviço Google que permite a criação, colaboração e compartilhamento de Notebooks inteiramente na nuvem.\nOutra opção é o Binder, serviço na nuvem que permite construir ambientes personalizados e lançar um servidor Jupyter na nuvem a partir de um repositório do GitHub. Além disso, o site apresenta um tutorial de como utilizar o Jupyter em Julia, Python e R.\nPara instalação local em sua máquina, o Jupyter já acompanha as principais instalações do Anaconda, um gerenciador de pacotes Python. Caso já tenha Anaconda instalado mas não o Jupyter, basta utilizar o comando:\nconda install -c conda-forge jupyterlab  Outra possibilidade é o gerenciar de pacotes Python pip, com o comando:\npip install jupyterlab  Por fim, o JupyterHub disponibiliza o poder de Jupyter para um grupo de usuários (estudantes de um curso ou um grupo de pesquisa, por exemplo), gerenciando ambientes virtuais e recursos computacionais.\nOs Jupyter notebooks podem ser exportados em diversos formatos, dependendo do meio onde serão distribuídos. O arquivo .ipynb é o notebook em sua essência, possibilitando aos demais executar e interagir com o seu conteúdo. É possível exportar como PDF, para impressão e compartilhamento, Markdown ou HTML para visualização web (como esse post), LaTeX para inclusão em material técnico/científico e até mesmo para apresentação de slides.\nConceitos Pedagógicos Como vimos anteriormente, a mistura entre blocos de código executáveis e blocos de texto enriquecido permitem ao Jupyter e seus usuários algo como combinar as explicações tradicionalmente encontrada nos livros com a interatividade de um aplicativo web. E com isso, Jupyter pode ter seu papel de destaque também como ferramenta educacional. Por ser tão flexível, se enquadra não apenas em áreas do conhecimento onde a programação é um objetivo final, mas também em áreas onde a programação se apresenta como um meio para analisar e resolver problemas.\nA aplicação de Jupyter no ensino pode se dar nos mais diversos formatos, a depender das necessidades do curso, e do conforto/interesse do instrutor para elaborar o material. Jupyter pode compreender apenas parte de uma aula, ou um curso inteiro. Pode ser utilizado para produzir a apostila que o turma deverá seguir durante o curso, o material de apoio, leitura complementar, listas de exercícios, exercícios resolvidos ou o gabarito de atividades avaliativas. Pode ser apresentado e encorajado como um formato no qual os alunos possam realizar e entregar o dever de casa e atividades avaliativas. Podem ser exibidos durante uma aula demonstrativa, presencial ou online, ou convidar os alunos a interagir com o conteúdo durante uma aula prática em laboratório. O objetivo é instigar o aprendizado ativo, aumentando o engajamento, participação, entendimento, desempenho e a preparação para a carreira futura dos alunos. É exercitada a criatividade, raciocínio lógico, capacidade de resolver problemas, comunicação e outras habilidades que são indispensáveis para qualquer área de atuação.\nCurva de Progressão Esta seção apresenta uma descrição (não exaustiva) da curva de aprendizado para alunos e instrutores, exemplificada com programação em Python e suas principais bibliotecas de uso geral.\nMas antes de começar, vale mencionar que o nível zero é dominar as denominadas células Markdown, para texto enriquecido. Nelas, é possível inserir equações com sintaxe $\\LaTeX$:\n$$E = mc^2,$$\ntítulos e subtítulos, texto em destaque e itálico. Temos também listas:\n Item 1 Item 2 Item 3  Citações:\n Considere usar Jupyter na sua instituição de ensino (2021, F. N. Schuch).\n Além de código com destaque de sintaxe, lista de tarefas, tabelas, figuras, vídeos, links e muito mais (veja mais detalhes aqui).\nNível Inicial Uma vez que sabemos como adicionar blocos explicativos detalhados, o próximo passo é trabalhar com blocos de código. Vamos tomar como exemplo o caso do movimento uniformemente variável, onde a posição de um dado objeto no espaço em função do tempo é dado pela seguinte equação:\n$$ S(t) = S_0 + v_0t + \\dfrac{at^2}{2}, $$\nonde $S$ é a posição, $S_0$ a posição inicial, $v_0$ é a velocidade inicial, $a$ a aceleração e $t$ o tempo.\nDigamos que a aula não seja de programação, mas mesmo assim, a turma pode ser convidada a interagir com o problema e testar diferentes respostas ao alterar os parâmetros quando o seguinte bloco de código é fornecido:\n# Atribuímos os parâmetros do problema S0 = 0 v0 = 10 a = -1 t = 10 # A equação que descreve o problema S = S0 + v0 * t + (a * t ** 2) / 2 # Por fim, exibimos a resposta print(S)  50.0  Essa situação pode se aplicar nas mais diversas disciplinas que envolvam algum tipo de cálculo, análise de dados e/ou tomada de decisão. Ou dependendo do objetivo do material, o bloco de código pode estar em vazio, servindo como um convite para que a turma resolva o problema por meio de ferramentas computacionais com uma barreira de entrada mínima.\nNível Intermediário Como próximo passo, pode-se incluir mais aspectos de lógica de programação, como: laços, testes lógicos, entrada e saída de arquivos, funções, controle de erros e exceções e a manipulação de estruturas de dados.\nOutro ponto chave é a utilização de ferramentas mais sofisticadas para álgebra matricial, produção de gráficos, álgebra analítica e métodos numéricos. Quatro exemplos são incluídos a seguir.\nNumpy Numpy é um pacote fundamental para a computação científica em Python. Dentre outras coisas, destaca-se pela definição e manipulação de arranjos de dados multidimensionais (tensores), conveniente álgebra linear, transformada de Fourier e capacidade de produzir números aleatórios.\nNo nível anterior, o problema do movimento uniformemente variável foi resolvido para obter a distância de deslocamento para um único ponto no tempo. Vamos usar um espaço linear do Numpy, indo de 0 à 20, discretizado em 51 pontos temporais. O código é o que segue:\n# Importamos a biblioteca import numpy # Criamos o espaço linear tempo = numpy.linspace(0, 20, num=51, endpoint=True) # Exibimos a variável na tela tempo  array([ 0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. , 4.4, 4.8, 5.2, 5.6, 6. , 6.4, 6.8, 7.2, 7.6, 8. , 8.4, 8.8, 9.2, 9.6, 10. , 10.4, 10.8, 11.2, 11.6, 12. , 12.4, 12.8, 13.2, 13.6, 14. , 14.4, 14.8, 15.2, 15.6, 16. , 16.4, 16.8, 17.2, 17.6, 18. , 18.4, 18.8, 19.2, 19.6, 20. ])  Calculamos novamente o deslocamento, agora para o vetor do bloco anterior, para cada ponto no espaço temporal teremos o retorno da respectiva posição, usando o seguinte código:\n# Calcula o vetor posição posicao = S0 + v0 * tempo + (a * tempo ** 2) / 2 # Exibe o resultado na tela posicao  array([ 0. , 3.92, 7.68, 11.28, 14.72, 18. , 21.12, 24.08, 26.88, 29.52, 32. , 34.32, 36.48, 38.48, 40.32, 42. , 43.52, 44.88, 46.08, 47.12, 48. , 48.72, 49.28, 49.68, 49.92, 50. , 49.92, 49.68, 49.28, 48.72, 48. , 47.12, 46.08, 44.88, 43.52, 42. , 40.32, 38.48, 36.48, 34.32, 32. , 29.52, 26.88, 24.08, 21.12, 18. , 14.72, 11.28, 7.68, 3.92, 0. ])  Podemos extrair mais informações do vetor posição que obtivemos no bloco anterior, se lembrarmos que a velocidade para cada instante é igual ao diferencial da posição com relação ao tempo. Mostrar exatamente como se programa um esquema diferencial é uma boa opção para um curso de métodos numéricos, ou a turma pode ser convidada a programar por si mesma. De qualquer modo, pode-se verificar o resultado também utilizando as funções de cálculo numérico que acompanham a biblioteca Numpy, como por exemplo numpy.gradient. Note que, em Python, pode-se acessar a documentação da função ao digitar help(numpy.gradient), ou ainda com o comando mágico numpy.gradient? quando em um ambiente Jupyter. O comando numpy.gradient?? retorna o código fonte da função, possibilitando assim investigar como ela realmente foi programada. O primeiro argumento informado para a função é o arranjo sobre o qual será calculado o gradiente, seguido pelo arranjo de coordenadas, o tempo nesse caso. edge_order é um argumento opcional que permite escolher a precisão da derivada junto aos contornos, por padrão esse valor é 1, mas podemos usar segunda ordem ao escolher o valor 2. Veja como fica o código:\n# Diferencial da posição com relação ao tempo velocidade = numpy.gradient(posicao, tempo, edge_order=2) # Exibe o resultado na tela velocidade  array([ 1.00000000e+01, 9.60000000e+00, 9.20000000e+00, 8.80000000e+00, 8.40000000e+00, 8.00000000e+00, 7.60000000e+00, 7.20000000e+00, 6.80000000e+00, 6.40000000e+00, 6.00000000e+00, 5.60000000e+00, 5.20000000e+00, 4.80000000e+00, 4.40000000e+00, 4.00000000e+00, 3.60000000e+00, 3.20000000e+00, 2.80000000e+00, 2.40000000e+00, 2.00000000e+00, 1.60000000e+00, 1.20000000e+00, 8.00000000e-01, 4.00000000e-01, 7.10542736e-15, -4.00000000e-01, -8.00000000e-01, -1.20000000e+00, -1.60000000e+00, -2.00000000e+00, -2.40000000e+00, -2.80000000e+00, -3.20000000e+00, -3.60000000e+00, -4.00000000e+00, -4.40000000e+00, -4.80000000e+00, -5.20000000e+00, -5.60000000e+00, -6.00000000e+00, -6.40000000e+00, -6.80000000e+00, -7.20000000e+00, -7.60000000e+00, -8.00000000e+00, -8.40000000e+00, -8.80000000e+00, -9.20000000e+00, -9.60000000e+00, -1.00000000e+01])  A aceleração, por sua vez, é igual ao diferencial da velocidade com relação ao tempo. Seguindo a mesma lógica do bloco anterior, temos:\n# Diferencial da velocidade com relação ao tempo aceleracao = numpy.gradient(velocidade, tempo, edge_order=2) # Exibe o resultado na tela aceleracao  array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])  Note que a aceleração constante está em conformidade com o problema aqui exemplificado, do movimento uniformemente variável.\nConfira a Documentação Numpy para ver tudo que o pacote tem a oferecer.\nMatplotlib Matplotlib é uma biblioteca de plotagem em Python, que produz figuras com qualidade de publicação em uma variedade de formatos e ambientes interativos. Você pode gerar gráficos, histogramas, espectros de potência, gráficos de barras, gráficos de erro, diagramas de dispersão e muito mais, com apenas algumas linhas de código, confira a Galeria de Exemplos.\nSeguindo o caso de estudo dessa postagem, a visualização dos resultados do movimento uniformemente variável é realizada com o seguinte bloco de código:\n# Importamos o pacote from matplotlib import pyplot # Descrevemos as três linhas que irão compor o gráfico pyplot.plot(tempo, posicao, label = 'Posição') pyplot.plot(tempo, velocidade, label = 'Velocidade') pyplot.plot(tempo, aceleracao, label = 'Aceleração') # Ativamos a legenda pyplot.legend() # Definimos a notação do eixo horizontal pyplot.xlabel('Tempo')  E assim, além da análise numérica, temos ferramentas de visualização integradas ao ambiente Jupyter. Os alunos são convidados a interagir com a aplicação, podendo facilmente alterar os parâmetros do problema e investigar as mudanças provocadas nos resultados.\nSympy Sympy é uma biblioteca Python para matemática simbólica. Seu objetivo é tornar-se um sistema de álgebra computacional (CAS) completo, mantendo o código o mais simples possível, para ser compreendido e facilmente extensível.\nExemplificamos o uso de matemática simbólica aqui em nosso estudo de caso. Para tanto, importamos Sympy, atribuímos para variáveis Python as suas representações simbólicas com sympy.symbols, construímos a equação analítica para o movimento uniformemente variável, e por fim apresentamos a equação resultante na tela:\nimport sympy # Importamos o pacote # Declaramos os símbolos S0, v0, a, t = sympy.symbols(\u0026quot;S_0 v_0 a t\u0026quot;) # Atribuímos a equação proposta eq_posicao = S0 + v0 * t + (a * t ** 2) / 2 # Exibimos a equação na tela eq_posicao  $$ S_0 + v_0t + \\dfrac{at^2}{2} $$\nUm recurso interessante é a substituição alguns dos símbolos por um valor numérico:\neq_posicao.subs({S0: 0, v0: 10, a: -1})  $$ - \\frac{t^{2}}{2} + 10 t$$\nCom isso, podemos graficar (com Matplotlib) a solução analítica:\nsympy.plotting.plot( eq_posicao.subs({S0: 0, a: -1, v0: 10}), (t, 0, 20), legend=True )  Ou ainda substituir todos os valores, e obter o dado deslocamento para o tempo 10, por exemplo:\neq_posicao.subs({S0: 0, v0: 10, a: -1, t: 10})  50.0  A solução analítica para a velocidade é obtida ao diferenciar a equação da posição em relação ao tempo:\n# Velocidade é o diferencial da posição pelo tempo eq_velocidade = sympy.diff(eq_posicao, t) # Exibimos a equação na tela eq_velocidade  $$ a t + v_{0} $$\nDe maneira semelhante, a solução analítica para a aceleração é obtida ao diferenciar a equação da velocidade em relação ao tempo:\n# Aceleração é o diferencial da velocidade pelo tempo eq_aceleracao = sympy.diff(eq_velocidade, t) # Exibimos a equação na tela eq_aceleracao  $$ a $$\nA aceleração é uma constante, afinal, esse é o movimento uniformemente variável.\nMuitos outros recursos estão disponíveis para a álgebra analítica com Sympy, como derivadas, integrais, limites, expansões em séries, aproximação para esquemas de diferenças finitas, resolução de equações (inclusive equações diferenciais), álgebra matricial, inequações, estatística, probabilidade, e muitos outros. Para uma visão completa, consulte a Documentação Sympy.\nScipy Por último, mas não menos importante, Scipy. Mais do que uma biblioteca Python, Scipy é uma coleção de software de código aberto para computação científica em Python. Fazem parte do projeto Numpy, Matplotlib e Sympy, que foram demonstradas anteriormente, IPython, que é na verdade o precursor do Projeto Jupyter, além de Pandas, que veremos a seguir. Por estarem todas essas importantes bibliotecas no contexto de um mesmo projeto, percebemos a grande sinergia e interoperabilidade entre elas.\nAlém disso, a própria biblioteca Scipy, um componente do universo Scipy, fornece muitas rotinas numéricas para: Integração numérica, diferenciação numérica, otimização, interpolação, transformada de Fourier, processamento de sinal, álgebra linear e álgebra linear esparsa, solução de problemas de autovalor, estatística, processamento de imagens e I/O de arquivos. Confira todos os detalhes na Documentação Scipy.\nNível Avançado Após construir a base da solução de problemas por ferramentas numéricas e analíticas na seção anterior, além de vermos como realizar gráficos com Matplotlib, chegamos agora à etapa final.\nNesse ponto, vale destacar a importância de balancear o nível de complexidade da resolução dos problemas com a expectativa didática, a experiência dos alunos pode ser frustrante ao se deparar com centenas de linha de código sem sentido. Esse ponto de equilíbrio deve ser avaliado caso a caso.\nA seguir, veremos alternativas para estruturas de dados, e também opções para produção de figuras interativas, que são uma grande ajuda para análise e interpretação dos resultados. Vale destacar que embora esses elementos apresentem uma barreira de entrada ligeiramente maior, uma vez sejam dominados, acabam por simplificar o fluxo de trabalho, permitindo resolver problemas mais complicados utilizando menos linhas de código.\nEstruturas de Dados Um passo natural após dominar Numpy, é partir para estruturas de dados mais elaboradas. O Pandas é um pacote Python que fornece estruturas de dados rápidas, flexíveis e expressivas, projetadas para tornar o trabalho com dados relacionais ou rotulados fáceis e intuitivos. A ferramenta apresenta dois tipos primários de estruturas de dados: Series (unidimensional) e DataFrame (bidimensional); sendo ideal para trabalhar com dados tabelados (SQL, arquivos Excel ou CSV, por exemplo), que cobre a vasta maioria da análise de dados em casos como finanças, estatística, ciências sociais e diversas áreas da engenharia. Uma das vantagens de utilizar Pandas é a facilidade com que podemos converter dados entre diferentes ferramentas. Na verdade, Pandas foi justamente construída sobre Numpy, e projetada para se integrar perfeitamente com todo a ambiente de computação científica.\nSeguindo o nosso estudo de caso, podemos agrupar os quatro vetores que construímos em Numpy em uma única estrutura Pandas, segundo o código:\n# Importamos o pacote import pandas # Criamos um DataFrame com base nos vetores # que produzimos anteriormente com Numpy tabela = pandas.DataFrame( { \u0026quot;Tempo\u0026quot;: tempo, \u0026quot;Posição\u0026quot;: posicao, \u0026quot;Velocidade\u0026quot;: velocidade, \u0026quot;Aceleração\u0026quot;: aceleracao, }, ) # Exibimos as 5 primeiras linhas da tabela na tela com .head() tabela.head()      Tempo Posição Velocidade Aceleração     0 0 0 10 -1   1 0.4 3.92 9.6 -1   2 0.8 7.68 9.2 -1   3 1.2 11.28 8.8 -1   4 1.6 14.72 8.4 -1    Obtemos facilmente uma descrição dos dados, incluindo a contagem, média, desvio padrão, e outros, basta utilizar o método .describe(), como segue:\ntabela.describe()      Tempo Posição Velocidade Aceleração     count 51 51 51 51   mean 10 32.6667 1.2539e-15 -1   std 5.94643 15.6486 5.94643 8.35323e-14   min 0 0 -10 -1   25% 5 21.12 -5 -1   50% 10 36.48 7.10543e-15 -1   75% 15 46.6 5 -1   max 20 50 10 -1    Conseguimos graficar todos os dados contidos na tabela com o método do DataFrame Pandas .plot(), que internamente está invocando Matplotlib, mas para o usuário, basta digitar:\ntabela.plot(x='Tempo')  Note que é exatamente a mesma figura que obtivemos antes com Matplotlib, mas dessa vez necessitamos de apenas uma linha de código. Recomenda-se a leitura da Documentação Pandas para uma visão geral de todas as vantagens que o pacote oferece.\nPandas funciona muito bem para dados 1D e 2D, mas e se o problema tiver mais dimensões? Bom, felizmente para esse caso temos Xarray, um pacote Python para lidar com arranjos catalogados N-dimensionais, também construído sobre Numpy, e com as funcionalidades fortemente inspiradas em Pandas. Xarray é ainda capaz de lidar com computação paralela e mesmo arquivos maiores do que a memória disponível, graças a sua integração com Dask. Temos um tutorial completo disponível em:\nFiguras Interativas Para exposição interativa dos resultados, possibilitando um conversa com os dados, outros pacotes gráficos Python surgem como alternativa à Matplotlib. Um exemplo é Plotly, que também está disponível para R e JavaScript. Os nossos dados tabelados são apresentados de maneira interativa com o seguinte bloco de código (experimente interagir com o mouse e testar as diferentes ferramentas):\nimport plotly.express as px fig = px.line( tabela, x=\u0026quot;Tempo\u0026quot;, y=[\u0026quot;Posição\u0026quot;, \u0026quot;Velocidade\u0026quot;, \u0026quot;Aceleração\u0026quot;], title=\u0026quot;Uma Figura Interativa\u0026quot;, ) fig.show()    (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./example.json\", function(chart) { Plotly.plot('chart-376248195', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })();  Novamente, no contexto educacional, a turma é convidada a interagir com os resultados, modificar parâmetros, analisar os novos resultados, em um aprendizado ativo.\nExiste uma série de outras ferramentas gráficas interativas disponíveis para as mais diversas aplicações, podemos citar: altair, bokeh, holoviews, e seaborn.\nOutros Temos algumas outras ferramentas que merecem destaque no ambiente Jupyter com aplicações didáticas:\n ipywidgets fornece uma série de widgets interativos, como botões, caixas de seleção, controles deslizantes e muito mais, permitindo criar ferramentas interativas avançadas para análise e resolução de problemas, uma opção perfeita para aplicativos de ensino; voilà permite exportar todos os elementos de um Jupyter Notebook para uma apresentação em estilo aplicativo web. Confira a Galeria Voilà para visualizar diversos exemplos; nbgrader é uma ferramenta voltada para auxiliar os instrutores na atribuição e avaliação de tarefas em Jupyter Notebooks.   Leitura Recomendada  Teaching and Learning with Jupyter, Lorena A. Barba, Lecia J. Barker, Douglas S. Blank, Jed Brown, Allen B. Downey, Timothy George, Lindsey J. Heagy, Kyle T. Mandli, Jason K. Moore, David Lippert, Kyle E. Niemeyer, Ryan R. Watkins, Richard H. West, Elizabeth Wickes, Carol Willing, and Michael Zingale. Open Book 2019. Disponível online.  Exemplos    Métodos Numéricos em Python  May 4, 2021 3:30 PM \u0026mdash; 5:30 PM   PPGRHSA, IPH, UFRGS   Veja no GitHub       Python: Introdução e Aplicações da Linguagem de Programação em Engenharia  Jul 16, 2019 2:00 PM \u0026mdash; Jul 16, 2020 5:30 PM   Escola Politécnica, PUCRS   Veja no GitHub       Métodos Numéricos Aplicados à Transferência de Calor  Oct 9, 2019 7:30 PM \u0026mdash; Oct 9, 2020 8:15 PM   Escola Politécnica, PUCRS   Veja no GitHub       CFD com Python: 12 Passos para Navier-Stokes      Alugar, economizar e pagar à vista ou financiar um imóvel? Um estudo de caso     Conclusão Esse foi um material demonstrativo sobre o emprego do Jupyter Notebook no contexto didático, uma vez que a ferramenta permite misturar trechos de texto descritivo com blocos de código interativos (assim como essa própria postagem), visando aumentar a participação, engajamento e desempenho dos estudantes das mais diversas áreas do conhecimento. Jupyter é um software gratuito e de código aberto, disponível em todos os sistemas operacionais e em servidores na nuvem (teste sem nenhuma instalação), além de ser compatível com dezenas de diferentes linguagens de programação. Por ser tão flexível, se enquadra não apenas em áreas do conhecimento onde a programação é um objetivo final, mas também em áreas onde a programação se apresenta como um meio para analisar e resolver problemas. Para uma demonstração mais imersivas, diversos pacotes Python de aplicação geral foram exemplificados. Certamente existe uma infinidade de outros pacotes Python com relevância ao contexto educacional, principalmente quando pensamos em soluções para problemas de domínios mais específicos. Mas de qualquer maneira, espero que essa leitura auxilie na disseminação dessa incrível ferramenta de ensino.\n","date":1611273600,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"f3b8a0512cd9b06a0be34406a4d1b7a4","permalink":"https://www.fschuch.com/blog/2021/01/22/jupyter-notebook-como-uma-poderosa-ferramenta-educacional/","publishdate":"2021-01-22T00:00:00Z","relpermalink":"/blog/2021/01/22/jupyter-notebook-como-uma-poderosa-ferramenta-educacional/","section":"post","summary":"Jupyter Notebook é um ambiente de programação interativo, que permite misturar trechos de texto descritivo com blocos de código e seus resultados. Isso o coloca como principal ferramenta de trabalho em Ciência de Dados, Aprendizado de Máquina e Inteligência Artificial, e essa postagem mostra o seu poder como ferramenta didática.","tags":["Jupyter","Python","Educação","Numpy","Matplotlib","Sympy","Scipy","Pandas","Plotly"],"title":"Jupyter Notebook como uma Poderosa Ferramenta Educacional","type":"post"},{"authors":null,"categories":null,"content":"Lista de Conteúdos  Introdução Metodologia  Localização Estilo Dimensões Formato   Conclusão    Introdução A síntese e análises de dados e resultados na forma gráfica é um tópico de interesse para profissionais das mais diversas áreas, seja na produção de conteúdo técnico/científico, educacional, ou para divulgação em meios digitais. Uma boa figura vai atrair a atenção do seu público alvo.\nExistem quatro tópicos que, na minha opinião, influenciam diretamente no resultado final dos gráficos que serão produzidos, especialmente quando falamos em qualidade de publicação. São eles:\n Localização: A formatação numérica deve estar de acordo com o idioma para o qual se está produzindo, seja na formatação de datas, moeda, ou mesmo o separador decimal; Estilo: Aqui se definem diversos aspectos visuais, como o esquema de cores do gráfico, eixos e plano de fundo, fonte, e outros elementos. É importante manter a consistência para os diversos gráficos que vão constituir o mesmo documento; Dimensões: A definição da largura e altura da figura, bem como o tamanho da fonte, devem ser condizentes com o tipo de conteúdo onde o gráfico será inserido, seja em slides, pôster, relatório, artigo, postagem nas redes sociais e muitos outros; Formato: O formato no qual as figuras serão salvas. Opções vetoriais são preferíveis, porque mantém uma boa apresentação visual mesmo em telas ou impressões de alta resolução, ou quando as figuras são ampliadas.   Metodologia Os pontos acima serão abordados em Python, ou mais especificamente, no pacote Matplotlib, que é uma biblioteca de plotagem 2D, que produz figuras de qualidade de publicação em uma variedade de formatos impressos e ambientes interativos para múltiplas plataformas. Matplotlib pode ser usada em scripts Python, nos shells do Python e do IPython, no Jupyter Notebook, nos servidores de aplicativos da web e em quatro kits de ferramentas de interface gráfica do usuário. Matplotlib tenta tornar as coisas fáceis simples e as coisas difíceis possíveis. Você pode gerar gráficos, histogramas, espectros de potência, gráficos de barras, gráficos de erros, diagramas de dispersão, etc., com apenas algumas linhas de código.\nAlém disso, funções de plotagem Matplotlib são integradas às principais soluções para gerenciamento de dados em Python, como NumPy, Pandas, Xarray, Dask e muitos outros.\nConfira na documentação do Matplotlib a melhor maneira de instalação no seu sistema. Podemos importar para nosso código com:\nimport matplotlib.pyplot as plt  Agora vamos abordar especificamente cada tópico listado para a produção de figuras com qualidade de publicação.\nLocalização Se seu interesse é produzir conteúdo em língua inglesa, indico que pule para o próximo tópico. Caso contrário, podemos usar o pacote locale para garantir a consistência de nossas figuras com os padrões da língua portuguesa, por exemplo, ou realmente qualquer outra. Para tanto, podemos importar o pacote e definir a linguagem padrão como português:\nimport locale locale.setlocale(locale.LC_ALL, \u0026quot;pt_BR.utf8\u0026quot;)  Todos os parâmetros personalizáveis são armazenados no dicionário plt.rcParams, uma visão completa está disponível na página de sua Documentação, mas não se preocupe, os principais pontos serão demonstrados aqui.\nO passo a seguir é informar que queremos utilizar outro idioma para a notação nos eixos dos gráficos, por exemplo, usar , como separador decimal, fazemos isso com o seguinte código:\nplt.rcParams.update( { 'axes.formatter.use_locale' : True, } )  Não faz sentido confundir o público com diferentes separadores de decimal se podemos resolver isso facilmente com três linhas de código, não é mesmo?\nPerceba que essa definição só é válida para os eixos das figuras, não modificando o comportamento do próprio núcleo Python, por exemplo:\nvalue = 0.67 print(value)  0.67  Note que a impressão ainda usa o ponto como separador decimal. Para impressões, anotações ou legendas nas figuras, podemos usar o método locale.str() para formatar automaticamente os números em ponto flutuante:\nprint(locale.str(value))  0,67  O que pode ser uma boa prática, uma vez que basta retornar uma linha de código para o inglês (locale.setlocale(locale.LC_ALL, \u0026quot;en_US.utf8\u0026quot;)), que todo o restante do código irá se comportar adequadamente.\nTambém é possível formatar facilmente dados monetários:\nprint(locale.currency(value))  'R$ 0,67'  E o formato das datas, com o pacote time, veja:\nfrom time import gmtime, strftime strftime(\u0026quot;%a, %d %b %Y %H:%M:%S +0000\u0026quot;, gmtime())  'qua, 14 out 2020 22:31:50 +0000'  Estilo Agora vamos falar sobre o estilo das figuras, incluindo sequencia de cores, estilo dos eixos, cor do fundo, presença ou não da grade, bem como seu próprio estilo, formatação das anotações e muitos outros detalhes.\nUma série de estilos já estão preparados e inclusos na biblioteca, e todos eles estão disponíveis em Documentação - Matplotlib. De lá, retirei alguns para exemplificar o leque de possibilidades que temos a nossa disposição:\n              \nIndicamos o uso de um estilo pelo seu nome, e o seguinte comando:\nplt.style.use('ggplot')  É possível ainda combinar diversos estilos em uma lista, para a produção de resultados únicos:\nplt.style.use(['ggplot', 'dark_background'])  Note que os estilos mais à direita irão sobrescrever parâmetros definidos previamente pelos estilos à esquerda, então a ordem com que são fornecidos pode mudar o resultado do final.\nPode-se ainda personalizar cada um dos aspectos dos gráficos individualmente, para mais detalhes, sugiro consultar a Documentação - Matplotlib. Caso queira retomar os parâmetros originais, use:\nplt.rcdefaults()  Dimensões Outro ponto essencial, a relação entre o tamanho da figura e o tamanho da fonte. Quando falamos em qualidade de publicação, os textos e números dos gráficos devem ser exatamente do mesmo tamanho que o restante do documento onde eles são inseridos.\nO ideal aqui é a precisa definição da largura e da altura que se deseja a figura, para que ela possa ser inserida no documento final em uma escala 1:1, sem nenhuma distorção.\nHá um pacote Python de minha autoria que facilita essa tarefa, o figure-scale. Maiores detalhes podem ser encontrados em sua Documentação, mas aqui vamos ver um exemplo de uso.\nPrimeiro, precisamos instalar o pacote:\npip install figure-scale  A classe FigureScale é o principal componente do pacote. Ela permite definir as dimensões da figura da maneira que for mais conveniente para seu caso:\n Largura e Altura: Especificar ambas as dimensões explicitamente; Largura e Proporção: Especificar a largura e deixar a altura ser calculada a partir da proporção; Altura e Proporção: Especificar a altura e deixar a largura ser calculada a partir da proporção.  Todas as dimensões podem ser especificadas em várias unidades. Vamos explorar cada abordagem:\nimport figure_scale as fs size_a = fs.FigureScale(units=\u0026quot;mm\u0026quot;, width=100, height=100) size_b = fs.FigureScale(units=\u0026quot;mm\u0026quot;, width=100, aspect=1.0) size_c = fs.FigureScale(units=\u0026quot;mm\u0026quot;, height=100, aspect=1.0)  Vamos detalhar cada um dos parâmetros:\n width é a largura útil da página, isso é, a largura da página menos ambas margens. Ou a largura da coluna, para os casos em que isso se aplicar. Em documentos $\\LaTeX$, esse valor pode ser obtido com o comando \\the\\columnwidth; height pode ser usado para o ajuste da altura em termos absolutos, caso o ajuste fino seja desejado. Em documentos $\\LaTeX$, esse valor pode ser obtido com o comando \\the\\textheight; aspect define a altura da figura em valor relativo em relação à largura. Por exemplo, aspect=1.0 criará uma figura quadrada, enquanto aspect=9.0/16.0 criará a proporção certa para telas wide-screen; unit representa a unidade de comprimento para width e height, algumas das opções suportadas são \u0026ldquo;in\u0026rdquo; (polegada), \u0026ldquo;mm\u0026rdquo;, \u0026ldquo;cm\u0026rdquo; e \u0026ldquo;pt\u0026rdquo; (pontos tipográfico, é a utilizada em $\\LaTeX$). Assim, o objeto realiza a devida conversão de unidades, uma vez que Matplotlib espera essa definição em polegadas.  Note que apenas dois dos três parâmetros width, height e aspect são necessários, o terceiro será calculado automaticamente a partir dos outros dois. A classe FigureScale implementa o protocole de Sequence, fazendo com que possa ser aceito como argumento para o parâmetro figsize em qualquer função Matplotlib que o aceite, como plt.subplots(), plt.figure() e outros.\nVeja como agora podemos definir com precisão o padrão de desejamos para dimensões e tamanho da fonte:\nplt.rcParams.update( { # 'figure.figsize' : fs.FigureScale(units='mm', width=160, aspect=1), # \u0026quot;axes.labelsize\u0026quot;: 12, \u0026quot;font.size\u0026quot;: 12, \u0026quot;legend.fontsize\u0026quot;: 12, \u0026quot;xtick.labelsize\u0026quot;: 12, \u0026quot;ytick.labelsize\u0026quot;: 12, } )  É possível realizar posteriormente um ajuste personalizado para cada figura, por exemplo:\nfig, axes = plt.subplots(figsize=fs.FigureScale(units='mm', width=160, aspect=1))  Toda minha produção técnica/científica tem sido feita em $\\LaTeX$, o que eu certamente recomendo. De fato, esse pode ser um tópico para outro post no futuro próximo. Se esse não é o seu caso, pode ser o momento de prosseguir para o próximo tópico. De qualquer maneira, vou compartilhar alguns outros ajustes para referência:\n  Artigo com o template de duas colunas da Elsevier:\nptl.rcParams.update( { 'figure.figsize' : fs.FigureScale(unit='pt', width=238.25444, aspect=3/4), # \u0026quot;axes.labelsize\u0026quot;: 8, \u0026quot;font.size\u0026quot;: 8, \u0026quot;legend.fontsize\u0026quot;: 8, \u0026quot;xtick.labelsize\u0026quot;: 8, \u0026quot;ytick.labelsize\u0026quot;: 8 } )    Relatório técnico, Dissertação ou Tese com abnTeX2:\nptl.rcParams.update( { 'figure.figsize' : fs.FigureScale(unit='pt', width=455.0, aspect=3/4), # \u0026quot;axes.labelsize\u0026quot;: 12, \u0026quot;font.size\u0026quot;: 12, \u0026quot;legend.fontsize\u0026quot;: 12, \u0026quot;xtick.labelsize\u0026quot;: 12, \u0026quot;ytick.labelsize\u0026quot;: 12, } )    Pôster em tamanho A0 com beamer (e esse template):\nptl.rcParams.update( { 'figure.figsize' : fs.FigureScale(unit='pt', width=2376.3973*.75, aspect=9/16), # \u0026quot;axes.labelsize\u0026quot;: 24, \u0026quot;font.size\u0026quot;: 24, \u0026quot;legend.fontsize\u0026quot;: 24, \u0026quot;xtick.labelsize\u0026quot;: 24, \u0026quot;ytick.labelsize\u0026quot;: 24, } )    Apresentação de slides com beamer (e o tema Focus v2.6):\nptl.rcParams.update( { 'figure.figsize' : fs.FigureScale(unit='pt', width=412.56497), aspect=9/16, } )    Em $\\LaTeX$, você tem a certeza de que deu tudo certo quando a figura é incluída com scale=1, e as dimensões e tamanho de fonte tem a aparência adequada, por exemplo:\n\\includegraphics[scale=1]{\u0026lt;nome_da_figura\u0026gt;}   Formato Por fim, temos o formato no qual serão salvos os gráficos. Eles podem ser divididos basicamente em dois grandes grupos, e temos um bloco de código para exemplificar:\nimport numpy as np x = np.linspace(0.0, 2.0 * np.pi) y = np.sin(x) for f in ['jpg', 'svg']: plt.plot(x,y, label = 'Label') plt.legend() plt.savefig('example_line.'+f, format=f)    Formato de matriz: A figura é constituída por um arranjo de pixels (ou matriz), que possuí um tamanho definido, por exemplo 240 x 120 pixels. Se quisermos amplia-la, veremos cada pequeno pixel, em um efeito meio quadriculado. Nesse grupo temos por exemplo os formatos JPG e PNG, veja o resultado:\n  Figura em formato de matriz 768 x 576 pixels (jpg).  A qualidade da figura é controlada pelo número de pixels, ou o parâmetro dpi (pontos por polegada, do inglês dots per inch). Aumentar o dpi aumenta a qualidade da imagem, mas também aumenta seu espaço em disco;\n  Formato Vetorial: Aqui, a figura é composta por vetores, utilizando elementos matemáticos para compor a figura completa. Ao contrário do grupo anterior, ela não perde qualidade quando ampliada. Como exemplo temos os formatos SVG e PDF, veja a figura:\n  Figura em formato vetorial (svg).    Mas afinal, qual escolher? A resposta é: isso depende.\nEu diria que opções vetoriais são preferíveis (svg para web, PDF para produção técnica), porque mantém uma boa apresentação visual mesmo em telas ou impressões de alta resolução, ou quando as figuras são ampliadas. Existem entretanto aplicações que simplesmente não aceitam formatos vetoriais (como algumas redes sociais), então podemos mudar para formato matricial (jpg ou png). Outro desafio para o formato vetorial é quando temos um elevado número de artefatos vetoriais. Independente do tipo de gráfico, à medida que a quantidade de dados vai aumentando de centenas, para milhares e milhões de pontos, pode ser que o espaço que a figura vetorial ocupa em disco seja, afinal, impraticável.\nNote entretanto que existe uma abordagem intermediária, métodos em Matplotlib que permitem converter elementos vetoriais para representação matricial, chamados rasterization. Para exemplificar isso, temos um bloco de código modificado da Documentação - Matplotlib, veja o código e a figura resultante:\nimport numpy as np import matplotlib.pyplot as plt d = np.arange(100).reshape(10, 10) x, y = np.meshgrid(np.arange(11), np.arange(11)) theta = 0.25*np.pi xx = x*np.cos(theta) - y*np.sin(theta) yy = x*np.sin(theta) + y*np.cos(theta) fig, (ax1, ax2, ax3) = plt.subplots(1, 3) ax1.set_aspect(1) ax1.pcolormesh(xx, yy, d) ax1.text(0.5, 0.5, \u0026quot;Text\u0026quot;, alpha=0.2, va=\u0026quot;center\u0026quot;, ha=\u0026quot;center\u0026quot;, size=50, transform=ax1.transAxes) ax1.set_title(\u0026quot;No Rasterization\u0026quot;) ax2.set_aspect(1) ax2.pcolormesh(xx, yy, d, zorder=-15) ax2.text(0.5, 0.5, \u0026quot;Text\u0026quot;, alpha=0.2, zorder=5, va=\u0026quot;center\u0026quot;, ha=\u0026quot;center\u0026quot;, size=50, transform=ax2.transAxes) ax2.set_title(\u0026quot;Rasterization z$\u0026lt;-10$\u0026quot;) ax2.set_rasterization_zorder(-10) ax3.set_aspect(1) ax3.pcolormesh(xx, yy, d) ax3.text(0.5, 0.5, \u0026quot;Text\u0026quot;, alpha=0.2, va=\u0026quot;center\u0026quot;, ha=\u0026quot;center\u0026quot;, size=50, transform=ax3.transAxes) ax3.set_title(\u0026quot;Rasterization\u0026quot;) ax3.set_rasterized(True) plt.savefig(\u0026quot;test_rasterization.pdf\u0026quot;, dpi=150) plt.savefig(\u0026quot;test_rasterization.eps\u0026quot;, dpi=150) if not plt.rcParams[\u0026quot;text.usetex\u0026quot;]: plt.savefig(\u0026quot;test_rasterization.svg\u0026quot;)    Vemos acima uma figura vetorial com três sub-gráficos:\n No elemento à esquerda, temos a figura puramente vetorial (No Rasterization), perceba a boa qualidade visual mesmo quando ampliada; A figura à direita foi convertida para o formato matricial (Rasterization) com a linha ax3.set_rasterized(True), incluindo título, coordenadas, anotação e o pcolormesh, mesmo que a figura tenha sido salva em svg. Perceba como ela foi totalmente representada pixel por pixel; No centro temos uma solução intermediária. Nesse caso, apenas elementos com zorder1 menor que -10 foram transformados com a linha ax2.set_rasterization_zorder(-10), nesse caso temos o pcolormesh. Título, coordenadas e a anotação permaneceram vetoriais, e assim, podemos obter o melhor de dois mundos.  A efetiva escolha sobre quais elementos converter é novamente um compromisso entre a qualidade da imagem e o seu tamanho em disco, e isso certamente depende de cada aplicação, ou mesmo da preferência pessoal. Note que dpi ainda é um parâmetro válido para os elementos convertidos para pixels.\nFinalmente, podemos definir esses parâmetros para serem aplicados como padrão em nosso código da seguinte maneira:\nplt.rcParams.update( { 'figure.dpi' : 240, 'savefig.format' : 'pdf', # 'text.usetex' : True, 'text.latex.preamble' : \u0026quot;\\\\usepackage{icomma}\u0026quot;, } )  A opção text.usetex é particularmente útil para quem usa $\\LaTeX$, permitindo incluir equações como anotações, título ou como rótulo para as coordenadas. A opção 'text.latex.preamble' : \u0026quot;\\\\usepackage{icomma}\u0026quot; é um bônus, isso elimina o espaço inserido em modo matemático após cada vírgula, que certamente não são bem-vindos quando falamos em qualidade de publicação.\nConclusão A apresentação de resultados em alta qualidade é um ponto fundamental para atrair engajamento e atenção do seu público. Aqui demonstrou-se como a atenção nos detalhes e algumas poucas linhas de código podem ter um enorme impacto na apresentação dos resultados em formato gráfico. Por fim, espero que esse meu relato sobre a produção de figuras em Python e Matplotlib lhe seja útil como um ponto de partida e motivação para seguir estudando o tema.\n  O parâmetro zorder controla a ordem na qual cada elemento do gráfico será exibido, isso é, o texto com zorder=5 será exibido sobre a figura pcolormesh com zorder=-15. Para maiores informações, consulte a Documentação - Matplotlib.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":1602633600,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"9fcd592824de914fc850cc19e8883814","permalink":"https://www.fschuch.com/blog/2020/10/14/graficos-com-qualidade-de-publicacao-em-python-com-matplotlib/","publishdate":"2020-10-14T00:00:00Z","relpermalink":"/blog/2020/10/14/graficos-com-qualidade-de-publicacao-em-python-com-matplotlib/","section":"post","summary":"Independente do tipo de conteúdo que você está trabalhando, seja técnico, científico, educacional, ou voltado para divulgação em mídias sociais, existem quatro tópicos que influenciam diretamente na qualidade dos gráficos que se estão produzindo: Localização, dimensões, estilo e formato. Todos são abordados em detalhes neste post.","tags":["Matplotlib","LaTeX","Python"],"title":"Gráficos com qualidade de publicação em Python com Matplotlib","type":"post"},{"authors":["Felipe N. Schuch","F.D. Vianna","A. Mombach","J.H. Silvestrini"],"categories":null,"content":"Descrição Iniciantes podem enfrentar muitas barreiras de entrada em um código acadêmico para Fluidodinâmica Computacional (CFD), por exemplo:\n A decomposição de domínio de cálculo para computação paralela em um sistema de memória distribuída; Programação, compilação, teste e depuração em linguagens de programação como Fortran ou C; O receio de estragar qualquer coisa no código fonte; Critérios de estabilidade de diferentes métodos numéricos; Falta de documentação e outros.  Esse trabalho visa quebrar essas barreiras ao construir uma camada Python, ou mais especificamente Jupyter Notebook, sobre o código CFD, programado originalmente em Fortran.\nPara tanto, o código CFD de alta ordem Xcompact3d foi modificado para aceitar toda a configuração do escoamento sob investigação de uma fonte externa, incluindo parâmetros físicos e numéricos, condição inicial e condições de contorno, e uma geometria sólida que pode ser inserida no domínio cartesiano por meio do método das fronteiras imersas (IBM, do inglês Immersed Boundary Method). A configuração do escoamento, por sua vez, é fornecida a partir de um Jupyter Notebook, aproveitando a documentação embutida com células Markdown (incluindo facilmente figuras, tabelas e equações $\\LaTeX$), visualização e interatividade com widgets e bibliotecas de plotagem, além da versatilidade e legibilidade da programação em Python. Além disso, os parâmetros de entrada podem ser verificados quanto à consistência e compatibilidade. O conhecimento prévio de NumPy e Matplotlib é suficiente para começar com as configurações de escoamento exemplificadas. No entanto, não há limitação para estendê-lo para ferramentas mais avançadas como Pandas, Xarray, Dask, Numba, Holoview, Plotly e muitos outros do ecossistema Jupyter. Na verdade, o Jupyter CFD Sandbox foi incorporado ao pacote Python Xcompact3d-toolbox.\nO resultado da metodologia apresentada nesse trabalho pode beneficiar usuários de diferentes níveis:\n Para alunos de fluidodinâmica computacional, oferece experiência prática direta e um local seguro para praticar e aprender; Para usuários avançados e desenvolvedores de código, ele funciona como uma ferramenta de prototipagem rápida, onde é possível testar conceitos e, em seguida, comparar os resultados para validar quaisquer implementações futuras no solucionador numérico.  Além disso, é um avanço importante em termos de reprodutibilidade de pesquisa, e pode ser portado para qualquer outro solucionador numérico, (avise-nos se você fizer isso).\nTutoriais e diversas configurações de escoamento estão disponíveis na Documentação do Xcompact3d-toolbox.\n","date":1602460800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"94f58d3ba326a0deef54ba555b589c75","permalink":"https://www.fschuch.com/publication/2020-jupytercon/","publishdate":"2020-09-02T17:46:50-03:00","relpermalink":"/publication/2020-jupytercon/","section":"publication","summary":"Este trabalho visa quebrar muitas das barreiras de entrada em um código acadêmico que resolva Navier-Stokes, acoplando-o a um ambiente *Jupyter sandbox*. Para alunos de fluidodinâmica computacional, ele fornece experiência prática direta e um local seguro para praticar e aprender, enquanto para usuários avançados e desenvolvedores de código, funciona como uma ferramenta de prototipagem rápida.","tags":["CFD","Python","Xcompact3d"],"title":"Um ambiente \"Jupyter Sandbox\"  acoplado ao Xcompact3d, um código acadêmico de alta ordem para Fluidodinâmica Computacional","type":"publication"},{"authors":["Felipe N. Schuch","Mathias S. Tessmann"],"categories":null,"content":"","date":1598486400,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"297997355fd87fcd586bffd39b24065c","permalink":"https://www.fschuch.com/publication/2020-boletim-economia-empirica-4/","publishdate":"2020-08-27T00:00:00Z","relpermalink":"/publication/2020-boletim-economia-empirica-4/","section":"publication","summary":"O presente ensaio trata-se de um estudo de caso em matemática financeira resolvido em Python. O mesmo envolve calcular diferentes cenários com relação a aquisição - ou não - de um imóvel. Além disso, aborda a manipulação de tabelas com o pacote Pandas e a produção de gráficos com Matplotlib. Veja o material completo para mais detalhes.","tags":["Engenharia Econômica","Educação Financeira","Python"],"title":"Simulações em Python para Tomada de Decisão: Alugar, Economizar e Pagar à Vista ou Financiar um Imóvel","type":"publication"},{"authors":null,"categories":null,"content":"Sobre Esse é um pacote Python projetado para lidar com o pré e pós-processamento dos dados provenientes do código Xcompact3d, uma solução acadêmica de código aberto e alta precisão, empregada para solucionar problemas de fluidodinâmica computacional com transporte de escalares. Tem como objetivo ajudar os usuários e desenvolvedores de código com um conjunto de ferramentas e processos automatizados.\nOs parâmetros físicos e computacionais são construídos sobre traitlets, uma estrutura que permite que as classes em Python tenham seus atributos checados quanto ao tipo, definição de valores padrões, e chamadas de métodos de verificação de atributos quando necessário. Isso visa manter todos os parâmetros em compatibilidade com o que o simulador espera. Além disso, ipywidgets são fornecidos para uma experiência amigável com o usuário (veja exemplos na Documentação).\nA estrutura de dados empregada é xarray (veja Why xarray?), que introduz mapeamentos na forma de dimensões, coordenadas e atributos sobre os arranjos puramente NumPy, permitindo uma experiência de desenvolvimento mais intuitiva, concisa e menos propensa à erros. Xcompact3d Toolbox conta com métodos capazes de ler os dados binários brutos resultantes das simulações do Xcompact3d, e empacota-los em um arranjo de dados Xarray, assim como o processo contrário, escrevendo-os para o disco em uma maneira compatível com a leitura de dados do Xcompact3d. Além disso, os arranjos de dados são compatíveis com dask para computação paralela.\nPor fim, Xcompact3d Toolbox está perfeitamente integrado à nova configuração de escoamento Sandbox (veja fschuch/Xcompact3d). O plano é fornecer toda a informação que o Xcompact3d precisa para especificar uma simulação, como condição inicial, geometria sólida, condições de contorno e o arquivo de parâmetros (veja os exemplos). Desse modo, iniciantes podem executar qualquer configuração inédita sem ter que se preocupar com programar em Fortran e com o ambiente de paralelização 2decomp. Para desenvolvedores, isso funciona como uma ferramenta de prototipagem rápida, para testar hipóteses e conceitos, além de servir como base de comparação para validar qualquer implementação futura no código fonte do Xcompact3d.\n","date":1597363200,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"2a1a8c2da22c74d3b0e2c7ec405e0e5b","permalink":"https://www.fschuch.com/project/xcompact3d-toolbox/","publishdate":"2020-08-14T00:00:00Z","relpermalink":"/project/xcompact3d-toolbox/","section":"project","summary":"Pacote Python com uma série de utilidades para lidar com o pré e pós-processamento de dados de simulações numéricas do Xcompact3d.","tags":["CFD","Dask","IPywidgets","Jupyter","Python","Xarray","Xcompact3d"],"title":"Xcompact3d Toolbox","type":"project"},{"authors":null,"categories":null,"content":"Introdução Desejo boas-vindas ao tutorial Xarray.\nXarray é um pacote Python de código aberto que visa tornar o trabalho com arranjos de dados catalogados uma tarefa simples, eficiente e até mesmo divertida!\nXarray introduz labels (mapeamento, rótulo, catálogo) como forma de expressar dimensões, coordenadas e atributos construidos acima de arranjos brutos do tipo NumPy, o que permite um fluxo de trabalho e desenvolvimento mais intuitivo, conciso e a prova de erros. O pacote inclui uma biblioteca grande e crescente de funções aplicadas para análises e visualização com essas estruturas de dados.\nXarray é inspirado e inclusive toma várias funcionalidades emprestadas do pandas, o popular pacote para manipulação de dados tabelados. Também é especialmente adaptado para funcionar com arquivos netCDF, que foram a fonte do modelo de dados em Xarray, além de integrar-se perfeitamente com Dask para computação paralela.\nConfigurando o Tutorial Esse tutorial foi projetado para rodar no Binder. O serviço permite executar totalmente na nuvem, nenhuma instalação extra é necessária. Para tanto, basta clicar aqui: \nSe você prefere instalar o tutorial localmente, siga os seguintes passos:\n  Clone o repositório:\ngit clone https://github.com/fschuch/xarray-tutorial-python-brasil    Instale o ambiente. O repositório inclui um arquivo environment.yaml no subdiretório .binder que contém uma lista de todos os pacotes necessários para executar esse tutorial. Para instalá-los usando conda, use o comando:\nconda env create -f .binder/environment.yml conda activate xarray    Inicie uma seção Jupyter:\njupyter lab    Material complementar   Referências\n Documentação Overview: Why xarray? Repositório do Xarray    Peça ajuda:\n Use a seção python-xarray no StackOverflow GitHub Issues para reportar bugs e requisitar novas funcionalidades    Estrutura do Tutorial O material é composto por múltiplos Jupyter Notebooks. Eles, por sua vez, são compostos por uma mistura de código, texto, visualizações e exercícios.\nSe essa é sua primeira experiência com JupyterLab, não se preocupe, ele é bastante simular com o Jupyter Notebook clássico. Se essa é a sua primeira vez com um Notebook, aqui vai uma introdução rápida:\n Existem células em dois modos: comando e edição; A partir do modo de comando, precione Enter para editar uma célular (assim como essa célula em Markdown); Do modo de edição, precione Esc para retornar ao modo de comando; Precione Shift + Enter para executar a célula e mover o cursor para a célula seguinte; A barra de ferramentas contém botões para executar, converter, criar, quebrar e mesclar células.  O conteúdo abordado será o seguinte:\n Introdução + Estruturas para dados Multidimensionais Trabalhando com dados mapeados Computação com Xarray Gráficos e Visualização Introdução ao Dask Dask e Xarray para computação paralela  ","date":1597168800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"57a2392eac1d70b5bfb4ba4711b4d5df","permalink":"https://www.fschuch.com/talk/xarray-estruturas-para-dados-multidimensionais/","publishdate":"2020-08-11T15:00:00-03:00","relpermalink":"/talk/xarray-estruturas-para-dados-multidimensionais/","section":"event","summary":"Tutorial introdutório para *Xarray*, um pacote Python de código aberto que é capaz de tornar o trabalho com arranjos de dados multidimensionais e catalogados uma tarefa simples e eficiente. Destaca-se a sua sinergia com outras ferramentas para I/O, plotagem e computação paralela.","tags":["Python","Xarray","Matplotlib"],"title":"Xarray, estruturas para dados multidimensionais","type":"event"},{"authors":null,"categories":null,"content":"Lista de Conteúdos  Introdução Descrição do Problema Desenvolvimento  NumPy Xarray   Conclusão    Introdução O estudo de caso apresentado aqui, a condução de calor transiente em uma placa bidimensional, tem um papel interessante, pois ele não é exatamente o objetivo deste texto, mas sim um meio. Deixe-me explicar, dia desses me deparei com Xarray (formalmente xray), pacote Python que se destina a tornar o trabalho com arranjos de dados multidimensionais uma tarefa simples, eficiente e divertida.\nXarray introduz rótulos na forma de dimensões, coordenadas e atributos sobre os dados brutos dos arranjos em formato NumPy, permitindo uma experiência de desenvolvimento mais intuitiva, consistente e a prova de falhas.\nApós ler a documentação oficial, fiquei empolgado para ver como esse pacote funciona na prática, e fico feliz em compartilhar essa experiência com você. Aqui entra o estudo da condução de calor transiente bidimensional, que será descrito a seguir. Logo após, o problema será resolvido com estruturas de dados NumPy, para contextualizar o leitor com três abordagens diferentes, e então, o mesmo problema será resolvido com Xarray para comparação.\n# Como sempre, o primeiro passo é importar # os pacotes que vamos utilizar # NumPy para manipulação de arranjos N-dimensionais import numpy as np # Matplotlib para graficar os resultados import matplotlib.pyplot as plt # Xarray, para testar o conceito dos rótulos # na forma de dimensões, coordenadas e atributos import xarray as xr   Descrição do Problema Uma placa de cobre de \\( (L_x \\times L_y) = ( 50 ~ cm \\times 50 ~ cm ) \\) inicialmente possui temperatura em toda a sua extensão igual à \\( T_0 = 0^oC \\).\nInstantaneamente, a temperatura em suas bordas é elevada. Vamos admitir que cada um dos contornos tenha uma variação linear de acordo com a temperatura definida nos vértices da geometria, conforme mostra a figura a seguir:\nSabe-se que as propriedades do material são:\n Condutividade térmica \\( k = 52 ~ W/m \\cdot K \\); Calor específico \\( c_p = 420 ~ J / kg \\cdot K \\); Massa específica \\( \\rho = 8.800 ~ kg / m^3 \\); Difusividade térmica \\( \\alpha = k / (\\rho c_p) \\).  Considerando um passo de tempo $\\Delta t = 4 ~ s$ e a resolução espacial de $\\Delta x = \\Delta y = 5 ~ cm$, calcule a evolução da temperatura na placa até o tempo de $6.000 ~ s$.\nEquação bidimensional que define a difusão de calor:\n\\[ \\dfrac{\\partial T}{\\partial t} = \\alpha \\left( \\dfrac{\\partial ^2 T}{\\partial x^2} + \\dfrac{\\partial ^2 T}{\\partial y^2} \\right), \\quad 0 \\le x \\le L_x, \\quad 0 \\le y \\le L_y, \\quad t \\ge 0. \\]\nCondições de cortorno:\n\\[ T_{x0} = T(x=0,y) = y \\dfrac{T_d - T_a}{L_y} + T_a, \\] \\[ T_{xn} = T(x=L_x,y) = y \\dfrac{T_b - T_c}{L_y} + T_c, \\] \\[ T_{y0} = T(x,y=0) = x \\dfrac{T_c - T_a}{L_x} + T_a, \\] \\[ T_{yn} = T(x,y=Ly) = x \\dfrac{T_b - T_d}{L_x} + T_d. \\]\nCondição inicial:\n\\[ T(x,y) = T_0, \\quad para \\quad t=0. \\]\nDiscretizando com a derivada segunda numa representação por diferença central e a derivada primeira com diferença ascendente temos:\n\\[ \\dfrac{T^{n+1} _{i,j}-T^{n} _{i,j}}{\\Delta t}=\\alpha \\left[ \\dfrac{T^{n} _{i-1,j}-2T^{n} _{i,j}+T^{n} _{i+1,j}}{(\\Delta x)^2} +\\dfrac{T^{n} _{i,j-1}-2T^{n} _{i,j}+T^{n} _{i,j+1}}{(\\Delta y)^2} \\right], \\quad 0 \\le i \\le I, \\quad 0 \\le j \\le J, \\quad n \\ge 0, \\]\n\\[ T_{x0} = y_j \\dfrac{T_d - T_a}{L_y} + T_a, \\quad para \\quad i=0 \\quad e \\quad 0 \\le j \\le J, \\] \\[ T_{xn} = y_j \\dfrac{T_b - T_c}{L_y} + T_c, \\quad para \\quad i=I \\quad e \\quad 0 \\le j \\le J, \\] \\[ T_{y0} = x_i \\dfrac{T_c - T_a}{L_x} + T_a, \\quad para \\quad 0 \\le i \\le I \\quad e \\quad j=0, \\] \\[ T_{yn} = x_i \\dfrac{T_b - T_d}{L_x} + T_d, \\quad para \\quad 0 \\le i \\le I \\quad e \\quad j=J, \\] \\[ T_{i,j}^n = T_0, \\quad para \\quad n=0. \\]\nLembre-se que o critério de estabilidade numérica do problema é:\n\\[ \\Delta t \\le \\dfrac{\\Delta x^2}{4 \\alpha}. \\]\nDesenvolvimento Uma vez descrito o problema, partimos para a prática! No bloco de código a seguir definimos todos os parâmetros físicos e numéricos que necessitamos:\n# Propriedades do Material k = 52.0 # W/mK cp = 420.0 # J/kgK rho = 8800.0 # kg/m^3 # Temperatura nos vértices Ta = 60. Tb = 20. Tc = 0. Td = 100. # Temperatura inicial T0 = 0. # Discretização espacial x = np.linspace(start=0., stop=.5, num=21, endpoint=True) y = np.linspace(start=0., stop=.5, num=21, endpoint=True) # e temporal t = np.linspace(start=0., stop=600., num=601, endpoint=True)  E então realizamos os primeiros cálculos:\n# Cálculo da difusividade térmica alpha = k / (rho * cp) # Passo de tempo e resolução da malha ao quadrado dt, dx2, dy2 = t[1] - t[0], (x[1] - x[0])**2., (y[1] - y[0])**2. # Estabilidade numérica if dt \u0026lt;= np.minimum(dx2, dy2) / 4. / alpha: print('Critério de estabilidade satisfeito.') else: print('Atenção! Critério de estabilidade não satisfeito.')  Critério de estabilidade satisfeito.  Lembre-se que a documentação de qualquer função pode ser facilmente acessada sempre que surgir alguma dúvida sobre a sintaxe ou sobre os argumentos que ela aceita, basta digitar help(np.linspace).\nA partir daqui começa a resolução do problema:\n# Alocar a temperatura e impor condição inicial T = T0 * np.ones((x.size, y.size, t.size)) # Condições de Contorno Tx0 = (Td - Ta) / (y[-1] - y[0]) * y + Ta Txn = (Tb - Tc) / (y[-1] - y[0]) * y + Tc Ty0 = (Tc - Ta) / (x[-1] - x[0]) * x + Ta Tyn = (Tb - Td) / (x[-1] - x[0]) * x + Td # Aplicando as condições de contorno no tempo inicial T[0, :, 0] = Tx0 T[-1, :, 0] = Txn T[:, 0, 0] = Ty0 T[:, -1, 0] = Tyn  Bom, aqui fazemos uma observação quanto aos arranjos em NumPy, é preciso sempre ter em mente a maneira como foram definidos. No caso da temperatura temos três coordenadas na ordem [x, y e t], ou [i, j e n] no espaço discreto. Portanto, ao aplicar T[0,:,0] = Tx0, dizemos que T será igual à Tx0 onde i=0 e n=0, para todo o j, exatamente o que queremos para essa condição de contorno, o mesmo pode ser percebido nas demais superfícies. Lembre-se que em Python, o índice -1 retoma o último elemento de uma dada dimensão.\nVamos definir uma função auxiliar para graficar os resultados obtidos, assim podemos facilmente repetir a produção de figuras para as diversas abordagens que usaremos. Veja o código:\ndef minha_figura(T, x, y): fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12, 4)) # Variação temporal da temperatura no centro da placa ax[0].plot(t, T[x.size // 2, y.size // 2, :]) ax[0].set(xlabel='t [s]', ylabel=r'T [$^0C$]', title=f'x={x[x.size//2]} e y={y[y.size//2]}') # E duas figuras para variação espacial: nfigs = 5 for n in range(nfigs): time = n * ((t.size) // (nfigs - 1)) # Variação com x e t para y fixo ax[1].plot(x, T[:, y.size // 2, time], label=f't={t[time]}s') # Variação com y e t com x fixo ax[2].plot(y, T[x.size // 2, :, time], label=f't={t[time]}s') # Adicionamos alguns detalhes visuais ax[1].set(xlabel='x [cm]', title=f'y={y[y.size//2]}') ax[2].set(xlabel='y [cm]', title=f'x={x[x.size//2]}') ax[1].legend() ax[2].legend() plt.show();  NumPy O avanço no tempo se dá ao isolarmos o termo \\( T^{n+1} _{i,j} \\) na equação governante discreta, que então assume a forma:\n\\[ T^{n+1} _{i,j} = T^{n} _{i,j} + \\alpha \\Delta t \\left[ \\dfrac{T^{n} _{i-1,j}-2T^{n} _{i,j}+T^{n} _{i+1,j}}{(\\Delta x)^2} +\\dfrac{T^{n} _{i,j-1}-2T^{n} _{i,j}+T^{n} _{i,j+1}}{(\\Delta y)^2} \\right], \\]\npara: \\(\\quad 0 \\le i \\le I, \\quad 0 \\le j \\le J, \\quad n \\ge 0 \\).\nPerceba que quando n=0, todos os valores à direita da igualdade são conhecidos (nossa condição inicial), e assim, pode-se calcular o termo à esquerda, que será a temperatura em n+1. Repetindo esse processo sucessivamente para cada valor de i, j e n, atingimos qualquer valor de tempo desejado, passo à passo.\nA maneira mais intuitiva de programar a equação acima é escrevê-la exatamente como ela é, percorrendo todo o espaço bidimensional e o tempo por meio de três laços aninhados, e aplicando as condições de contorno ao final de cada passo de tempo:\n%%time for n in range(t.size - 1): for i in range(1, x.size - 1): for j in range(1, y.size - 1): T[i, j, n + 1] = T[i, j, n] + alpha * dt * ( (T[i - 1, j, n] - 2. * T[i, j, n] + T[i + 1, j, n]) / dx2 + (T[i, j - 1, n] - 2. * T[i, j, n] + T[i, j + 1, n]) / dy2) # Condições de contorno T[0, :, n + 1], T[-1, :, n + 1], T[:, 0, n + 1], T[:, -1, n + 1] = Tx0, Txn, Ty0, Tyn  Wall time: 921 ms  E então graficamos o resultado:\nminha_figura(T, x, y)  Note que no tempo nós já conhecemos a solução para n=0, então calculamos o laço temporal t.size-1 vezes. De maneira similar, a temperatura é conhecida em todas as paredes, então não precisamos resolver a equação nos contornos, e assim, cada laço temporal exclui a primeira e a última posição (range(1,x.size-1), por exemplo).\nEmbora o bloco de código acima resolva o problema, essa não é uma boa abordagem do ponto de vista do tempo necessário para o cálculo, ao realizar sequencialmente cada uma das operações por meio do aninhamento de laços.\nSobre NumPy, além do suporte para arranjos multi-dimensionais, toda a biblioteca é programada em C. Temos o desempenho de uma linguagem compilada (C), dentro de um ambiente de linguagem interpretada (Python), o melhor de dois mundos. Para tirar proveito disso, o ideal é realizar as operações vetorialmente ao resolver o problema em fatias (mais informações aqui), de modo que podemos reescrever o código como:\n%%time for n in range(t.size-1): T[1:-1,1:-1,n+1] = T[1:-1,1:-1,n] + dt * alpha * ( (T[ :-2,1:-1,n] - 2. * T[1:-1,1:-1,n] + T[2: ,1:-1,n]) / dx2 + (T[1:-1, :-2,n] - 2. * T[1:-1,1:-1,n] + T[1:-1,2: ,n]) / dy2 ) # Condições de contorno T[0,:,n+1], T[-1,:,n+1], T[:,0,n+1], T[:,-1,n+1] = Tx0, Txn, Ty0, Tyn  Wall time: 21 ms  Vemos os resultados novamente com:\nminha_figura(T, x, y)  Temos exatamente a mesma resposta para um tempo de cálculo inferior. Bem, esse ganho de desempenho depende das características da sua máquina e do problema, talvez podem nem ser perceptíveis quando usamos apenas 21 pontos em cada direção espacial, mas experimente aumentar esses valores.\nUma terceira alternativa com NumPy é deixar com que suas funções embarcadas façam parte do trabalho, o pacote conta com diversos recursos para derivação, integração, interpolação, trigonometria e muitos outros.\nVale destacar que no momento não conheço nenhuma função NumPy que calcule a derivada segunda em um arranjo. De qualquer maneira, se admitirmos que a derivada segunda pode ser aproximada com a aplicação dupla da derivada primeira (lembre-se que embora analiticamente sejam equivalentes, numericamente isso nem sempre é verdade), podemos usar a função np.gradient para reescrever nosso código na forma:\n%%timeit for n in range(t.size-1): T[:,:,n+1] = T[:,:,n] + dt * alpha * ( np.gradient(np.gradient(T[:,:,n], x, axis=0), x, axis=0) + np.gradient(np.gradient(T[:,:,n], y, axis=1), y, axis=1) ) # Condições de contorno T[0,:,n+1], T[-1,:,n+1], T[:,0,n+1], T[:,-1,n+1] = Tx0, Txn, Ty0, Tyn  221 ms ± 43.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)  A figura dos resultados mais uma vez:\nminha_figura(T, x, y)  Essa abordagem pode não ser tão precisa quanto as que vimos anteriormente, mas a descrição de como implementar operadores diferenciais será assunto para um outro dia. Por outro lado, se ainda assim e erro está em uma faixa tolerável para a sua aplicação, essa pode ser uma alternativa pela facilidade de aplicação e boa legibilidade do código. Como qualquer outro arranjo NumPy, devemos lembrar de que definimos a temperatura na ordem [x, y e t], e assim, axis=0 resultará no gradiente na direção x, enquanto axis=1 será o gradiente em y.\n Xarray Uma vez realizada a contextualização, vamos agora abordar a transferência de calor transiente bidimensional com Xarray, um pacote para estruturas de dados rotulados N-dimensionais (também denominados tensores). A sua vantagem é permitir realizar operações empregando o nome das coordenadas em vez da sua numeração (dim='x' em vez de axis=0), além de armazenar atributos como o nome e unidade das diversas variáveis.\nO ganho imediato em usar Xarray é que escrevemos menos código. A longo prazo o ganho é a legibilidade, podemos entender o que estávamos pensando ao retomar para um código semanas ou meses depois.\nPara exemplificar, vamos iniciar criando um Dataset para armazenar as informações do nosso problema. Existem diversos modos para isso, e uma leitura na documentação oficial é recomendada. Com o seguinte bloco de código, inicializamos nosso sistema de coordenadas:\ndata = xr.Dataset(coords={ 'x': np.linspace(start = 0., stop = 0.5, num = 21, endpoint = True), 'y': np.linspace(start = 0., stop = 0.5, num = 21, endpoint = True), 't': np.linspace(start = 0., stop = 600., num = 601, endpoint = True) })  Ao contrário do exemplo anterior em Numpy onde tínhamos as três variáveis (x, y e t), aqui toda a informação está consolidada em uma única estrutura, que denominamos data. O acesso específico a cada uma delas ocorre de maneira similar a notação dos dicionários em Python, isso é, data['x'], ou ainda de maneira mais condensada como data.x, por exemplo.\nVamos adicionar atributos às nossas coordenadas para facilitar o entendimento do código, além disso, veremos que os atributos são automaticamente incluídos nas figuras, diminuindo nosso trabalho futuro. Aqui incluimos as unidades e denominamos t como tempo:\ndata.x.attrs['units'] = 'm' data.y.attrs['units'] = 'm' data.t.attrs['units'] = 's' data.t.attrs['name'] = 'tempo'  Agora definimos a temperatura como um arranjo tridimensional (x, y e tempo) e também incluimos os atributos para referência:\ndata['T'] = xr.DataArray(0., coords=[data.x, data.y, data.t]) data.T.attrs['units'] = '°C' data.T.attrs['name'] = 'Temperatura'  E as propriedades do material:\ndata['alpha'] = 1.407e-5 data.alpha.attrs['units'] = r'm$^2$/s' data.alpha.attrs['name'] = 'Difusividade térmica'  Em um ambiente Jupyter Notebook interativo, visualizamos facilmente todo o conteúdo e atributos da nossa estrutura de dados ao imprimi-la na tela:\ndata              /* CSS stylesheet for displaying xarray objects in jupyterlab. * */ :root { \u0026ndash;xr-font-color0: var(\u0026ndash;jp-content-font-color0, rgba(0, 0, 0, 1)); \u0026ndash;xr-font-color2: var(\u0026ndash;jp-content-font-color2, rgba(0, 0, 0, 0.54)); \u0026ndash;xr-font-color3: var(\u0026ndash;jp-content-font-color3, rgba(0, 0, 0, 0.38)); \u0026ndash;xr-border-color: var(\u0026ndash;jp-border-color2, #e0e0e0); \u0026ndash;xr-disabled-color: var(\u0026ndash;jp-layout-color3, #bdbdbd); \u0026ndash;xr-background-color: var(\u0026ndash;jp-layout-color0, white); \u0026ndash;xr-background-color-row-even: var(\u0026ndash;jp-layout-color1, white); \u0026ndash;xr-background-color-row-odd: var(\u0026ndash;jp-layout-color2, #eeeeee); }\nhtml[theme=dark], body.vscode-dark { \u0026ndash;xr-font-color0: rgba(255, 255, 255, 1); \u0026ndash;xr-font-color2: rgba(255, 255, 255, 0.54); \u0026ndash;xr-font-color3: rgba(255, 255, 255, 0.38); \u0026ndash;xr-border-color: #1F1F1F; \u0026ndash;xr-disabled-color: #515151; \u0026ndash;xr-background-color: #111111; \u0026ndash;xr-background-color-row-even: #111111; \u0026ndash;xr-background-color-row-odd: #313131; }\n.xr-wrap { display: block; min-width: 300px; max-width: 700px; }\n.xr-text-repr-fallback { /* fallback to plain text repr when CSS is not injected (untrusted notebook) */ display: none; }\n.xr-header { padding-top: 6px; padding-bottom: 6px; margin-bottom: 4px; border-bottom: solid 1px var(\u0026ndash;xr-border-color); }\n.xr-header \u0026gt; div, .xr-header \u0026gt; ul { display: inline; margin-top: 0; margin-bottom: 0; }\n.xr-obj-type, .xr-array-name { margin-left: 2px; margin-right: 10px; }\n.xr-obj-type { color: var(\u0026ndash;xr-font-color2); }\n.xr-sections { padding-left: 0 !important; display: grid; grid-template-columns: 150px auto auto 1fr 20px 20px; }\n.xr-section-item { display: contents; }\n.xr-section-item input { display: none; }\n.xr-section-item input + label { color: var(\u0026ndash;xr-disabled-color); }\n.xr-section-item input:enabled + label { cursor: pointer; color: var(\u0026ndash;xr-font-color2); }\n.xr-section-item input:enabled + label:hover { color: var(\u0026ndash;xr-font-color0); }\n.xr-section-summary { grid-column: 1; color: var(\u0026ndash;xr-font-color2); font-weight: 500; }\n.xr-section-summary \u0026gt; span { display: inline-block; padding-left: 0.5em; }\n.xr-section-summary-in:disabled + label { color: var(\u0026ndash;xr-font-color2); }\n.xr-section-summary-in + label:before { display: inline-block; content: \u0026lsquo;►\u0026rsquo;; font-size: 11px; width: 15px; text-align: center; }\n.xr-section-summary-in:disabled + label:before { color: var(\u0026ndash;xr-disabled-color); }\n.xr-section-summary-in:checked + label:before { content: \u0026lsquo;▼\u0026rsquo;; }\n.xr-section-summary-in:checked + label \u0026gt; span { display: none; }\n.xr-section-summary, .xr-section-inline-details { padding-top: 4px; padding-bottom: 4px; }\n.xr-section-inline-details { grid-column: 2 / -1; }\n.xr-section-details { display: none; grid-column: 1 / -1; margin-bottom: 5px; }\n.xr-section-summary-in:checked ~ .xr-section-details { display: contents; }\n.xr-array-wrap { grid-column: 1 / -1; display: grid; grid-template-columns: 20px auto; }\n.xr-array-wrap \u0026gt; label { grid-column: 1; vertical-align: top; }\n.xr-preview { color: var(\u0026ndash;xr-font-color3); }\n.xr-array-preview, .xr-array-data { padding: 0 5px !important; grid-column: 2; }\n.xr-array-data, .xr-array-in:checked ~ .xr-array-preview { display: none; }\n.xr-array-in:checked ~ .xr-array-data, .xr-array-preview { display: inline-block; }\n.xr-dim-list { display: inline-block !important; list-style: none; padding: 0 !important; margin: 0; }\n.xr-dim-list li { display: inline-block; padding: 0; margin: 0; }\n.xr-dim-list:before { content: \u0026lsquo;('; }\n.xr-dim-list:after { content: \u0026lsquo;)'; }\n.xr-dim-list li:not(:last-child):after { content: \u0026lsquo;,'; padding-right: 5px; }\n.xr-has-index { font-weight: bold; }\n.xr-var-list, .xr-var-item { display: contents; }\n.xr-var-item \u0026gt; div, .xr-var-item label, .xr-var-item \u0026gt; .xr-var-name span { background-color: var(\u0026ndash;xr-background-color-row-even); margin-bottom: 0; }\n.xr-var-item \u0026gt; .xr-var-name:hover span { padding-right: 5px; }\n.xr-var-list \u0026gt; li:nth-child(odd) \u0026gt; div, .xr-var-list \u0026gt; li:nth-child(odd) \u0026gt; label, .xr-var-list \u0026gt; li:nth-child(odd) \u0026gt; .xr-var-name span { background-color: var(\u0026ndash;xr-background-color-row-odd); }\n.xr-var-name { grid-column: 1; }\n.xr-var-dims { grid-column: 2; }\n.xr-var-dtype { grid-column: 3; text-align: right; color: var(\u0026ndash;xr-font-color2); }\n.xr-var-preview { grid-column: 4; }\n.xr-var-name, .xr-var-dims, .xr-var-dtype, .xr-preview, .xr-attrs dt { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; padding-right: 10px; }\n.xr-var-name:hover, .xr-var-dims:hover, .xr-var-dtype:hover, .xr-attrs dt:hover { overflow: visible; width: auto; z-index: 1; }\n.xr-var-attrs, .xr-var-data { display: none; background-color: var(\u0026ndash;xr-background-color) !important; padding-bottom: 5px !important; }\n.xr-var-attrs-in:checked ~ .xr-var-attrs, .xr-var-data-in:checked ~ .xr-var-data { display: block; }\n.xr-var-data \u0026gt; table { float: right; }\n.xr-var-name span, .xr-var-data, .xr-attrs { padding-left: 25px !important; }\n.xr-attrs, .xr-var-attrs, .xr-var-data { grid-column: 1 / -1; }\ndl.xr-attrs { padding: 0; margin: 0; display: grid; grid-template-columns: 125px auto; }\n.xr-attrs dt, dd { padding: 0; margin: 0; float: left; padding-right: 10px; width: auto; }\n.xr-attrs dt { font-weight: normal; grid-column: 1; }\n.xr-attrs dt:hover span { display: inline-block; background: var(\u0026ndash;xr-background-color); padding-right: 10px; }\n.xr-attrs dd { grid-column: 2; white-space: pre-wrap; word-break: break-all; }\n.xr-icon-database, .xr-icon-file-text2 { display: inline-block; vertical-align: middle; width: 1em; height: 1.5em !important; stroke-width: 0; stroke: currentColor; fill: currentColor; } \u0026lt;xarray.Dataset\u0026gt; Dimensions: (t: 601, x: 21, y: 21) Coordinates:\n  x (x) float64 0.0 0.025 0.05 0.075 0.1 \u0026hellip; 0.4 0.425 0.45 0.475 0.5\n  y (y) float64 0.0 0.025 0.05 0.075 0.1 \u0026hellip; 0.4 0.425 0.45 0.475 0.5\n  t (t) float64 0.0 1.0 2.0 3.0 4.0 \u0026hellip; 596.0 597.0 598.0 599.0 600.0 Data variables: T (x, y, t) float64 0.0 0.0 0.0 0.0 0.0 0.0 \u0026hellip; 0.0 0.0 0.0 0.0 0.0 alpha float64 1.407e-05xarray.DatasetDimensions:t: 601x: 21y: 21Coordinates: (3)x(x)float640.0 0.025 0.05 \u0026hellip; 0.45 0.475 0.5units :marray([0. , 0.025, 0.05 , 0.075, 0.1 , 0.125, 0.15 , 0.175, 0.2 , 0.225, 0.25 , 0.275, 0.3 , 0.325, 0.35 , 0.375, 0.4 , 0.425, 0.45 , 0.475, 0.5 ])y(y)float640.0 0.025 0.05 \u0026hellip; 0.45 0.475 0.5units :marray([0. , 0.025, 0.05 , 0.075, 0.1 , 0.125, 0.15 , 0.175, 0.2 , 0.225, 0.25 , 0.275, 0.3 , 0.325, 0.35 , 0.375, 0.4 , 0.425, 0.45 , 0.475, 0.5 ])t(t)float640.0 1.0 2.0 \u0026hellip; 598.0 599.0 600.0units :sname :tempoarray([ 0., 1., 2., \u0026hellip;, 598., 599., 600.])Data variables: (2)T(x, y, t)float640.0 0.0 0.0 0.0 \u0026hellip; 0.0 0.0 0.0 0.0units :°Cname :Temperaturaarray([[[0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], \u0026hellip;, [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.]],\n[[0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], \u0026hellip;, [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.]],\n[[0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], \u0026hellip;, \u0026hellip; \u0026hellip;, [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.]],\n[[0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], \u0026hellip;, [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.]],\n[[0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], \u0026hellip;, [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.], [0., 0., 0., \u0026hellip;, 0., 0., 0.]]])alpha()float641.407e-05units :m$^2$/sname :Difusividade térmicaarray(1.407e-05)Attributes: (0)\n  Existe uma série de métodos para selecionar dados dentro dos nossos arranjos (mais informações aqui), uma delas é por meio de dicionários. Por exemplo, para impor a condição inicial na temperatura podemos usar o dicionário {'t' : 0}, ou a notação equivalente dict(t=0). De maneira análoga, iremos impor as condições de contorno, como vemos:\n# Condição Inicial data.T[dict(t=0)] = T0 # Condições de Contorno data.T[dict(t=0,x=0)] = (Td - Ta) / (data.y[-1] - data.y[0]) * data.y + Ta data.T[dict(t=0,x=-1)] = (Tb - Tc) / (data.y[-1] - data.y[0]) * data.y + Tc data.T[dict(t=0,y=0)] = (Tc - Ta) / (data.x[-1] - data.x[0]) * data.x + Ta data.T[dict(t=0,y=-1)] = (Tb - Td) / (data.x[-1] - data.x[0]) * data.x + Td  Se novamente admitirmos que a derivada segunda pode ser aproximada com a aplicação dupla da derivada primeira, resolvemos o problema com o seguinte bloco de código:\n%%time for n in range(data.t.size - 1): dt = data.t[n+1] - data.t[n] # Equação Governate data.T[dict(t=n+1)] = data.T.isel(t=n) + dt * data.alpha * ( data.T.isel(t=n).differentiate('x').differentiate('x') + data.T.isel(t=n).differentiate('y').differentiate('y') ) # Condições de Contorno data.T[dict(t=n+1,x=0)] = data.T.isel(t=0,x=0) data.T[dict(t=n+1,x=-1)] = data.T.isel(t=0,x=-1) data.T[dict(t=n+1,y=0)] = data.T.isel(t=0,y=0) data.T[dict(t=n+1,y=-1)] = data.T.isel(t=0,y=-1)  Wall time: 5.2 s  Note a diferença visual em relação ao nosso exemplo anterior em NumPy, onde sempre temos que lembrar da ordem de definição dos eixos para manipular os dados, como np.gradient(T[:,:,n], x, axis=0) para derivação da temperatura no tempo n em relação a x, com Xarray usamos simplesmente data.T.isel(t=n).differentiate('x').\nOutra vantagem de usar Xarray, o pacote oferece uma série de funcionalidades gráficas, construídas sobre Matplotlib (mais informações aqui), de modo que com poucas linhas de código podemos:\n# Graficar a evolução temporal da temperatura no centro da placa data.T.isel(x=data.x.size//2, y=data.y.size//2).plot.line();  # Variação com x e t para y fixo data.T.isel(t=slice(None,None,120), y=data.y.size//2).plot.line(x='x');  # Variação com y e t para x fixo data.T.isel(t=slice(None,None,120), x=data.x.size//2).plot.line(x='y');  # E aqui temos a completa variação espaço-temporal data.T.sel(t=slice(None,None,40)).T.plot.contourf( col='t', col_wrap=4, aspect = 1, cmap='bone', levels = 32 );   Conclusão Com esse estudo de caso, demonstrou-se como resolver a condução de calor em placa plana bidimensional transiente empregando dois diferentes pacotes para manipulação de arranjos, NumPy e Xarray. Vimos como o primeiro funciona baseado na numeração dos diferentes eixos de coordenadas axis=0, enquanto o segundo utiliza rótulos dim='x', em uma apresentação muito mais intuitiva e visual. Certamente, cada abordagem tem seus pontos fortes e fracos, e a escolha de uma ou outra depende do tipo de aplicação em questão e da preferência do próprio programador.\n","date":1591315200,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"f03c83fafdfb39ba236b6fd43d17c6bd","permalink":"https://www.fschuch.com/blog/2020/06/05/conducao-de-calor-transiente-bidimensional/","publishdate":"2020-06-05T00:00:00Z","relpermalink":"/blog/2020/06/05/conducao-de-calor-transiente-bidimensional/","section":"post","summary":"Este post apresenta a resolução do problema de transferência de calor transiente em uma placa bidimensional por meio do método das diferenças finitas, incluindo a discretização da equação governante e duas abordagens distintas para o gerenciamento de dados em Python (NumPy e Xarray).","tags":["Transferência de Calor","Diferenças Finitas","Métodos Numéricos","Xarray","Numpy","Matplotlib","Python"],"title":"Condução de Calor Transiente Bidimensional","type":"post"},{"authors":null,"categories":null,"content":"Lista de Conteúdos  Introdução Obtenção e manipulação dos dados Visualização    Introdução A análise de dados históricos do mercado financeiro pode ser prática para diversos fins, como estudos acadêmicos, gerenciamento de portfólio, criação de conteúdo e outros.\nBoa parte dos materiais por aí são baseados naqueles famosos aplicativos de planilha, nada contra, mas eu gosto mesmo de resolver os problemas propostos usando Python. Para isso, vamos usar dois pacotes:\n  yfinance oferece uma alternativa em Python para baixar dados históricos do mercado financeiro a partir do Yahoo! finanças;\n  mplfinance é uma utilidade construída sobre Matplotlib, que oferece visualização e análise para dados financeiros.\n   Lembre-se sempre que lucros passados não são garantia de lucros futuros, e que esse post não é uma recomendação de compra.   O primeiro passo é instalar os pacotes que usaremos, e isso pode ser feito no ambiente Jupyter (como esse post) com o seguinte comando mágico:\n!pip install -q yfinance mplfinance  E então importamos ambos para a nossa aplicação:\nimport yfinance as yf import mplfinance as mpf   Obtenção e manipulação dos dados O módulo Ticker nos permite o acesso a diversos dados de maneira integrada ao Python, e apenas para exemplificar, usaremos a Microsoft, código de negociação MSFT:\nmsft = yf.Ticker(\u0026quot;MSFT\u0026quot;)  Informações completas da companhia são obtidos com o método info, como segue:\nmsft.info  {'zip': '98052-6399', 'sector': 'Technology', 'fullTimeEmployees': 163000, 'longBusinessSummary': 'Microsoft Corporation develops, licenses, and supports software, services, devices, and solutions worldwide. Its Productivity and Business Processes segment offers Office, Exchange, SharePoint, Microsoft Teams, Office 365 Security and Compliance, and Skype for Business, as well as related Client Access Licenses (CAL); Skype, Outlook.com, and OneDrive; LinkedIn that includes Talent, Learning, Sales, and Marketing solutions, as well as premium subscriptions; and Dynamics 365, a set of cloud-based and on-premises business solutions for small and medium businesses, large organizations, and divisions of enterprises. Its Intelligent Cloud segment licenses SQL and Windows Servers, Visual Studio, System Center, and related CALs; GitHub that provides a collaboration platform and code hosting service for developers; and Azure, a cloud platform. It also offers support services and Microsoft consulting services to assist customers in developing, deploying, and managing Microsoft server and desktop solutions; and training and certification to developers and IT professionals on various Microsoft products. Its More Personal Computing segment provides Windows original equipment manufacturer (OEM) licensing and other non-volume licensing of the Windows operating system; Windows Commercial, such as volume licensing of the Windows operating system, Windows cloud services, and other Windows commercial offerings; patent licensing; Windows Internet of Things; and MSN advertising. It also offers Surface, PC accessories, PCs, tablets, gaming and entertainment consoles, and other intelligent devices; Gaming, including Xbox hardware, and Xbox content and services; video games and third-party video game royalties; and Search, including Bing and Microsoft advertising. It sells its products through OEMs, distributors, and resellers; and directly through digital marketplaces, online stores, and retail stores. The company was founded in 1975 and is headquartered in Redmond, Washington.', 'city': 'Redmond', 'phone': '425-882-8080', 'state': 'WA', 'country': 'United States', 'companyOfficers': [], 'website': 'http://www.microsoft.com', 'maxAge': 1, 'address1': 'One Microsoft Way', 'industry': 'Software—Infrastructure', 'previousClose': 219.66, 'regularMarketOpen': 220.15, 'twoHundredDayAverage': 196.80064, 'trailingAnnualDividendYield': 0.00928708, 'payoutRatio': 0.3455, 'volume24Hr': None, 'regularMarketDayHigh': 222.29, 'navPrice': None, 'averageDailyVolume10Day': 27025187, 'totalAssets': None, 'regularMarketPreviousClose': 219.66, 'fiftyDayAverage': 212.05457, 'trailingAnnualDividendRate': 2.04, 'open': 220.15, 'toCurrency': None, 'averageVolume10days': 27025187, 'expireDate': None, 'yield': None, 'algorithm': None, 'dividendRate': 2.24, 'exDividendDate': 1605657600, 'beta': 0.923331, 'circulatingSupply': None, 'startDate': None, 'regularMarketDayLow': 219.33, 'priceHint': 2, 'currency': 'USD', 'trailingPE': 38.135414, 'regularMarketVolume': 25074770, 'lastMarket': None, 'maxSupply': None, 'openInterest': None, 'marketCap': 1662310023168, 'volumeAllCurrencies': None, 'strikePrice': None, 'averageVolume': 33866804, 'priceToSalesTrailing12Months': 11.623326, 'dayLow': 219.33, 'ask': 219, 'ytdReturn': None, 'askSize': 1000, 'volume': 25074770, 'fiftyTwoWeekHigh': 232.86, 'forwardPE': 29.967258, 'fromCurrency': None, 'fiveYearAvgDividendYield': 1.8, 'fiftyTwoWeekLow': 132.52, 'bid': 219, 'tradeable': False, 'dividendYield': 0.010199999, 'bidSize': 1300, 'dayHigh': 222.29, 'exchange': 'NMS', 'shortName': 'Microsoft Corporation', 'longName': 'Microsoft Corporation', 'exchangeTimezoneName': 'America/New_York', 'exchangeTimezoneShortName': 'EDT', 'isEsgPopulated': False, 'gmtOffSetMilliseconds': '-14400000', 'quoteType': 'EQUITY', 'symbol': 'MSFT', 'messageBoardId': 'finmb_21835', 'market': 'us_market', 'annualHoldingsTurnover': None, 'enterpriseToRevenue': 11.243, 'beta3Year': None, 'profitMargins': 0.30962, 'enterpriseToEbitda': 24.639, '52WeekChange': 0.59857357, 'morningStarRiskRating': None, 'forwardEps': 7.33, 'revenueQuarterlyGrowth': None, 'sharesOutstanding': 7567649792, 'fundInceptionDate': None, 'annualReportExpenseRatio': None, 'bookValue': 15.626, 'sharesShort': 39634230, 'sharesPercentSharesOut': 0.0052, 'fundFamily': None, 'lastFiscalYearEnd': 1593475200, 'heldPercentInstitutions': 0.74093, 'netIncomeToCommon': 44280999936, 'trailingEps': 5.76, 'lastDividendValue': 0.51, 'SandP52WeekChange': 0.16647923, 'priceToBook': 14.057341, 'heldPercentInsiders': 0.014249999, 'nextFiscalYearEnd': 1656547200, 'mostRecentQuarter': 1593475200, 'shortRatio': 1.09, 'sharesShortPreviousMonthDate': 1598832000, 'floatShares': 7455727348, 'enterpriseValue': 1607928643584, 'threeYearAverageReturn': None, 'lastSplitDate': 1045526400, 'lastSplitFactor': '2:1', 'legalType': None, 'lastDividendDate': 1597795200, 'morningStarOverallRating': None, 'earningsQuarterlyGrowth': -0.151, 'dateShortInterest': 1601424000, 'pegRatio': 2.29, 'lastCapGain': None, 'shortPercentOfFloat': 0.0053, 'sharesShortPriorMonth': 36458662, 'category': None, 'fiveYearAverageReturn': None, 'regularMarketPrice': 220.15, 'logo_url': 'https://logo.clearbit.com/microsoft.com'}  Pode-se obter informações sobre os principais acionistas:\nmsft.major_holders   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  0 1     0 1.42% % of Shares Held by All Insider   1 74.09% % of Shares Held by Institutions   2 75.16% % of Float Held by Institutions   3 4630 Number of Institutions Holding Shares     msft.institutional_holders   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Holder Shares Date Reported % Out Value     0 Vanguard Group, Inc. (The) 632013255 2020-06-29 0.0835 128621017525   1 Blackrock Inc. 521841633 2020-06-29 0.0690 106199990731   2 State Street Corporation 314554694 2020-06-29 0.0416 64015025775   3 FMR, LLC 236873992 2020-06-29 0.0313 48206226111   4 Price (T.Rowe) Associates Inc 183090016 2020-06-29 0.0242 37260649156   5 Capital World Investors 122923512 2020-06-29 0.0162 25016163927   6 Geode Capital Management, LLC 116688974 2020-06-29 0.0154 23747373098   7 Capital International Investors 98209725 2020-06-29 0.0130 19986661134   8 Capital Research Global Investors 94081197 2020-06-29 0.0124 19146464401   9 Northern Trust Corporation 93331898 2020-06-29 0.0123 18993974561     Os dados históricos são obtidos com o método history(), que aceita como argumentos o período desejado, ou datas de início e fim, e retorna um Pandas DataFrame que contém os preços de abertura e fechamento do mercado, além de máximas e mínimas, o volume de negociação, informações sobre dividendos pagos e desdobramentos.\ndata = msft.history(period=\u0026quot;max\u0026quot;)  E assim, temos a disposição todos os métodos inerentes do Pandas, como head(), que nos mostra a parte superior da tabela de dados:\ndata.head()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Open High Low Close Volume Dividends Stock Splits   Date            1986-03-13 0.06 0.06 0.06 0.06 1031788800 0.0 0.0   1986-03-14 0.06 0.07 0.06 0.06 308160000 0.0 0.0   1986-03-17 0.06 0.07 0.06 0.07 133171200 0.0 0.0   1986-03-18 0.07 0.07 0.06 0.06 67766400 0.0 0.0   1986-03-19 0.06 0.06 0.06 0.06 47894400 0.0 0.0     Ou tail(), que mostra a parte inferior:\ndata.tail()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Open High Low Close Volume Dividends Stock Splits   Date            2020-10-12 218.79 223.86 216.81 221.40 40461400 0.0 0.0   2020-10-13 222.72 225.21 220.43 222.86 28950800 0.0 0.0   2020-10-14 223.00 224.22 219.13 220.86 23451700 0.0 0.0   2020-10-15 217.10 220.36 216.01 219.66 22718400 0.0 0.0   2020-10-16 220.15 222.29 219.33 219.66 25074770 0.0 0.0     Podemos facilmente produzir um gráfico com o método plot(), conforme segue:\ndata.plot();  Essa figura ficou meio poluída visualmente, vamos nos concentrar apenas no preço de fechamento, e acrescentar algumas opções extras:\n# Acessamos apenas o preço de fechamento, plotamos com log no eixo y, # porque é mais representativo, adicionamos um título à figura data.Close.plot(logy=True, title=msft.info['symbol']) # Aqui adicionamos médias móveis, porque não? # mav vem do inglês para moving average for mav in [500, 1000, 2000]: data.Close.rolling(mav).mean().plot(label=f'mav {mav}') plt.legend();  Podemos também calcular e graficar a variação percentual diária do preço como:\ndata['Var [%]'] = 100. * (data.Close - data.Open) / data.Open data['Var [%]'].plot();  Que pode ser exibida como um histograma de frequências:\ndata['Var [%]'].plot.hist(bins=100);  Temos ainda o método actions() que retorna dados históricos sobre dividendos e desdobramento das ações, e perceba que ele pode ser encadeado com o método plot(), para múltiplas operações em uma única linha de código:\nmsft.actions.plot();  O método describe() é particularmente útil para ter uma rápida representação de uma grande quantidade de dados, fornecendo a contagem, média, desvio padrão, valor mínimo, máximo e outros.\ndata.describe()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Open High Low Close Volume Dividends Stock Splits Var [%]     count 8722.000000 8722.000000 8722.000000 8722.000000 8.722000e+03 8722.000000 8722.000000 8722.000000   mean 26.930644 27.217296 26.637444 26.937902 6.000501e+07 0.002196 0.001949 0.067909   std 37.001413 37.388700 36.589514 37.016185 3.867451e+07 0.040982 0.061015 2.052796   min 0.060000 0.060000 0.060000 0.060000 2.304000e+06 0.000000 0.000000 -25.925926   25% 2.360000 2.380000 2.330000 2.362500 3.617535e+07 0.000000 0.000000 -0.781170   50% 18.595000 18.805000 18.360000 18.590000 5.316930e+07 0.000000 0.000000 0.000000   75% 26.267500 26.487500 25.925000 26.225000 7.371192e+07 0.000000 0.000000 0.889940   max 229.270000 232.860000 227.350000 231.650000 1.031789e+09 3.080000 2.000000 16.666667     Esse foi nosso exemplo, informações complementares podem ser encontradas no post do autor original do pacote yfinance. Experimente executar os exemplos propostos para outros códigos de negociação, por exemplo com o índice S\u0026amp;P 500 com o ticker ^GSPC, o índice Ibovespa com o ticker ^BVSP, ou empresas brasileiras, como o ticker ITUB3.SA, e muitos outros.\n Visualização A representação gráfica de dados financeiros é mais usual pelo método Candlestick, onde exibe-se os preços de abertura, fechamento, máximo e mínimo de maneira mais compreensiva.\nVamos mudar os dados empregados apenas para ter um segundo exemplo da utilização do yfinance, agora especificando uma data de início e fim para a série histórica, e agrupando os resultados no período de uma semana.\ndata = yf.Ticker('^BVSP').history(start='2019-01-01', end='2019-12-31', interval='1wk')  E agora com mplfinance e apenas uma linha de código, temos a nossa figura:\nmpf.plot(data, type='candle', mav=(5,10), volume=True, show_nontrading=True, style='yahoo', title='Ibovespa, 2019');  Bem mais limpa visualmente do que a nossa primeira tentativa, não é mesmo? Perceba que o método aceita diferentes tipos de gráfico, a inclusão de médias móveis (mav), o volume de negociações (pode mostrar, ou não), os dias em que não houveram pregão, e pode-se escolher o estilo do gráfico. Informações completas sobre o pacote mplfinance estão disponíveis no link.\n","date":1590019200,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"d8733dc8ff64f4929a7fb58067ef555e","permalink":"https://www.fschuch.com/blog/2020/05/21/obtencao-e-manipulacao-de-dados-historicos-do-mercado-financeiro/","publishdate":"2020-05-21T00:00:00Z","relpermalink":"/blog/2020/05/21/obtencao-e-manipulacao-de-dados-historicos-do-mercado-financeiro/","section":"post","summary":"Demonstra-se o uso do módulo yfinance para o acesso a dados históricos do mercado financeiro, bem como o módulo mplfinance, para a sua representação gráfica.","tags":["Matemática Financeira","Pandas","Matplotlib","Python"],"title":"Obtenção e manipulação de dados históricos do mercado financeiro","type":"post"},{"authors":null,"categories":null,"content":"PyOWM é uma biblioteca Python, projetada como um invólucro cliente para a API web do OpenWeatherMap (OWM). Permite o consumo rápido e fácil dos dados OWM para aplicações Python por meio de um modelo de objeto simples e de maneira amigável ao usuário humano.\nA biblioteca está disponível no GitHub, onde pode-se obter maiores informações.\nO primeiro passo para sua utilização é a instalação, que pode ser feita no ambiente Jupyter Notebook (como esse post) com um comando mágico, com a seguinte linha de código:\n!pip install -q pyowm  A seguir, importamos a biblioteca:\nimport pyowm  Note que o provedor de dados climáticos é grátis, mas requer uma chave de acesso. Para tanto, um rápido registro é necessário na página do OWM.\nUma vez que se tenha a chave, informamos ela ao programa:\nowm = pyowm.OWM('sua-chave-aqui') # Tem uma assinatura Pro? Nesse caso use: # owm = pyowm.OWM(API_key='sua-chave-aqui', subscription_type='pro')  Podemos fazer uma observação informando o local pretendido, por exemplo:\nobservation = owm.weather_at_place('Porto Alegre,BR')  E então obtemos a previsão do tempo:\nw = observation.get_weather()  Para imprimir na tela:\nw  \u0026lt;pyowm.weatherapi25.weather.Weather - reference time=2020-04-23 20:57:39+00, status=clear, detailed status=clear sky\u0026gt;  O último passo do exemplo é observar os resultados obtidos:\n# Informação sobre o vento w.get_wind()  {'deg': 130, 'speed': 5.1}  # Umidade relativa do ar w.get_humidity()  44  # E temperatura w.get_temperature('celsius')  {'temp': 25.67, 'temp_kf': None, 'temp_max': 27.0, 'temp_min': 24.44}  Confira a documentação oficial da biblioteca se precisar de qualquer informação adicional.\n","date":15876e5,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"5d6c65c8ea64dca443094fd8f60786d6","permalink":"https://www.fschuch.com/blog/2020/04/23/obtencao-da-previsao-do-tempo-com-o-pacote-pyowm/","publishdate":"2020-04-23T00:00:00Z","relpermalink":"/blog/2020/04/23/obtencao-da-previsao-do-tempo-com-o-pacote-pyowm/","section":"post","summary":"PyOWM é um invólucro em Python para a API web de previsão do tempo OpenWeatherMap.","tags":["Python"],"title":"Obtenção da previsão do tempo com o pacote PyOWM","type":"post"},{"authors":null,"categories":null,"content":"O pacote cyberpunk incrementa o estilo visual dos gráficos em Python com apenas 3 linhas adicionais de código. Ele foi construído sobre matplotlib por Dominik Haitz, e está disponível no GitHub.\nO primeiro passo para sua utilização é a instalação, que pode ser feita no ambiente Jupyter Notebook (como esse post) com um comando mágico, com a seguinte linha de código:\n!pip install -q mplcyberpunk  A seguir, importamos os pacotes:\nimport matplotlib.pyplot as plt import numpy as np import mplcyberpunk  Vamos criar uma função auxiliar para produzir o mesmo gráfico em diferentes configurações:\ndef graficar(): plt.plot([1, 3, 9, 5, 2, 1, 1], marker='o') plt.plot([4, 5, 5, 7, 9, 8, 6], marker='o')  Primeiro apresentamos a figura com as definições padrões matplotlib:\ngraficar()  Agora mudamos o estilo para cyberpunk e refazemos a mesma figura para comparação:\nplt.style.use(\u0026quot;cyberpunk\u0026quot;) graficar()  O próximo passo é adicionar o efeito de brilho com add_glow_effects, veja o código:\ngraficar() mplcyberpunk.add_glow_effects()  Note que atualmente esse efeito está disponível apenas para linhas. O passo a passo de sua implementação pode ser visto aqui.\nAmbos os efeitos de brilho podem ser controlados separadamente com as funções:\n make_lines_glow - para o brilho das próprias linhas; add_underglow - para a área sob as linhas.  Para exemplifica-los, vamos criar outra função gráfica:\ndef graficar2(): x = np.linspace(-5, 5, num=120) functions = { 'sen(x)' : np.sin(x), 'sen(x)+x' : np.sin(x)+x, 'sen(x)*x' : np.sin(x)*x, 'sen(x)/x' : np.sin(x)/x } for key, fun in functions.items(): plt.plot(x, fun, label=key) plt.legend()  E seguem os resultados:\ngraficar2() plt.title('Apenas o estilo gráfico Cyberpunk');  graficar2() mplcyberpunk.make_lines_glow() plt.title('Estilo + brilho das linhas');  graficar2() mplcyberpunk.make_lines_glow() mplcyberpunk.add_underglow() plt.title('Estilo + brilho das linhas e sob as linhas');  ","date":1586736e3,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"280001262c1dbbb74b40347d976b04a8","permalink":"https://www.fschuch.com/blog/2020/04/13/producao-de-graficos-para-matplotlib-usando-o-estilo-cyberpunk/","publishdate":"2020-04-13T00:00:00Z","relpermalink":"/blog/2020/04/13/producao-de-graficos-para-matplotlib-usando-o-estilo-cyberpunk/","section":"post","summary":"Com o objetivo de expor a capacidade de personalização de estilo das figuras em Matplotlib, neste post apresentamos o pacote *mplcyberpunk*.","tags":["Matplotlib","Python"],"title":"Produção de gráficos para Matplotlib usando o estilo Cyberpunk","type":"post"},{"authors":["Felipe N. Schuch","Mathias S. Tessmann"],"categories":null,"content":"Lista de Conteúdos  Introdução  Execute Online   Sistemas de Amortização Cenários  Financiar Alugar e Aportar Mensalmente Economizar e Comprar à Vista   Síntese dos Resultados    Introdução A matemática financeira é uma disciplina fundamental na atuação de profissionais de diversos setores e, adicionalmente, possui importante papel na gestão de recursos próprios e no gerenciamento do orçamento doméstico. É justamente nesse ponto que muitas pessoas têm seu primeiro contato com programação, e talvez nem se deem conta disso, ao utilizar alguma aplicação de manipulação de planilhas para controlar os gastos de casa. Verdade seja dita, planilhas são estruturas de dados muito úteis.\nEsta postagem trata de um estudo de cenários didáticos sobre a aquisição - ou não - de um imóvel. Ele cobre três situações:\n Comprar com uma entrada e financiamento; Alugar e investir mensalmente; Economizar e comprar à vista.  Para tanto, exemplifica-se como resolver o problema proposto com o emprego de duas importantes ferramentas:\n Pandas é um pacote Python que fornece estruturas de dados rápidas, flexíveis e expressivas, projetadas para tornar o trabalho com dados “relacionais” ou “rotulados” fáceis e intuitivos. O objetivo é ser o alicerce fundamental de alto nível para a análise prática de dados do mundo real em Python. Além disso, tem o objetivo mais amplo de se tornar a mais prestigiada e flexível ferramenta de análise / manipulação de dados de código aberto disponível em qualquer linguagem. Pandas é bem adequado para muitos tipos diferentes de dados:  Dados tabulares com colunas de tipos heterogêneos, como em uma tabela SQL, arquivo .csv ou planilha do Excel; Dados de séries temporais ordenados e não ordenados (não necessariamente de frequência fixa); Dados de matriz arbitrária (homogeneamente digitados ou heterogêneos) com rótulos de linha e coluna; Qualquer outra forma de conjuntos de dados observacionais / estatísticos. Os dados realmente não precisam ser rotulados para serem colocados em uma estrutura de dados de pandas.   Matplotlib é uma biblioteca de plotagem 2D do Python, que produz figuras de qualidade de publicação em uma variedade de formatos impressos e ambientes interativos entre plataformas. Matplotlib pode ser usado em scripts Python, nos shells do Python e do IPython, no notebook Jupyter, nos servidores de aplicativos da web e em quatro kits de ferramentas de interface gráfica do usuário. Matplotlib tenta tornar as coisas fáceis simples e as coisas difíceis possíveis. Você pode gerar gráficos, histogramas, espectros de potência, gráficos de barras, gráficos de erros, diagramas de dispersão, etc., com apenas algumas linhas de código.  # As primeiras linhas de código tratam de importar ambas bibliotecas import pandas as pd import matplotlib.pyplot as plt  Se reproduzir esse conteúdo em partes ou em sua totalidade, forneça um link para o material original:\n https://fschuch.com/blog/2020/04/11/alugar-economizar-e-pagar-a-vista-ou-financiar-um-imovel-um-estudo-de-caso  E por favor, apoie os nossos autores @fschuch e @mathiazst.\n Essa não é uma recomendação de compra. Lucros passados não são garantia de lucros futuros. Esse é um estudo de cenários didáticos e hipotéticos. Os autores se eximem completamente de qualquer responsabilidade sobre o uso, interpretação e consequências do uso direto ou indireto de qualquer informação contida nesse material.   Execute Online Você pode executar esse notebook em seu próprio navegador (nenhuma instalação é necessária), existem duas opções para isso:\n\n O login em uma conta Google pode ser necessário, modifique os blocos de código para os valores que você desejar, na barra de menu superior, procure por Runtime \u0026gt; Run All;  \n Aguarde enquanto o sistema é preparado (isso pode levar algum tempo), modifique os blocos de código para os valores que você desejar, na barra de menu superior, procure por Cell \u0026gt; Run All.  Pronto! Interprete os novos resultados obtidos.\n Sistemas de Amortização Quando falamos em sistemas de pagamento, ou sistema de amortização, existem quatro parâmetros fundamentais:\n  Tempo total \\(N\\);\n  Taxa de juros \\(i\\);\n  Saldo devedor inicial \\(SD_0\\);\n  Valor da parcela, que por sua vez é subdividido em:\n Amortização, valor que efetivamente abate parte do saldo devedor; Juros, valor pago como remuneração ao financiador,  onde observa-se que: \\[ \\text{Amortização} = \\text{Parcela} - \\text{Juros}. \\]\n  Pode-se citar pelo menos dois modelos clássicos que tratam dessa relação:\n  Sistema de Amortização Constante (SAC): Como o próprio nome sugere, a amortização é constante ao longo de todo o tempo: $$\\text{Amortização}_n = \\dfrac{SD_0}{N}$$ Os juros são obtidos ao multiplicar a taxa de juros pelo saldo devedor do período anterior: $$\\text{Juros}_n = i \\times SD _{n-1}$$ E como vimos, a parcela é a soma dos dois anteriores: $$\\text{Parcela}_n = \\text{Juros}_n + \\text{Amortização}_n.$$ Note que nesse sistema, o saldo devedor decresce linearmente, além disso, as prestações diminuem gradualmente com o passar do tempo.\n  Outra opção é a Tabela Price, ou sistema francês de amortização. Aqui, o valor das parcelas é constante no tempo, e obtido por meio de equação: $$\\text{Parcela} = SD_0 \\dfrac{i}{1-(1+i)^{-n}}.$$ Os juros são novamente obtidos por: $$\\text{Juros}_n = i \\times SD _{n-1}.$$ E por fim obtemos o valor da amortização de cada parcela como: $$\\text{Amortização}_n = \\text{Parcela}_n - \\text{Juros}_n.$$\n  Tendo tudo isso em vista, podemos construir uma rotina em Python que nos retorne um DataFrame em Pandas, que nada mais é do que uma tabela. Ele inclui os valores obtidos para juros, amortização, parcela e saldo devedor para cada período n, em função da escolha do sistema de pagamento (SAC ou Price), da taxa de juros i, do número de períodos de tempo N e do saldo devedor inicial SD0. Segue a função:\ndef sistema_pagamento(sis,i,N,SD0): ''' Calcula os juros, amortização, valor das parcelas e saldo devedor em função do sistema de amortização escolhido Args: sis (str): Sistema de amortização (SAC ou Price) i (float): Taxa de juros N (int): Períodos de tempo SD0 (float): Saldo devedor inicial Returns: df: DataFrame com as colunas juros, amortização, valor das parcelas e saldo devedor ''' df = pd.DataFrame(columns=['Juros', 'Amortização', 'Parcela', 'Saldo Devedor'], index=range(N+1) ) df['Saldo Devedor'][0] = SD0 if sis.lower() == 'sac': df['Amortização'][1:] = SD0/N for n in df.index[1:]: df['Juros'][n] = round(df['Saldo Devedor'][n-1]*i,2) df['Parcela'][n] = df['Juros'][n]+df['Amortização'][n] df['Saldo Devedor'][n] = df['Saldo Devedor'][n-1] - df['Amortização'][n] elif sis.lower() == 'price': df['Parcela'][1:] = round(SD0*(i)/(1-(1+i)**(-N)),2) for n in df.index[1:]: df['Juros'][n] = round(df['Saldo Devedor'][n-1]*i,2) df['Amortização'][n] = df['Parcela'][n] - df['Juros'][n] df['Saldo Devedor'][n] = df['Saldo Devedor'][n-1] - df['Amortização'][n] else: print('Valor inválido para sis, tente novamente com sac ou price') # Aqui ajustamos a última parcela caso tenha valor residual devido ao arredondamento df['Parcela'][N] += df['Saldo Devedor'][N] df['Saldo Devedor'][N] -= df['Saldo Devedor'][N] return df  Agora podemos ver um exemplo da função em ação para ambos os sistemas de pagamento, para um taxa de juros de 5%, 4 períodos de tempo e saldo devedor inicial de R$1.000:\nsistema_pagamento('sac',0.05,4,1000)      Juros Amortização Parcela Saldo Devedor     0 nan nan nan 1000   1 50 250 300 750   2 37.5 250 287.5 500   3 25 250 275 250   4 12.5 250 262.5 0    Note na tabela acima algumas posições marcadas com NaN, abreviação para não um número (do inglês para Not a Number). Eles ocorreram no nosso exemplo para o tempo 0, onde valores não foram informados para algumas colunas. O NaN não é necessariamente um problema, a biblioteca Pandas é justamente capaz de lidar com dados faltantes (mais detalhes aqui). Perceba que essas células podem ser definidos para qualquer valor desejado com o método fillna(), vamos utiliza-lo no segundo exemplo:\nsistema_pagamento('price',0.05,4,1000).fillna(0)      Juros Amortização Parcela Saldo Devedor     0 0 0 0 1000   1 50 232.01 282.01 767.99   2 38.4 243.61 282.01 524.38   3 26.22 255.79 282.01 268.59   4 13.43 268.58 282.02 0    Uma das vantagens de se trabalhar com dados tabulares é que eles podem ser facilmente transformados em gráfico, veja como fazemos isso com apenas algumas linhas de código:\nfig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True) sistema_pagamento('sac',0.05,30,1000).plot(ax=ax1,title='Sistema SAC') sistema_pagamento('price',0.05,30,1000).plot(ax=ax2,title='Tabela Price') ax2.set_xlabel('Tempo') ax1.set_ylabel('Valor - R$') ax2.set_ylabel('Valor - R$');  Note na figura acima todos os comentários que fizemos anteriormente sobre ambas as formas de pagamento.\nCenários Aqui estabelecemos os parâmetros de cálculo que serão empregados nos diferentes cenários. São eles:\n Valor do imóvel valor_do_imovel; Valor da entrada entrada; Taxa de juros anual para o financiamento taxa_financeamento_anual; Taxa anual de aluguel taxa_aluguel_anual: Fração do preço total do imóvel que seria paga como aluguel em um ano; Rendimento anual esperado caso os aportes sejam investidos rendimento_investimentos_anual; Quantos anos são esperados para o pagamento tempo_anos; Sistema de amortização sistema (SAC ou Price).  Além disso, assume-se que nestes exemplos, todos os parâmetros mantenham-se constantes ao longo do tempo, o que certamente não ocorre em situações reais.\nvalor_do_imovel = 500000.00 entrada = 100000.00 taxa_financeamento_anual = 0.0942 taxa_aluguel_anual = 0.04 rendimento_investimentos_anual = 0.08 tempo_anos = 30 sistema = 'SAC' #sistema = 'PRICE'  Agora obtemos a taxa de juros mensal correspondente aos valores anualizados que utilizamos como entrada. Lembre-se que:\n$$ i_{\\text{mensal}} = (1+ i_{\\text{anual}})^\\frac{1}{12}-1, $$\nde maneira que podemos escrever a seguinte função:\ndef taxa_aa_para_am(i): ''' Função recebe uma taxa de juros anual e retorna a taxa mensal equivalente. ''' return (1.+i)**(1./12.)-1.  No seguinte bloco obtemos a valor a ser financiado como o valor do imóvel menos o valor da entrada, além disso, convertemos as taxas para termos mensais, assim como o tempo:\nvalor_do_financiamento = valor_do_imovel - entrada taxa_financeamento = taxa_aa_para_am(taxa_financeamento_anual) taxa_aluguel = taxa_aa_para_am(taxa_aluguel_anual) rendimento_investimentos = taxa_aa_para_am(rendimento_investimentos_anual) tempo = tempo_anos * 12  Financiar O primeiro cenário consiste em financiar um imóvel, e para tanto basta aplicarmos a função do sistema de pagamentos que construimos na etapa inicial desse estudo:\nfinanciar = sistema_pagamento( sistema, taxa_financeamento, tempo, valor_do_financiamento )  Lembre-se que em Python é sempre possível acessar o manual de qualquer função, inclusive da que acabamos de criar, com o comando:\nhelp(sistema_pagamento)  Para fins comparativos, vamos estabelecer a evolução temporal do Patrimônio - Imóvel como a soma acumulativa dos valores de amortização (valor da parcela que efetivamente abate o saldo devedor) e da entrada, enquanto Custo - Juros será a soma acumulativa dos valores de juros (valor da parcela que remunera a instituição financiadora).\nfinanciar['Patrimônio - Imóvel'] = financiar['Amortização'].cumsum() + entrada financiar['Custo - Juros'] = financiar['Juros'].cumsum()  Podemos visualizar todos os elementos da nossa tabela:\nfinanciar      Juros Amortização Parcela Saldo Devedor Patrimônio - Imóvel Custo - Juros     0 nan nan nan 400000 nan nan   1 3012.07 1111.11 4123.18 398889 101111 3012.07   2 3003.7 1111.11 4114.81 397778 102222 6015.77   3 2995.33 1111.11 4106.44 396667 103333 9011.1   4 2986.97 1111.11 4098.08 395556 104444 11998.1   \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip;   356 41.83 1111.11 1152.94 4444.44 495556 543595   357 33.47 1111.11 1144.58 3333.33 496667 543628   358 25.1 1111.11 1136.21 2222.22 497778 543653   359 16.73 1111.11 1127.84 1111.11 498889 543670   360 8.37 1111.11 1119.48 0 500000 543678    361 rows × 6 columns\nOu facilmente graficar os resultados para o primeiro cenário:\nfinanciar[['Patrimônio - Imóvel', 'Custo - Juros'] ].plot.area(title='Financiar') plt.xlabel('Tempo (meses)') plt.ylabel('Valor (R$)')  Veja o que dizem os números:\n Ao longo de 360 meses, o montante total de R$1.043.678,18 foi desembolsado, sendo:\n R$543.678,18 para a instituição financeira (52,09% do total);\n R$500.000,0 foram aportados no imóvel (47,91% do total).   Alugar e Aportar Mensalmente O segundo cenário avalia não comprar, mas sim alugar o imóvel pelo tempo estipulado. Entretanto, considera-se que todos os valores que seriam gastos com o financiamento no caso anterior serão convertidos em aportes em aplicações financeiras.\n# Inicializamos um DataFrame vazio alugar = pd.DataFrame(index=range(tempo+1)) # Calculamos o valor do aluguel aluguel = round((valor_do_imovel)*taxa_aluguel,2) alugar['Aluguel'] = aluguel # Aluguel no tempo zero é igual a zero alugar['Aluguel'][0] = 0.0 # Aqui calculamos o custo com aluguel como o somatório # de todos os valores pagos alugar['Custo - Aluguel'] = alugar['Aluguel'].cumsum() # O aporte em aplicações financeiras se da pela diferença # entre o que seria pago de financiamento no exemplo anterior # e o valor do aluguel do imóvel alugar['Aportes'] = financiar['Parcela'] - aluguel # E o aporte inicial é o valor que estaria disponível como entrada alugar['Aportes'][0] = entrada  Nesse exemplo faremos uma separação do Patrimônio em duas partes, a fração que é proveniente dos aportes como Patrimônio - Principal, enquanto a parte proveniente do rendimento dos juros será denominada Patrimônio - Rendimentos, que podem ser calculados como segue:\n# Aqui a variável é basicamente inicializada alugar['Patrimônio'] = alugar['Aportes'] # O patrimônio é realmente calculado neste laço for n in alugar.index[1:]: alugar['Patrimônio'][n] = alugar['Aportes'][n] + alugar['Patrimônio'][n-1] * (1. + rendimento_investimentos) # Por fim, a fração Principal é tida como o somatório de todos os aportes alugar['Patrimônio - Principal'] = alugar['Aportes'].cumsum() # E os rendimentos são obtidos pela seguinte subtração alugar['Patrimônio - Rendimentos'] = alugar['Patrimônio'] - alugar['Patrimônio - Principal']  Feito todos os cálculos, podemos analisar os resultados\nalugar[['Patrimônio - Principal', 'Patrimônio - Rendimentos', 'Custo - Aluguel'] ].plot.area(title='Alugar e Aportar Mensalmente') plt.xlabel('Tempo (meses)') plt.ylabel('Valor (R$)')  Veja o que dizem os números:\n Ao longo de 360 meses, temos:\n R$589.273,20 foram desembolsados com aluguel;\n O montante total em investimentos é de R$3.144.815,24, sendo:\n R$454.404,98 proveniente dos aportes (14,45% do total); R$2.690.410,26 dos rendimentos (85,55% do total).     Economizar e Comprar à Vista O terceiro cenário considera a hipótese de alugar um imóvel e investir a diferença que haveria para um possível financiamento, assim como no caso anterior do aluguel. A diferença é que aqui o imóvel será comprado quando os investimentos atingirem o valor necessário. Nesse momento, o pagamento do aluguel será encerrado e os valores serão convertidos em mais aporte.\nO patrimônio será composto agora de três partes, além da fração que é proveniente dos aportes como Patrimônio - Principal e da parte proveniente do rendimento dos juros, denominada Patrimônio - Rendimentos, teremos o Patrimônio - Imóvel.\nVeja o cálculo:\n# A parte inicial desse cenário é igual ao anterior, # então iniciamos copiando os resultados comprar = alugar.copy() comprar['Patrimônio - Imóvel'] = 0.0 # A diferença é que o imóvel será comprado quando # se atingir o saldo disponível, obtemos essa # valor da planilha com o seguinte comando tcompra = comprar[comprar['Patrimônio']\u0026gt;=valor_do_imovel].first_valid_index() # Escrevemos na tela para conferência print(f'O imóvel será comprado no mês {tcompra}') # Nesse instante compramos o imóvel comprar['Patrimônio - Imóvel'][tcompra::] += valor_do_imovel # E descontamos o valor da compra do # montante que estava investido comprar['Patrimônio'][tcompra::] -= valor_do_imovel comprar['Patrimônio - Principal'][tcompra] -= valor_do_imovel - comprar['Patrimônio - Rendimentos'][tcompra] comprar['Patrimônio - Rendimentos'][tcompra] = 0.0 # Então redirecionamos todo o valor que seria gasto # com aluguel a partir daqui para mais aportes comprar['Aportes'][tcompra::] += comprar['Aluguel'][tcompra::] # Zeramos a atualizamos o cálculo com custo de aluguel comprar['Aluguel'][tcompra::] = 0.0 comprar['Custo - Aluguel'] = comprar['Aluguel'].cumsum() # Por fim, calcula-se a evolução do patrimônio a # partir da data da compra do imóvel for n in alugar.index[tcompra+1:]: comprar['Patrimônio - Principal'][n] = comprar['Patrimônio - Principal'][n-1] + comprar['Aportes'][n] comprar['Patrimônio - Rendimentos'][n] = comprar['Patrimônio'][n-1] * rendimento_investimentos + comprar['Patrimônio - Rendimentos'][n-1] comprar['Patrimônio'][n] = comprar['Patrimônio - Principal'][n] + comprar['Patrimônio - Rendimentos'][n]   O imóvel será comprado no mês 103.\n E produzimos a figura do caso:\ncomprar[['Patrimônio - Imóvel', 'Patrimônio - Principal', 'Patrimônio - Rendimentos', 'Custo - Aluguel'] ].plot.area(title='Economizar e Comprar à Vista') plt.xlabel('Tempo (meses)') plt.ylabel('Valor (R$)')  Veja o que dizem os números:\n Ao longo de 360 meses:\n R$166.960,74 foram desembolsados com 103 meses de aluguel;\n O montante total em investimentos foi de R$2.113.852,73, sendo:\n R$562.981,64 proveniente dos aportes (26,63% do total);\n R$1.050.871,09 dos rendimentos (49,71% do total);\n Além de R$500.000,00 do imóvel (23,65% do total).     Síntese dos Resultados Para sintetizar tudo o que vimos até aqui, criaremos uma tabela auxiliar apenas com os dados observados ao final do período de estudos, e isso é feito facilmente em um DataFrame com o comando .tail(1):\n# Criamos um DataFrame vazio summary = pd.DataFrame() # Adicionamos os valores obtidos na tempo final de cada um dos cenários summary = summary.append(alugar.tail(1), ignore_index=True, sort=False) summary = summary.append(comprar.tail(1), ignore_index=True, sort=False) summary = summary.append(financiar.tail(1), ignore_index=True, sort=False) # Vamos eliminar as colunas da tabela que não nos interessam summary.drop(['Aluguel', 'Aportes', 'Patrimônio', 'Juros', 'Amortização', 'Parcela', 'Saldo Devedor'], axis=1, inplace=True) # E renomear as linhas de acordo com cada caso summary.index = ['Alugar', 'Comprar à Vista', 'Financiar'] # Por fim mostramos na tela summary.fillna(0)      Custo - Aluguel Patrimônio - Principal Patrimônio - Rendimentos Patrimônio - Imóvel Custo - Juros     Alugar 589273 454405 2.69041e+06 0 0   Comprar à Vista 166961 562982 1.05087e+06 500000 0   Financiar 0 0 0 500000 543678    Por fim, apresentamos a figura:\nsummary[['Patrimônio - Imóvel', 'Patrimônio - Principal', 'Patrimônio - Rendimentos', 'Custo - Aluguel', 'Custo - Juros'] ].plot.barh(stacked=True) plt.title('Estudo de caso: Financiar, economizar e pagar \\n à vista ou alugar um imóvel?') plt.xlabel('Valor (R$)') plt.locator_params(axis='x', nbins=5)   Conclusão Nesse estudo de caso buscamos identificar as possíveis diferenças nos resultados de financiar quatro quintos de um imóvel, alugar um imóvel para morar e investir o montante que seria desembolsado com a compra, e pagar aluguel enquanto poupa o dinheiro para comprá-lo à vista. Para quaisquer exercícios deste tipo, o valor da taxa de juros é sempre o principal determinante. Vamos considerar os juros como os valores pagos pela posse do dinheiro, onde você os paga quando é um agente deficitário – tem menos dinheiro do que necessita e precisa tomar emprestado – e os recebe quando é um agente superavitário – tem mais dinheiro do que precisa e investe o que sobra -, e que tem sua taxa definida pelas escolhas intertemporais dos indivíduos, as quais acabam por determinar sua oferta e demanda de equilíbrio. Para fins de simplificação e comparação dos três cenários em questão, mantivemos constantes as receitas e despesas das famílias, assim como a taxa de juros do financiamento em 9,42% a.a., do aluguel em 4% a.a. e dos rendimentos financeiros em 8% a.a. Os resultados mostram que ao final do período considerado, caso você não atribua valor – tenha prazer - ao fato de se considerar o dono do imóvel, os benefícios pecuniários serão muito maiores se for pago aluguel e investido os valores que seriam gastos com a compra do imóvel. Se por algum motivo essa não for uma alternativa, é mais vantajoso poupar o dinheiro enquanto paga o aluguel para efetuar a compra do imóvel à vista, ao final dos primeiros 29% do período.\n","date":1586563200,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"65fe8321bb785af47aaa82028ee84fe7","permalink":"https://www.fschuch.com/blog/2020/04/11/alugar-economizar-e-pagar-a-vista-ou-financiar-um-imovel-um-estudo-de-caso/","publishdate":"2020-04-11T00:00:00Z","relpermalink":"/blog/2020/04/11/alugar-economizar-e-pagar-a-vista-ou-financiar-um-imovel-um-estudo-de-caso/","section":"post","summary":"Temos aqui um estudo de caso em matemática financeira resolvido em Python. O exercício envolve calcular diferentes cenários com relação a aquisição - ou não - de um imóvel. Além disso, veja como manipular tabelas com o pacote Pandas e a produção de gráficos com Matplotlib.","tags":["Educação Financeira","Engenharia Econômica","Pandas","Matplotlib","Python"],"title":"Alugar, economizar e pagar à vista ou financiar um imóvel? Um estudo de caso","type":"post"},{"authors":["Felipe N. Schuch"],"categories":null,"content":"","date":1585526400,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"b2d5f647b51248fbd530f3ee9f6820ff","permalink":"https://www.fschuch.com/publication/2020-phd-thesis/","publishdate":"2020-03-30T00:00:00Z","relpermalink":"/publication/2020-phd-thesis/","section":"publication","summary":"Escoamentos hiperpicnais são observados quando a massa específica de um fluido que adentra em uma bacia em repouso é maior que aquela do fluido ambiente. Essa diferença pode ser devido à temperatura, salinidade, turbidez ou concentração. Em uma configuração de fundo inclinado, a quantidade de movimento do escoamento diminui progressivamente, até que ele mergulhe sob o fluido ambiente e escoe junto ao leito. Destaca-se a relevância do estudo quanto à saúde de ecossistemas nas regiões de foz de rios, no gerenciamento e operação de reservatórios e no campo da geologia, uma vez que antigos depósitos de areia podem preservar registros sobre ambientes climáticos e tectônicos, além de formarem importantes reservatórios de hidrocarbonetos. No presente trabalho, simulações numéricas 3D são realizadas para um escoamento hiperpicnal que evolui no leito de um canal inclinado. Usando técnicas numéricas projetadas para supercomputadores, as equações incompressíveis de Navier-Stokes e transporte são resolvidas para reproduzir os experimentos de Lamb et al. (2010). Este estudo apresenta e verifica uma nova estrutura numérica, desenvolvida para a correta reprodução e análise do fenômeno de mergulho e suas características associadas. Uma boa concordância é encontrada entre os dados experimentais de Lamb et al. (2010), o modelo analítico de Parker e Toniolo (2007) e as simulações apresentadas. Uma nova equação é proposta para a previsão da profundidade para mergulho, incluindo o papel da velocidade de sedimentação e da declividade do leito do canal. A alta resolução espaço-temporal das simulações permite verificar as hipóteses estabelecidas, e uma boa concordância é encontrada não apenas para a posição de mergulho estacionária observada, mas também para a evolução temporal até atingir tal posição. Por fim, investiga-se o impacto observado quando o fluido ambiente no canal é alternado de água doce para salgada, onde percebe-se que tal mudança não é relevante quando a velocidade de sedimentação é nula, contanto que a diferença de densidade dos fluidos seja mantida constante. Por outro lado, uma nova dinâmica é observada na zona de mergulho e a jusante dela na presença de sedimentação, evidenciada pela convecção ascendente e mistura intensificada entre ambos os fluidos.","tags":["Mergulho do escoamento","Corrente de turbidez","Simulação de grandes escalas","Critério de mergulho","Xcompact3d"],"title":"Análise do mergulho de escoamentos hiperpicnais em canal inclinado por meio de simulação numérica de grandes escalas","type":"publication"},{"authors":null,"categories":null,"content":"Uma das principais utilidades de qualquer ferramenta computacional é a possibilidade de automatizar tarefas. Aqui vemos como transformar qualquer URL facilmente para QRcode com Python.\nO primeiro passo é instalar o pacote qrcode.\nIsso pode ser feito por meio do seu gerenciador de pacotes preferido, como Anaconda Python, por exemplo, ou com o comando no terminal:\npip install -q qrcode  Ou pode ser importado diretamente dentro do ambiente Jupyter com o comando mágico:\n!pip install -q qrcode  Independente da sua escolha para meio de instalação, agora importamos o módulo:\nimport qrcode  E então estamos prontos para criar o primeiro qrcode com o comando qrcode.make(\u0026lt;url\u0026gt;), como vemos a seguir:\nqrcode.make('https://www.instagram.com/aprenda.py/')  Experimente ler o código acima com o seu smartphone.\nA opção anterior apenas mostrou o resultado na tela, mas pode ser muito mais interessante salvar o qrcode para um arquivo. Pode-se fazer isso com duas linhas de código:\nimg = qrcode.make('www.instagram.com/aprenda.py') img.save('aprenda.py.qrcode.png')  Para opções avançadas, como alteração das cores, borda ao tamanho da imagem, não deixe de conferir a documentação oficial do pacote em:\nqr = qrcode.QRCode() qr.add_data('https://pypi.org/project/qrcode/') qr.make(fit=True) qr.make_image(fill_color=\u0026quot;darkblue\u0026quot;, back_color=\u0026quot;orange\u0026quot;)  Note que é sempre possível e bastante simples consultar a documentação com:\nhelp(qr.make_image)  Help on method make_image in module qrcode.main: make_image(image_factory=None, **kwargs) method of qrcode.main.QRCode instance Make an image from the QR Code data. If the data has not been compiled yet, make it first.  Por fim, lembre-se que estamos dentro de um ambiente de programação Python, e podemos aproveitar de todos os recursos disponíveis, como laços, testes lógicos, estruturas de dados e a combinação com outros pacotes para produzir resultados únicos e automatizados.\n","date":1583539200,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"54f2e5149c1c9ce8da7507d917005db4","permalink":"https://www.fschuch.com/blog/2020/03/07/transforme-qualquer-url-em-qrcode-usando-python/","publishdate":"2020-03-07T00:00:00Z","relpermalink":"/blog/2020/03/07/transforme-qualquer-url-em-qrcode-usando-python/","section":"post","summary":"Mais sobre automação de tarefas, aqui vemos como transformar qualquer URL facilmente para QRcode. Experimente ler o código com seu smartphone.","tags":["Python"],"title":"Transforme qualquer URL em QRcode usando Python","type":"post"},{"authors":null,"categories":null,"content":"Introdução CFD com Python, também conhecido como os 12 passos para Navier-Stokes, é um módulo prático para o aprendizado dos fundamentos de Dinâmica dos Fluidos Computacional (CFD, do Inglês Computational Fluid Dynamics) por meio de códigos que resolvem as equações diferenciais parciais que descrevem a física dos escoamentos. Esta é uma adaptação e tradução para português por Felipe N. Schuch. Os textos e códigos originais foram parte do curso ministrado pela Prof. Lorena Barba entre 2009 e 2013 no departamento de Engenharia Mecânica da Universidade de Boston (Prof. Barba então se mudou para Universidade George Washington).\nO curso é para iniciantes. O módulo assume que o leitor tenha conhecimentos básicos sobre programação (qualquer linguagem) e alguma familiaridade com equações diferenciais e mecânica dos fluidos. Guiando estudantes através destes passos (sem falhar nenhum!), podemos ensina-los lições valiosas. A constante evolução entre os exercícios proporciona um senso de recompensa ao final de cada atividade, e eles sentem que estão aprendendo com pouco esforço. Conforme avançam, eles naturalmente praticam como reutilizar trechos de código e progressivamente aprendem técnicas de programação e visualização. Enquanto eles analisam os resultados, aprendem sobre difusão, precisão e convergência. Em todos os casos, o aluno é encorajado a seguir o trabalho de cada lição paralelamente ao reescrever em um Jupyter Notebook novo, mantendo anotações pessoais de seu progresso e de seus experimentos.\n We hope that the CFD Python series will help a new cohort of students and self-learners gain basic CFD skills. Let us know what you think!\nProf. Lorena Barba\n Como Acessar Existem basicamente duas opções, descritas à seguir:\nExecutar online Execute uma seção interativa dessa versão do CFD com Python em seu navegador usando o serviço Binder. Esta opção não requer nenhuma instalação na sua máquina, apenas clique no botão:\n\n Espere a aplicação carregar tudo para você, isso pode levar algum tempo; O próximo passo é abrir os arquivos na pasta tarefas; Ao final do curso, não esqueça de salvar uma cópia do Notebook com suas anotações pessoais.  Instalação Se você gostaria de executar na sua própria máquina por meio da instalação de alguma distribuição Python, consulte os detalhes sobre o procedimento em nosso repositório no GitHub.\nConteúdo Os passos 1 a 4 são em uma direção espacial (1D). Passos 5 a 10 são em duas dimensões (2D). Passos 11 e 12 resolvem as equações de Navier-Stokes em 2D. Três Notebooks \u0026ldquo;bônus\u0026rdquo; cobrem a condição CFL de estabilidade, operações de arranjos multi-dimensionais com NumPy e definição de funções em Python.\n Ligeira Introdução à Python \u0026ndash; Para novatos em Python, essa lição introduz bibliotecas numéricas (NumPy e Matplotlib), variáveis em Python, endentação e manipulação de arranjos. Passo 1 \u0026ndash; Convecção linear com avanço à partir da condição inicial (CI) e condições de contorno (CC) apropriadas. Passo 2 \u0026ndash; Com as mesmas CI/BCs, convecção não linear. Condição CFL \u0026ndash; Explorando a estabilidade numérica e a condição de Courant-Friedrichs-Lewy (CFL). Passo 3 \u0026ndash; Com as mesmas CI/BCs, apenas difusão. Passo 4 \u0026ndash; Equação de Burgers, com CI dente de serra e CC periódica (e uma introdução ao SymPy). Operações com arranjos em NumPy Passo 5 \u0026ndash; Convecção linear 2D com CI função quadrada e CC apropriadas. Passo 6 \u0026ndash; Com as mesmas CI/BCs, convecção não linear 2D. Passo 7 \u0026ndash; Com as mesmas CI/BCs, difusão 2D. Passo 8 \u0026ndash; Equação de Burgers 2D. Definindo Funções em Python Passo 9 \u0026ndash; Equação de Laplace 2D com CI zero e CC ambas Neumann e Dirichlet. Passo 10 \u0026ndash; Equação de Poisson 2D. Passo 11 \u0026ndash; Resolve o escoamento em Cavidade com Navier-Stokes 2D. Passo 12 \u0026ndash; Resolve o escoamento em Canal com Navier–Stokes 2D.   Clicar nos links nessa seção irá abrir cada Notebook pelo serviço nbviewer, que os apresenta na tela, porem não em forma executável. Para isso, consulte Executar online.   Conteúdo complementar Existem ainda duas outras versões do CFD com Python:\n Versão original em Inglês, por Prof. Lorena Barba. Tradução para Espanhol, por F.J. Navarro-Brull para CAChemE.org  A versão original foi ainda publicada em:\n Barba, Lorena A., and Forsyth, Gilbert F. (2018). CFD Python: the 12 steps to Navier-Stokes equations. Journal of Open Source Education, 1(9), 21, doi.org/10.21105/jose.00021  ","date":1578787200,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"3eef2eecad9263005b473f796b42657d","permalink":"https://www.fschuch.com/blog/2020/01/12/cfd-com-python-12-passos-para-navier-stokes/","publishdate":"2020-01-12T00:00:00Z","relpermalink":"/blog/2020/01/12/cfd-com-python-12-passos-para-navier-stokes/","section":"post","summary":"Este material lhe guiará, passo a passo, pelos fundamentos de Dinâmica dos Fluidos Computacional. Cada tarefa introduz tanto novos conceitos físicos sobre as equações de Navier-Stokes, quanto detalhes sobre a programação em Python que resolve as equações diferenciais parciais. Tudo isso de maneira interativa e online (nenhuma instalação é necessária).","tags":["CFD","Python"],"title":"CFD com Python: 12 Passos para Navier-Stokes","type":"post"},{"authors":null,"categories":null,"content":"Lista de Conteúdos  Introdução Trapézio Simples Trapézio Composto  Implementação Operador Integral Biblioteca SciPy   Bônus: Erro do método    Introdução A operação integral é, de maneira geral, representada pela seguinte equação: \\[ \\int_a^b f(x)dx. \\]\nNo contexto geométrico, essa operação é capaz de calcular a área sob a curva \\( f(x) \\), para o intervalo \\( a \\le x \\le b \\). Muitas das funções mais conhecidas apresentam uma integral definida, isso é, podem ser calculadas de forma analítica, e essas definições aparecem em Tabelas de Integrais ou em utilitários de álgebra simbólica (SymPy, por exemplo).\nExistem casos onde a solução analítica não é possível, já que a função é de elevada complexidade ou mesmo desconhecida, e aí podemos recorrer aos métodos numéricos.\nTrapézio Simples A regra do trapézio é uma das primeiras técnicas de integração que aprendemos em um curso de métodos numéricos. Ela consiste em aproximar a área sob a curva da função \\( f(x) \\) como a área de um trapézio, dada pela equação:\n\\[ \\int_a^b f(x)dx \\approx \\dfrac{f(a) + f(b)}{2} (b-a). \\]\nO que seria o equivalente a calcular a área demarcada pela região azul na figura:\nConsiderando a função \\( f(x) = \\cos(x) + x/\\pi \\) no intervalo \\( 0 \\le x \\le 4 \\pi \\), podemos facilmente calcular o valor da integral pelo método do trapézio como:\n\\[ \\int_0^{4 \\pi} f(x)dx \\approx \\dfrac{1 + 5}{2} (4\\pi-0) \\approx 37,699. \\]\nSabe-se, entretanto, que a solução exata é aproximadamente \\( 25,133 \\). Nossa estimativa passou longe do valor esperado, mas como podemos melhorar isso?\n Trapézio Composto Bem, podemos melhorar a aproximação para o cálculo do valor da integral ao aumentarmos o número de trapézios, ou ao usar a regra trapezoidal composta. Ela é dada pela equação:\n\\[ \\int_a^b fdx \\approx \\sum_{i=0}^{n-1} \\dfrac{f_{i} + f_{i+1}}{2} \\Delta x = \\dfrac{\\Delta x}{2} \\left( f_1 + 2f_2 + \\dots + 2f_{n-1} + f_{n}\\right). \\]\nVamos considerar a mesma função \\( f(x) = \\cos(x) + x/\\pi \\) no intervalo \\( 0 \\le x \\le 4 \\pi \\). Se considerarmos \\( n = 4 \\), a integral vai representar a área azul na figura:\nMelhor, não? Calcular seu valor já não é tão trivial, mas que tal começarmos a por a mão na massa?\nimport numpy as np # Importamos nossa biblioteca preferida def f(x): # Transcrevemos a função dada return np.cos(x) + x/np.pi dx = 4*np.pi/3 # Calculamos o dx para esse caso # E finalmente calculamos a integral # pelo método trapezoidal composto dx*(f(0*dx) + 2*f(1*dx) + 2*f(2*dx) + f(3*dx))/2  25.132741228718345  A resposta chegou mais perto. Podemos continuar aumentando o número de pontos empregados para diminuir o erro. Mas mais pontos demandariam muito trabalho com a abordagem que usamos aqui, a equação nem caberia na tela. Vamos automatizar esse processo?\nImplementação Vamos resolver o método trapezoidal para a mesma função e intervalo, mas agora com ainda mais pontos, que tal \\( n = 21 \\)? A representação visual é essa:\nVamos ir aumentando o nível de requinte do código, para que ele faça todo o trabalho dessa vez:\n# Aqui definimos o intervalo que queremos, # bem como o número de pontos x = np.linspace(0, 4*np.pi, num=21) ''' E é tudo que precisamos, o resto é por conta do computador ''' y = f(x) # Nossa função já foi definida no bloco anterior dx = x[1] - x[0] # Obtém o espaçamento I = 0. # A operação envolve um somatório, então iniciamos uma variável acumuladora I += dx*y[0]/2 for i in range(1,x.size-1): # Reflita, por que esse laço vai de 1 até n-1? I += dx*y[i] I += dx*y[-1]/2 print(I) # E finalmente temos o resultado  25.132741228718345  E estamos cada vez mais perto da resposta exata. Nesse ponto, se estiver seguindo essa lição com uma aplicação Python aberta (o que é altamente recomendado), aproveite para experimentar diferentes possibilidades, varie os parâmetros, varie a função, veja o que acontece.\n Uma desvantagem dessa abordagem é que o laço for vai realizar as operações em série, uma de cada vez, e isso é bem ruim do ponto de vista do desempenho computacional.    Caso não conheça a função np.linspace, lembre-se que em Python é sempre possível acessar a documentação facilmente, basta digitar help(np.linspace).   Operador Integral Após se divertir com os códigos que criamos até aqui, vamos prosseguir nossa escalada no que se refere a elegância. Vamos apresentar nossa integral na forma de um operador integral. Retorne até a equação da regra trapezoidal composta e dê uma boa olhada. Percebe o padrão? Todos os termos são multiplicados por \\( \\Delta x \\), com exceção do primeiro e do último, que são multiplicados por \\( \\Delta x / 2 \\). Ora, se isso não tem exatamente a aparência de um vetor preenchido pelo valor 1, onde o primeiro e último elemento são divididos por 2, e então todos multiplicados por \\( \\Delta x \\), e por fim somados. São muitas palavras, mas não se assuste, a aparência não é tão ruim:\n\\[ \\int_a^b f(x) dx = \\sum_{i=1}^n \\big( W_i f(x_i) \\big), \\] sendo o operador integral dado por \\[ W = \\Delta x [ 1/2, 1, \\dots, 1, \\dots, 1, 1/2 ]. \\]\nTendo em vista que a coordenada x, a função y e o espaçamento da malha dx já foram todos definidos nos blocos anteriores, tudo que precisamos agora é definir o nosso operador integral:\n# Iniciamos o operador integral como um vetor # preenchido por 1, multiplicado por dx W = dx*np.ones_like(x) # Dividimos o primeiro e último elemento por 2 for i in [0, -1]: W[i] /= 2.0 # A multiplicação do operador pela função e a # soma dos elementos fornece nossa resposta np.sum(W * y)  25.132741228718345  Nessa opção, após a inicialização, podemos calcular outras integrais apenas repetindo a última linha do código, aumentando a legibilidade e a chance de reutilização do código, e menos linhas para copiar e colar também são um benefício na hora de procurar e corrigir falhas.\n Todas as operações embutidas nas principais bibliotecas python (como NumPy e SciPy) empregam conceitos de otimização e programação vetorial, então são preferíveis por aumentar o desempenho computacional.   Biblioteca SciPy Meus parabéns se você chegou até aqui, o último passo. Vamos recapitular, já vimos quatro maneiras diferentes para calcular uma integral:\n Com a regra simples, a resposta veio de uma simples continha; Ao passar para a regra composta as coisas cresceram, usamos uma calculadora; Vimos como automatizar o cálculo, e foi então possível experimentar diversas combinações de parâmetros; Então, aumentamos a elegância e resolvemos o problema de forma matricial.  Agora, a última etapa envolve um dos motivos pelo qual Python tem se tornado tão popular: existe uma infinidade de bibliotecas já programadas, prontas para realizar diversas tarefas. De modo que podemos fazer:\nfrom scipy.integrate import trapz trapz(y,x)  25.132741228718345  Lindo, não? Repare que obtivemos exatamente a mesma resposta para os três últimos exercícios, mostrando que existem diferentes caminhos a serem trilhados. A prática vai lhe permitir escolher entre eles.\nFazemos um destaque à função scipy.integrate.cumtrapz, que calcula a integral de forma acumulativa, que pode ser particularmente útil dependendo da aplicação.\nExemplos # Um exemplo unidirecional trapz([1,2,3])  4.0  # Onde podemos informar como argumento # opcional o sistema de coordenadas trapz([1,2,3], x=[4,6,8])  8.0  # Ou o espaçamento dos pontos, # caso seja uniforme trapz([1,2,3], dx=2)  8.0  # Esse é o exemplo de um caso bidimensional a = np.arange(6).reshape(2, 3) a  array([[0, 1, 2], [3, 4, 5]])  # Integral em x trapz(a, axis=0)  array([1.5, 2.5, 3.5])  # Integral em y trapz(a, axis=1)  array([2., 8.])  # Integral dupla: x e então em y trapz(trapz(a, axis=0), axis=0)  5.0  # Integral dupla: y e então em x trapz(trapz(a, axis=-1), axis=-1)  5.0  Bônus: Erro do método Por fim, podemos ver que o erro do método numérico decresce exponencialmente, na ordem de \\( n^{-2} \\), em função do aumento do número de pontos:\nMas ele fica saturado por volta de \\( 10^{-12} \\). É hora da reflexão, você sabe me dizer o que acontece ali?\n","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"cfacebd071dd075414bc77fbf70346b4","permalink":"https://www.fschuch.com/blog/2020/01/07/integracao-numerica-com-a-regra-dos-trapezios/","publishdate":"2020-01-07T00:00:00Z","relpermalink":"/blog/2020/01/07/integracao-numerica-com-a-regra-dos-trapezios/","section":"post","summary":"Ao final desta leitura, você deve compreender os princípios da integração numérica pelo método dos trapézios. Desde os conceitos básicos, passando por exemplos de algoritmos de implementação, até uma descrição de como usar SciPy, uma biblioteca Python para cálculo científico.","tags":["SciPy","Métodos Numéricos","Python"],"title":"Integração numérica com a Regra dos Trapézios","type":"post"},{"authors":null,"categories":null,"content":"","date":1570660200,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"e7dc669b2cbc7a7c9eaea97555034537","permalink":"https://www.fschuch.com/talk/metodos-numericos-aplicados-a-transferencia-de-calor/","publishdate":"2020-09-02T21:13:06-03:00","relpermalink":"/talk/metodos-numericos-aplicados-a-transferencia-de-calor/","section":"event","summary":"Aula como professor convidado, ministrada para a turma de transferência de calor.","tags":["Python","Métodos Numéricos","Transferência de Calor","Matplotlib","NumPy","Pandas","SymPy","SciPy"],"title":"Métodos Numéricos Aplicados à Transferência de Calor","type":"event"},{"authors":null,"categories":null,"content":"Pedra, papel e tesoura é um clássico, portanto imagino que você já deva ter jogado em algum momento. Mas não custa nada relembrar, a regra é simples: pedra ganha da tesoura, tesoura ganha do papel e papel ganha da pedra (para mais informações, veja Wikipédia).\ngraph TD A(Pedra) --\u0026gt;| ganha de | B(Tesoura) B --\u0026gt;| ganha de | C(Papel) C --\u0026gt;| ganha de | A  Do ponto de vista computacional, esse é um belo exercício para praticar.\n Dica: A função choise do módulo random é uma boa opção para que o computador escolha aleatoriamente a sua jogada dentre as possibilidades pré estabelecidas em uma lista.   Claro que existem vários caminhos diferentes para resolver um dado problema, para esse desafio não seria diferente. A cada problemas que resolvemos, agregamos experiência para abordar o seguinte.\nDedique aqui algum tempo para produzir a sua própria solução.\nApenas então prossiga para a células de código abaixo para ver a minha versão do jogo:\n# Importamos a função choice, que fará o papel do nosso adversário from random import choice # Lista das jogadas válidas play = [\u0026quot;pedra\u0026quot;, \u0026quot;papel\u0026quot;, \u0026quot;tesoura\u0026quot;] # Matriz de decisão do resultado, contendo as regras do jogo rule = ((\u0026quot;e\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;v\u0026quot;), (\u0026quot;v\u0026quot;, \u0026quot;e\u0026quot;, \u0026quot;d\u0026quot;), (\u0026quot;d\u0026quot;, \u0026quot;v\u0026quot;, \u0026quot;e\u0026quot;)) # Texto a ser exibido na tela para cada resultado possível text = { \u0026quot;e\u0026quot;: \u0026quot; Empatou!\u0026quot;, \u0026quot;v\u0026quot;: \u0026quot; Parabéns, você venceu!\u0026quot;, \u0026quot;d\u0026quot;: \u0026quot; Você foi derrotado!\u0026quot;, } # Aqui temos o jogo propriamente dito while True: h, c = input(\u0026quot;Faça a sua jogada: \u0026quot;).lower(), choice(play) if h == \u0026quot;sair\u0026quot;: # É sempre uma boa prática ter uma saída de um laço while True break if h in play: # E um teste de que a jogada foi válida print(f\u0026quot; O computador jogou {c}\u0026quot;) print(text[rule[play.index(h)][play.index(c)]]) else: print(f\u0026quot; As jogadas válidas são:\\n {play}\u0026quot;)  E aqui vemos o jogo em ação:\nFaça a sua jogada: pedra O computador jogou pedra Empatou! Faça a sua jogada: Papel O computador jogou papel Empatou! Faça a sua jogada: TESOURA O computador jogou papel Parabéns, você venceu! Faça a sua jogada: SaIR  Muitas vezes nos deparamos com a tarefa de ter que desvendar o código escrito por outra pessoa, e esse é o segundo passo desse desafio. Você consegue compreender como se dá o jogo no bloco acima? Se a resposta for não, recomendo a leitura sobre as estruturas de dados em Python chamadas dicionários, além de algumas cláusulas de controle de laços.\n","date":156384e4,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"d7270be1c3a8605d49549390df681ca7","permalink":"https://www.fschuch.com/blog/2019/07/23/desafio-de-programacao-o-jogo-pedra-papel-e-tesoura/","publishdate":"2019-07-23T00:00:00Z","relpermalink":"/blog/2019/07/23/desafio-de-programacao-o-jogo-pedra-papel-e-tesoura/","section":"post","summary":"Um pouco de diversão hoje com o desafio de programar o jogo clássico pedra, papel e tesoura.","tags":["Desafio","Jogos","Python"],"title":"Desafio de Programação: O jogo Pedra, Papel e Tesoura","type":"post"},{"authors":null,"categories":null,"content":" Postagens Recentes    Aula Particular Online   Conheça o Projeto Esta é a primeira linha de código para Aprenda.py:\nprint(\u0026quot;Olá mundo!\u0026quot;)  Aprenda.py tem por objetivo incentivar e divulgar a resolução de problemas por meio de ferramentas computacionais. Nos últimos anos, a denominação STEAM tem se popularizado, vindo do inglês para:\n Science (Ciência); Technology (Tecnologia); Engineering (Engenharia); Art (Arte); Mathematics (Matemática).  Em meio a tantas linguagens de programação disponíveis, a escolha do Python se deu pela sua incrível popularidade, boa flexibilidade, e principalmente, pela vasta gama de bibliotecas encontradas para os mais diversos fins. Soma-se isso à interatividade da plataforma Jupyter Notebook, que permite combinar blocos de código com textos, equações, vídeos, figuras e tabelas, criando um perfeito ambiente para produção de conteúdo interativo e aprendizagem, assim como esse blog.\nMinha relação com Python começou de maneira autodidata, e consistia em resolver os problemas que vivenciava diariamente na minha atuação como aluno de pós-graduação. Inicialmente o foco era apenas como uma ferramenta para produção de figuras com Matplotlib, em substituição ao Gnuplot que era empregado por mim até então. Com o tempo e com a prática, pude perceber que eu podia usar Python de fato para todo o processamento de dados (que antes era feito em Fortran). Essa foi uma mudança chave para um nítido aumento de produtividade. Perceba que o fluxo de trabalho em Fortran consiste em programar o código, compilar (se nenhum erro for encontrado), executar e avaliar os resultados (muitas vezes em ferramentas externas). Enquanto com Jupyter Notebook, o fluxo de trabalho é interativo, multiplataforma e facilmente documentável.\nCom essa experiência, me dispus a palestrar na Jornada Acadêmica da minha universidade (disponível no GitHub), mostrando uma introdução a linguagem Python e exemplificando como resolver diversos problemas na área da engenharia. Entre eles: Métodos Numéricos, Transferência de Calor, Resistência dos Materiais, Vibrações Mecânica e outros. E desde então sigo aprendendo mais sobre o assunto, e fico feliz em compartilhar isso com você.\n ","date":1563494400,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"1286ef3ee7e82a8e6e98044e28e93327","permalink":"https://www.fschuch.com/project/aprenda.py/","publishdate":"2019-07-19T00:00:00Z","relpermalink":"/project/aprenda.py/","section":"project","summary":"Esse projeto tem por objetivo incentivar e divulgar a resolução de problemas por meio de ferramentas computacionais.","tags":["Python","Educação"],"title":"Aprenda.py","type":"project"},{"authors":null,"categories":null,"content":"","date":1563296400,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"cb32b5512cf320a1035a2d8b01f83b0b","permalink":"https://www.fschuch.com/talk/python-introducao-e-aplicacoes-da-linguagem-de-programacao-em-engenharia/","publishdate":"2020-09-02T20:43:09-03:00","relpermalink":"/talk/python-introducao-e-aplicacoes-da-linguagem-de-programacao-em-engenharia/","section":"event","summary":"Oficina de programação ministrada durante a Jornada Acadêmica, da Escola Politécnica - PUCRS.","tags":["Python","Métodos Numéricos","Matplotlib","NumPy","Pandas","SymPy","SciPy"],"title":"Python: Introdução e Aplicações da Linguagem de Programação em Engenharia","type":"event"},{"authors":[],"categories":[],"content":"Python and XCompact3d XCompact3d 2021 Online Developer Meeting Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n Hi, my name is Felipe; Today I gonna talk about Python and XCompact3d; Starting with a quick introduction; Then I gonna show a little bit of what I\u0026rsquo;ve been doing in this TOPIC; And finally, I will bring some points for discussion here with you, especially AIMING to improve the synergy between Python and XCompact.    Introduction  Why Python?  Computational cost vs Cost for development; Faster to Prototype ideas; Code interactively using IPython and Jupyter; It is a great tool for pre and post-processing.   I don\u0026rsquo;t know if everyone here already uses Python, so I gonna start with Why Python; Many people MAY SAY it is a terrible tool because it DOESN\u0026rsquo;T RUN SO fast as other alternatives; But to THOSE people I say, we need to look at the big picture, lets also talk about the COST for development, HUMAN RESOURCES; Here is where Python is really good; Together with the INTERACTIVE tools like Jupyter, Python is a very popular CHOICE for data science; And in our case, it\u0026rsquo;s a great tool for pre and post-processing.    Why Numpy?  It is a Python library that provides a multidimensional array object and an assortment of routines for fast operations on arrays; Much faster option, because it runs in optimized, pre-compiled C code; With Numpy, we have the best of two worlds, the performance of compiled code in the background, together with the flexibility of Python code for the user.  See https://numpy.org\n And now, Why Numpy? It provides multidimensional ARRAY operations in Python; It is much faster than pure Python, because it runs in OPTIMIZED, pre-compiled C code; With Numpy, we have the best of two WORLDS, the performance of compiled code, together with the flexibility of Python CODE FOR THE USER.    Numpy - Example x = np.linspace(start=0., stop=2*np.pi, num=50) y = np.linspace(start=0., stop=2*np.pi, num=50) ux = np.sin(x[:,np.newaxis])*np.cos(y[np.newaxis,:]) uy = -np.cos(x[:,np.newaxis])*np.sin(y[np.newaxis,:]) int = np.trapz(np.trapz(ux, x=x, axis=0), x=y, axis=0) plt.streamplot(x,y,ux.T,uy.T) plt.xlabel(r\u0026quot;$x_1$\u0026quot;); plt.ylabel(r\u0026quot;$x_2$\u0026quot;);   This is a little workflow using Numpy;  We start here setting two vectors, they will work as our coordinates, x and y; Now you see that booth ux and uy are 2D, but Numpy doesn\u0026rsquo;t know it, so we should inform it using this np.newaxis notation; And we can compute a integration in this plane, but it is up to the user to keep track of the coordinates and the number of each AXIS. The plot is just for reference;   But WHO am I to complain about Numpy?  It is the core of the scientific ecosystem in Python; I Just wanna show you that we can use Numpy in a better way;      Why Xarray?  Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like multidimensional arrays, which allows for a more intuitive, more concise, and less error-prone developer experience; Besides, it is integrated to other tools for:  Plotting (matplotlib, HoloViews and others); Parallel computing (Dask); I/O (NetCDF).    See http://xarray.pydata.org\n WITH Xarray. It introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy arrays, which allows for a more intuitive, more CONCISE, and LESS ERROR-PRONE DEVELOPER experience:  Xarray can do axis alignment and broadcast AUTOMATICALLY for any array operation;   Besides, it\u0026rsquo;s integrated with other tools for Plotting, Parallel computing and I/O.    Xarray - Example dataset = xr.Dataset( coords={ \u0026quot;y\u0026quot;: np.linspace(start=0.0, stop=2 * np.pi, num=50), \u0026quot;x\u0026quot;: np.linspace(start=0.0, stop=2 * np.pi, num=50), } ) dataset[\u0026quot;ux\u0026quot;] = np.sin(dataset[\u0026quot;x\u0026quot;]) * np.cos(dataset[\u0026quot;y\u0026quot;]) dataset[\u0026quot;uy\u0026quot;] = -np.cos(dataset[\u0026quot;x\u0026quot;]) * np.sin(dataset[\u0026quot;y\u0026quot;]) dataset  \u0026lt;xarray.Dataset\u0026gt; Dimensions: (x: 50, y: 50) Coordinates: * y (y) float64 0.0 0.1282 0.2565 0.3847 ... 5.899 6.027 6.155 6.283 * x (x) float64 0.0 0.1282 0.2565 0.3847 ... 5.899 6.027 6.155 6.283 Data variables: ux (x, y) float64 0.0 0.0 0.0 0.0 ... -2.369e-16 -2.429e-16 -2.449e-16 uy (x, y) float64 -0.0 -0.1279 -0.2537 ... 0.2537 0.1279 2.449e-16  Note: This is just the string representation, the dataset will look even better in HTML when running in Jupyter.\n See this example using xarray; We start with the dataset OBJECT, informing the coordinates in this DICT-LIKE constructor; Now we can access the coordinates by THEIR name, and with it, xarray knows this result should be 2D; We can investigate the dataset, its dimensions, coordinates and variables, ALL TOGETHER in a single object; We will see more examples applied to xcompact soon;    XCompact3d-toolbox https://xcompact3d-toolbox.readthedocs.io\n The physical and computational parameters are built on top of traitlets:  IPywidgets for a friendly user interface;   Data structure is provided by xarray, again with:  Plotting (matplotlib, HoloViews and others); Parallel computing (Dask); I/O (NetCDF).     But first, lets talk about the toolbox; It is a Package designed to handle pre and post-processing in Python; Actually, it is more like a Python WRAPPER, because it RELIES HEAVILY on other Python tools; For instance, the physical and computational parameters are built on top of TRAITLETS;  Together with a friendly user interface in IPywidgets;   And the Data structure is provided by Xarray, again with support for Plotting, Parallel computing and I/O;    Parameters' consistency with Traitlets \u0026gt;\u0026gt;\u0026gt; prm = x3d.Parameters(loadfile=\u0026quot;example.i3d\u0026quot;) \u0026gt;\u0026gt;\u0026gt; # Type checking \u0026gt;\u0026gt;\u0026gt; prm.iibm = 10.0 TraitError: The 'iibm' trait of a Parameters instance expected an int, not the float 10.0. \u0026gt;\u0026gt;\u0026gt; # Limits are imposed \u0026gt;\u0026gt;\u0026gt; prm.iibm = 5 # \u0026lt;--- This can be only 0, 1 or 2, as x3d expects TraitError: The value of the 'iibm' trait of a Parameters instance should not be greater than 2, but a value of 5 was specified  \u0026gt;\u0026gt;\u0026gt; # On change validation \u0026gt;\u0026gt;\u0026gt; prm.nx = 93 TraitError: Invalid value for mesh points (nx) \u0026gt;\u0026gt;\u0026gt; prm.nx = 17 \u0026gt;\u0026gt;\u0026gt; # On chance callbacks \u0026gt;\u0026gt;\u0026gt; print(prm.nclx1, prm.nclxn, prm.nx, prm.dx) 2 2 17 0.0625 \u0026gt;\u0026gt;\u0026gt; prm.nclx1 = 0 # \u0026lt;--- Setting periodic BC \u0026gt;\u0026gt;\u0026gt; print(prm.nclx1, prm.nclxn, prm.nx, prm.dx) 0 0 16 0.0625   With Traitlets, the parameters can be checked for consistence; The GOAL here is to anticipate some user mistakes; For instance:  The parameters are type checked; We can impose some boundaries; We can see some on CHANGE validations; And onchange callbacks;   So, with it, we make sure that the parameters file will be compatible with xcompact3d;    User Interface with IPywidgets (try it online)  [Try it online](https://xcompact3d-toolbox.readthedocs.io/en/latest/tutorial/parameters.html#). --  And all the behaviors we saw in the command line are also available at the user interface; As you can see, we ensure that booth boundaries in one direction will be periodic or not at the same time, and the number of MESH POINTS goes BACK and FORWARD properly; You can see the estimation for size in disk changing as well; -It is pretty cool, you can try it online in this link.    XCompact3d-toolbox - Example prm = x3d.Parameters(loadfile=\u0026quot;input.i3d\u0026quot;) ds = xr.Dataset() # Make sure to have enough memory! for var in \u0026quot;ux uy uz pp\u0026quot;.split(): ds[var] = prm.read_all_fields(f\u0026quot;./data/3d_snapshots/{var}-*.bin\u0026quot;) ds[\u0026quot;phi\u0026quot;] = xr.concat([prm.read_all_fields(f\u0026quot;./data/3d_snapshots/phi{n+1}-*.bin\u0026quot;) for n in range(prm.numscalar)], \u0026quot;n\u0026quot;,).assign_coords(n=(\u0026quot;n\u0026quot;, range(prm.numscalar))) ds  \u0026lt;xarray.Dataset\u0026gt; Dimensions: (n: 5, t: 76, x: 721, y: 49, z: 721) Coordinates: * x (x) float32 0.0 0.02083 0.04167 0.0625 ... 14.94 14.96 14.98 15.0 * z (z) float32 0.0 0.02083 0.04167 0.0625 ... 14.94 14.96 14.98 15.0 * y (y) float32 0.0 0.02083 0.04167 0.0625 ... 0.9375 0.9583 0.9792 1.0 * n (n) int32 0 1 2 3 4 * t (t) float64 0.0 0.4 0.8 1.2 1.6 2.0 ... 28.4 28.8 29.2 29.6 30.0 Data variables: phi (n, t, x, y, z) float32 dask.array\u0026lt;chunksize=(5, 1, 721, 49, 721), meta=np.ndarray\u0026gt; ux (t, x, y, z) float32 dask.array\u0026lt;chunksize=(1, 721, 49, 721), meta=np.ndarray\u0026gt; uy (t, x, y, z) float32 dask.array\u0026lt;chunksize=(1, 721, 49, 721), meta=np.ndarray\u0026gt; uz (t, x, y, z) float32 dask.array\u0026lt;chunksize=(1, 721, 49, 721), meta=np.ndarray\u0026gt; pp (t, x, y, z) float32 dask.array\u0026lt;chunksize=(1, 721, 49, 721), meta=np.ndarray\u0026gt;   Now we have a real case using a xarray dataset; This is from a polidispersed Turbidity Current in Axisymmetric Configuration; We start with an empty dataset, and them populate it with all the variables from our simulation; You see here the three velocity components and pressure; With toolbox, we can read all files at once; Besides five scalar fractions are concatenated in just one array with this command here; And finally, we can see the dataset, with:  5 scalar fractions, from 76 snapshots in time, with this spatial resolution; The coordinates are also INCLUDED. With xarray, we can do many operations calling the coordinates by name, it is very powerful; and we see the five variables.   For me, it is really impressive to have ALL data AVAILABLE FOR US at once here in this single object; But JUST MAKE SURE to have have enough memory for it! Now, lets see how to use it    Xarray - Working with coordinates ds.phi.sel(t=10.0).mean(\u0026quot;y\u0026quot;).plot(col=\u0026quot;n\u0026quot;)  ds['suspended'] = ds.phi.integrate([\u0026quot;x\u0026quot;, \u0026quot;y\u0026quot;, \u0026quot;z\u0026quot;]); ds.suspended.plot(hue=\u0026quot;n\u0026quot;)  ds['w1'] = ds.uz.differentiate(\u0026quot;y\u0026quot;) - ds.uy.x3d.first_derivative(\u0026quot;z\u0026quot;)   In the first example:  From the dataset, we select the scalar; I\u0026rsquo;m choosing JUST where time is equals to 10.0; Computing a vertical average calling the coordinate by its name; And finally a plot for reference, presenting each scalar fraction in a different figure; The settling velocity is different for each fraction, so that is why the concentration is decreasing from LEFT to RIGHT;   In the second line, I\u0026rsquo;m showing how to compute the suspended material, it is defined as the volumetric INTEGRATION of the concentration fields, we can code it in this way, and again a plot for reference; And the last code shows how to compute the first component of VORTICITY;  It is equal to duz / dy SUBTRACTING duy / dz; We can use the standard second order scheme from xarray; Or the high order alternative from the toolbox;   From my experience working with xarray, we can solve more complicated PROBLEMS with FEWER lines of code; Besides, calling the coordinates by their name, makes our code VERY READABLE, AND CONSEQUENTLY, it is easier to collaborate, share and maintain;    Could we handle larger-than-memory Datasets?   Yes, if the files were written as NetCDF:\nds = xr.open_mfdataset(\u0026quot;./data/3d_snapshots/*.nc\u0026quot;)    Actually, it is just what we did! In the previous example we handled a 66,5GB dataset in a 8GB virtual machine;\n  Let\u0026rsquo;s consider implementing I/O with NetCDF at XCompact3d?\n  Note: I\u0026rsquo;ve written a script to convert raw binaries to NetCDF, in order to test this concept.\n But, how about this question? Can we handle larger-than-memory Datasets? Yes, we can, and we just did it; The example WE JUST SAW WAS A 60 GB dataset, working on a 8 GB virtual machine in our campus, that I accessed remotely; I wrote a script to convert the RAW BINARIES to NetCDF, aiming to test this CONCEPT; And now you tell me, would you like to work in this way?  Opening the entire dataset with just one command line? It uses lazy computation, so the data will only be transfered to the memory when demanded;   Which leads to another question: Let’s consider implementing I/O with NetCDF at XCompact3d?    Integrating Python and XCompact3d  Now talking more specifically about the integrating between Python and XCompact3d    F2PY - Fortran to Python interface generator ! xcompact3d.f90 | mpirun -n 4 ./xcompact3d program xcompact3d use core implicit none call init_xcompact3d() call main_loop() call finalise_xcompact3d() end program xcompact3d  # xcompact3d.py | mpirun -n 4 python xcompact3d.py from xcompact3d import core if __name__ == '__main__': core.init_xcompact3d() core.main_loop() core.finalise_xcompact3d()  Note: This example actually works, and with no performance penalty.\n F2PY is a tool from the Scipy / Numpy universe, it is a FORTRAN TO PYTHON INTERFACE GENERATOR; And this is a working prototype; I just rearranged a little the FORTRAN code, putting everything in this module called core, so we can still run it; F2PY produces the Python interface; And now we can access the same module core here in Python, and we can, actually, run the simulation WITH NO PERFORMANCE PENALTY; Because we are running with the exactly same compiled code; AND, AFTER TESTING IT, A HAD SOME IDEAS.    Overview / Objectives  Make key subroutines available in Python; Testing them individually with unittest will increase XCompact3d\u0026rsquo;s maintainability; Distributing the compiled code with pip may increase our user base.   Using F2PY, we could make some key subroutines available in Python:  For the simulation itself, but also post-processing;   We could test them with UNITARY TEST, increasing the codes MAINTAINABILITY; We could distribute the compiled code, in order to increase our user base; And all of this with no significant change at the fortran code; So, of course, it would be still possible to download the code from source, compile it, and keep our WORKFLOW just as it is today, but OPENING SOME new possibilities.    F2PY - Fortran to Python interface generator The next steep from xcompact3d import core, solver if __name__ == \u0026quot;__main__\u0026quot;: core.init_xcompact3d() my_own_initial_conditions() # Low cost, very customizable while solver.is_running: my_own_boundary_conditions() # Low cost, very customizable solver.advance_time() # High performance with Fortran code my_own_postprocessing() # Low cost, very customizable core.finalise_xcompact3d()  Note 1: Here we have every Python tool at our disposal, like modules for optimization, control, visualization, machine learning, I/O, GPU accelerated computing (CuPy), etc. Note 2: It results in a very customizable interface without affecting the main code in Fortran.\n This is how I plan the next step; We could make more routines available, for instance, open up the main loop;  There is here at the begging, lets say, my own boundary conditions coded in Python, very customizable; From the solver, we call advance_time with the performance and scalability that we are USED to; After that, we could call on board postprocessing, again, very customizable in Python.   The main point here is that we have EVERY Python tool at our DISPOSAL, like modules for optimization, control, visualization, machine learning, I/O, maybe some GPU accelerated computing and many others. It results in a very flexible interface without affecting the main code in Fortran.    It is time to discuss the conclusions  Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n 🏠 fschuch.com ✉ felipe.schuch@edu.pucrs.br\n www.fschuch.com/en/slides/2021-x3d-showcase --  THAT IS IT, I have no conclusion, because I think we could discuss IT NOW; So, Please, let me know what do you think about it.   ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"073cf2d757d52e94fba68ad2f1269cc0","permalink":"https://www.fschuch.com/slides/2021-x3d-dev-meeting/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/2021-x3d-dev-meeting/","section":"slides","summary":"Python and XCompact3d XCompact3d 2021 Online Developer Meeting Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n Hi, my name is Felipe; Today I gonna talk about Python and XCompact3d; Starting with a quick introduction; Then I gonna show a little bit of what I\u0026rsquo;ve been doing in this TOPIC; And finally, I will bring some points for discussion here with you, especially AIMING to improve the synergy between Python and XCompact.","tags":[],"title":"Python and XCompact3d","type":"slides"},{"authors":[],"categories":[],"content":"Sandbox flow configuration: A rapid prototyping tool inside XCompact3d  Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n Hi, my name is Felipe; I\u0026rsquo;m glad to be here today REPRESENTING our LAB; LaSET is the CFD LAB here at PUC rio grande do sul, And this is our work: Sandbox flow configuration: A rapid prototyping tool inside XCompact3d    Motivation  Starting with the motivation for this work, there are two main points to highlight      How can we speed up our workflow?\n  Can we improve the learning curve for beginners in our code?\n    The first is:\n How can we speed up our workflow? I mean, the iterations here the scientific PROCESS; But more specifically, How can we speed up the iterations here in the simulation cycle.    and the second point:\n Can we improve the learning curve for beginners in our code? And especially, how to help them to code new flow configurations, going beyond the benchmark cases.      Identifying the main challenges  Using parallel computation in a distributed-memory system and Message Passing Interface;   Illustration of the 2D domain decomposition from 2DECOMP\u0026amp;FFT. \n Coding, compiling, testing, debugging and handling I/O in Fortran.   This leads us to identify the main challenges in our workflow, if we would like to make it easier for beginners and faster for developers; I would say, the PARALLEL DECOMPOSITION IS GREAT for performance and scalability, but it takes a while to master allocation, transpositions and all the MPI calls; Besides that, coding, compiling, testing, debugging and handling I/O in Fortran is not so easy, it is another point that we would like to improve.    Methodology  The PROBLEMS WERE identified, now, lets see how to solve them!    Sandbox Flow Configuration (BC-Sandbox.f90)\n The initial set-up is imported from external files; The choice of the external tool is up to the user:  Fortran, Matlab, Octave, R, Julia; Python with just Numpy or more specific tools (Py4Incompact3D or Xcompact3d-toolbox);   It adds no extra dependency to the workflow.   This is the Sandbox Flow configuration. Of course, xcompact3d already reads the PARAMETERS FILE at initialization, but with the new MODULE SANDBOX, the entire initial set-up can be imported from the disk; Using it, we can customize any new flow configuration with no need to RECOMPILE the code every time. The initial set-up includes case specific definitions, like: Initial condition; Boundary conditions; Geometry; Others. It can be provided EXTERNALLY. Our INTENTION was to keep it simple, but using the disk is still very USEFULL, because with it, the choice of what to use as external tool is totally up to the user:  It can be Fortran, Matlab, R, Julia, Python, and many others, as long as you can write binary arrays in the same fashion that xcompact3d would do.   And here we have a good point: This framework can speed up our workflow, and at the same time, there is no extra DEPENDENCIES to install. Besides, the core of the code was UNTOUCHED, so we have the usual performance in the code, combined with FLEXIBILITY for initial definitions; In this way, we use the right tool for the right task.    Variables handled by Sandbox  Initial condition for velocity and scalar field(s); Inflow profiles for velocity and scalar field(s) (if nclx1=nclxS1=2); Top and bottom boundary values for scalar field(s) (if nclyS1=2 or nclySn=2); Customized operator for the imposition of constant flow rate (if nclx1=nclxn=0); $\\epsilon$ array, describing the solid geometry for IBM (if iibm $\\ne$ 0).  See README for more details.\n Here we see what we can do with sandbox:  We should always specify the initial condition for velocity and the scalar fields; But the other arrays are just demanded in specific situations: Like, we can specify inflow profiles for velocity and scalar if we use Dirichlet boundary condition where x is equals to 0; We can also set scalar values at the bottom and top boundaries if we use Dirichlet; We can specify a customized operator if we want to impose a constant flow rate in a periodic flow; And we set a epsilon array if using Immersed Boundary Method.      An example using Python and Numpy import numpy as np ux = np.zeros(shape=(nx, ny, nz), dtype=np.float64) uy = np.zeros_like(ux) uz = np.zeros_like(ux) phi = np.zeros(shape=(nx, ny, nz, numscalar), dtype=np.float64) # Sequence of operations to set the initial condition ux.T.tofile('./data/ux.bin') uy.T.tofile('./data/uy.bin') uz.T.tofile('./data/uz.bin') for n in range(numscalar): phi[:,:,:,n].T.tofile('./data/phi{}.bin'.format(n+1))  Note: The initial set-up can be provided from any other language, as long as the files are written as raw binaries (compatible with 2DECOMP\u0026amp;FFT) and the filenames are correct.\n Here is an example of how to set the initial condition in Python with Numpy; We initialize the arrays with the right shape and data type; Then, we take advantage of Python\u0026rsquo;s flexibility and readability to set the values for our flow configuration; Besides, we can combine with other tools to plot, compute and test our set-up. And finally, we write them to the disk, so they will be available for the module sandbox.    Cases Covered by Sandbox    Case IC BC FRC IBM LMN     Channel-Flow ✔️  ✔️     Cylinder ✔️ ✔️  ✔️    Lock-exchange ✔️ ✔️   ⚠️   Periodic Hill ✔️  ✔️ ✔️    Taylor–Green vortex ✔️       TBL ✔️ ⚠️ ⚠️      Note: Initial Condition (IC); Boundary Conditions (BC); Flow rate Control (FRC); Immersed Boundary Method (IBM); Low Mach Number (LMN).\n Here we see an estimation of the cases covered by sandbox at this moment; We can simulate Channel-flow, flow around a cylinder, Periodic Hill and TGV; Density current in the lock-exchange will work too, as long as we are not using the low mach number approach, it was not implemented in the module yet; Well, it is a work in progress; And the turbulent boundary layer demands more specific definitions of boundary conditions and flow rate control, so it is also not supported. But, like I told you, it is just an estimation, because now we can play around and modify any of these cases.   .bin` | (nx, ny, nz) | `numscalar $$ 0` | --- ### It supports Boundary Condition | Filename | Shape | Demanded | | ----------- | ------| -------- | | `bxx1.bin` | (ny, nz) | `nclx1=2` | | `bxy1.bin` | (ny, nz) | `nclx1=2` | | `bxz1.bin` | (ny, nz) | `nclx1=2` | | `bxphi1.bin` | (ny, nz) | `nclxS1=2` | | `byphi1.bin` | (nx, nz) | `nclyS1=2` | | `byphin.bin` | (nx, nz) | `nclySn=2` | --- ### It supports other arrays | Filename | Description | Demanded | | ----------- | ----------- | -------- | | `geometry.bin` | $\\epsilon$ array set to 1 inside the solid and zero otherwise | `iibm $\\ne$ 0` | | `vol_frc.bin` | Customized operator to impose constant flow rate | `nclx1=nclxn=0` | --- --  Case Study  For example, we are going to merge the periodic channel and the flow around a cylinder\u0026hellip;    Periodic Heat Exchanger  Periodic boundary conditions in x and z; A cylinder at the center with low temperature; No-slip conditions for velocity at top and bottom, besides, high temperature at the walls.   Besides combining it with HEAT TRANSFER, in what I called, The Period Heat Exchanger. We have periodic boundary conditions in the streamwise and spanwise directions; A cylinder at the center of the domain with its dimensionless temperature fixed at zero; And no-slip BC at the bottom and top walls, and their temperature fixed in one. Lets see how to code it!    Initialization \u0026gt;\u0026gt;\u0026gt; import xcompact3d_toolbox as x3d \u0026gt;\u0026gt;\u0026gt; import xcompact3d_toolbox.sandbox \u0026gt;\u0026gt;\u0026gt; prm = x3d.Parameters(loadfile='input.i3d') \u0026gt;\u0026gt;\u0026gt; dataset = x3d.sandbox.init_dataset(prm) \u0026gt;\u0026gt;\u0026gt; dataset  \u0026lt;xarray.Dataset\u0026gt; Dimensions: (n: 1, x: 128, y: 129, z: 8) Coordinates: * x (x) float64 0.0 0.04688 0.09375 0.1406 ... 5.812 5.859 5.906 5.953 * y (y) float64 0.0 0.04688 0.09375 0.1406 ... 5.859 5.906 5.953 6.0 * z (z) float64 0.0 0.04688 0.09375 0.1406 0.1875 0.2344 0.2812 0.3281 * n (n) int32 0 Data variables: byphi1 (n, x, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 byphin (n, x, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 ux (x, y, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 uy (x, y, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 uz (x, y, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 phi (n, x, y, z) float64 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 vol_frc (x, y, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0   I\u0026rsquo;m using xcompact3d-toolbox just because I\u0026rsquo;m more familiar with it; We start here importing the Package; Lets say that we already had set all the correct parameters at the input file, so now we load it; And we start the dataset. It is returned to us with the proper dimensions, coordinates and the SEVEN data variables that we are going to work with now    Boundary Conditions High temperature at the bottom and top walls:\n$$ \\Theta(x,y=0,z,t) = 1 $$\n$$ \\Theta(x,y=L_y,z,t) = 1 $$\n\u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;byphi1\u0026quot;] += 1.0 \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;byphin\u0026quot;] += 1.0   We start setting the temperature as one at the bottom and top walls, like specified for our new flow configuration;    Initial Condition \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;ux\u0026quot;] += velocity_profile + random_noise \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;uy\u0026quot;] += random_noise \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;uz\u0026quot;] += random_noise \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;phi\u0026quot;] += 1.0  Note: Part of the code was not presented, for simplicity.\n Now, lets set the initial condition for the streamwise velocity as this vertical profile in addition to some random noise, and just random noise for uy and uz; And the initial temperature will be one everywhere.    Geometry \u0026gt;\u0026gt;\u0026gt; epsi = x3d.sandbox.init_epsi(prm) \u0026gt;\u0026gt;\u0026gt; for array in epsi.values(): ... array = array.geo.cylinder(x=prm.xlx / 2.0, y=prm.yly / 2.0) ... \u0026gt;\u0026gt;\u0026gt; epsi[\u0026quot;epsi\u0026quot;].isel(z=0).plot()   Now it is time to set the geometry, a cylinder in the center of the domain. Notice that xcompact3d-toolbox includes methods to DRAW many standards geometries. Here we are using the cylinder, we just have to specify its center AND WE ARE GOOD TO GO.    Flow rate Control \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;vol_frc\u0026quot;] += prm.dy / prm.yly / prm.nx / prm.nz \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;vol_frc\u0026quot;][dict(y=0)] *= 0.5 \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;vol_frc\u0026quot;][dict(y=-1)] *= 0.5 \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;vol_frc\u0026quot;] = dataset.vol_frc.where(epsi == False, 0.0) \u0026gt;\u0026gt;\u0026gt; dataset.vol_frc.isel(z=0).plot()  Note: The code will compute the stream-wise flow rate as int = sum(vol_frc * ux), and correct the stream-wise velocity as ux = ux / int.\n Since the domain is periodic in x, we need to specify a forcing term to maintain a constant flow rate, As you see here, xcompact3d will compute the flow rate with this integration, so we can CUSTOMIZE this operator for the volumetric integration; This one will give us a unitary value per HEIGHT unit, and will include an average in x and z. We multiply both top and bottom plane by half because of the composed trapezoidal rule for integration; And of course, we can disconsider the cylinder when integrating.     Now we save the arrays to the disk: \u0026gt;\u0026gt;\u0026gt; dataset.x3d.write(prm) \u0026gt;\u0026gt;\u0026gt; x3d.gene_epsi_3D(epsi, prm)   And run the simulation: mpirun -n [number of cores] ./xcompact3d |tee log.out   There is no need to recompile the code every time; We can code, test, plot and debug the initial set-up interactively in a Jupyter Notebook (or any other computational tool).   Now it is time to write all the variables to the disk and run the simulation; Notice that there is no need to RECOMPILE the code every time; And we can code, test, plot and debug the initial set-up using any computational tool, like a Jupyter Notebook, and make it very INTERACTIVE;    Periodic Heat Exchanger\n View the code online.\n Here we see an animation of the case that we just coded, the periodic heat exchanger; It is just a toy model, the Reynolds Number is very low, but you are invited to access the complete code here in this link, and play around with the parameters and definitions; You can access the slides using the QR CODE at the end of this talk. Any way, I have a few more examples to show to you\u0026hellip;     View the code online.\n We are looking in a top view, that is presenting the depth-averaged concentration of the turbidity current in asymmetric configuration. This one is just like Ricardo explained to us earlier in HIS talk, but this time the denser fluid starts here at the bottom left corner and can spread in more directions. We can see the lobes-and-clefts near the front, how some rings are formed in the body and them they break down, and many other nice features.     View the code online.\n End the last example is the flow around a square with passive scalar as a visualization tool. Here at the inlet we have this smooth step function for the passive scalar, as a result, we can see this nice pattern downstream due to the turbulence; As always, everything is very CUSTOMIZABLE. We could change the position of the square, we could include more squares; change the number os steeps here at the inlet;    Bonus  And I have a special bonus for you    User Interface with IPywidgets (try it online)\n [Try it online](https://xcompact3d-toolbox.readthedocs.io/en/latest/tutorial/parameters.html#). --  I\u0026rsquo;ve talked about improving the learning curve for beginners in our code, and here is another initiative. We have this user interface with IPywidgets under development in our LAB; Using it, we can enforce the right relationship between the parameters, just to make sure they are compatible with xcompact3d; You can see here that we ensure that booth boundaries in one direction will be periodic or not, and the number of mesh points goes BACK and FORWARD properly. There are more features, but I will leave the link here, so you can try it.    Conclusion  The outcome of this work benefits users from different levels:  For students in CFD, it provides direct hands-on experience and a safe place for practising and learning; For advanced users and code developers, it works as a rapid prototyping tool; Furthermore, it is a useful advance in terms of research reproducibility.  Note: module sandbox is still in pre-release (fschuch/Xcompact3d).\n To conclude this talk, we EXPECT to help USER from different levels with our framework;  For students in CFD, it provides direct hands-on experience and a safe place for practising and learning; For advanced users and code developers, it works as a rapid prototyping tool; Furthermore, it is a useful advance in terms of research reproducibility, because now it is easier to create, collaborate and share any new flow configuration.      Questions?  Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n 🏠 fschuch.com ✉ felipe.schuch@edu.pucrs.br\n www.fschuch.com/en/slides/2021-x3d-showcase --  THAT IS IT, tank you very much for your ATTENTION; I\u0026rsquo;m ready to take any questions now.   ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"20eb7637c67ce93dcdf96a6b01bec1e7","permalink":"https://www.fschuch.com/slides/2021-x3d-showcase/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/2021-x3d-showcase/","section":"slides","summary":"Sandbox flow configuration: A rapid prototyping tool inside XCompact3d  Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n Hi, my name is Felipe; I\u0026rsquo;m glad to be here today REPRESENTING our LAB; LaSET is the CFD LAB here at PUC rio grande do sul, And this is our work: Sandbox flow configuration: A rapid prototyping tool inside XCompact3d    Motivation  Starting with the motivation for this work, there are two main points to highlight      How can we speed up our workflow?","tags":[],"title":"Sandbox flow configuration: A rapid prototyping tool inside XCompact3d","type":"slides"},{"authors":[],"categories":[],"content":"Xarray, estruturas para dados multidimensionais Tutorial para Python Brasil 2020, por Felipe N. Schuch.\n  Disponível aqui ⬆️   Felipe N. Schuch 🏠 fschuch.com ✉ felipeschuch@outlook.com\n Pesquisador em Fluidodinâmica Computacional na PUCRS, com interesse em: Escoamentos turbulentos, transferência de calor e massa, e interação fluido-estrutura; Processamento e visualização de dados em Python; Jupyter Notebook como uma ferramenta de colaboração, pesquisa e ensino.\n  Projetos   LaSET-PUCRS - Laboratório de CFD; Xcompact3d - Solver de Navier-Stokes; Xcompact3d Toolbox - Pacote Python para lidar com dados de simulação; Aprenda.py - Siga no Instagram @aprenda.py.   Estrutura do Tutorial  Introdução + Estruturas para dados Multidimensionais; Trabalhando com dados mapeados; Computação com Xarray; Gráficos e Visualização; Introdução ao Dask; Dask e Xarray para computação paralela.   ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"8362ca31678d96e26b6cf24f768ab37a","permalink":"https://www.fschuch.com/slides/2020-python-brasil/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/2020-python-brasil/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Felipe N. Schuch"],"categories":null,"content":"","date":1459382400,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"84390ba971bf83a22ed739c0282b5370","permalink":"https://www.fschuch.com/publication/2016-master-thesis/","publishdate":"2016-03-31T00:00:00Z","relpermalink":"/publication/2016-master-thesis/","section":"publication","summary":"O estudo dos mecanismos de transporte e deposição dos sedimentos em canal ganhou destaque nas últimas décadas, já que antigos depósitos sedimentares no leito do mar formam importantes reservatórios de hidrocarbonetos. A intenção desta pesquisa é investigar, através de simulação numérica direta, a dinâmica do fenômeno de mergulho que ocorre quando um escoamento carregado de partículas em suspensão adentra em um ambiente de menor densidade. Para tanto, utiliza-se o código computacional Incompact3d, baseado na solução da equação de Boussinesq para fluidos incompressíveis. É investigada a influência da vazão e concentração de sedimentos na entrada do canal sobre o ponto de mergulho e perfis de deposição, e os resultados são comparados com modelos teóricos e experimentos físicos.","tags":["Xcompact3d"],"title":"Análise de pluma hiperpicnal poli-dispersa por simulação numérica direta","type":"publication"},{"authors":["Felipe N. Schuch","L.C. Pinto","J.H. Silvestrini"],"categories":null,"content":"","date":1411344e3,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"b0fc0fefc13f5dc9fd63d50acc77d1cd","permalink":"https://www.fschuch.com/publication/2014-eptt/","publishdate":"2014-09-22T00:00:00Z","relpermalink":"/publication/2014-eptt/","section":"publication","summary":"O presente trabalho tem como objetivo analisar o comportamento do escoamento estratificado por partículas em suspensão e salinidade através de Simulação Numérica Direta (DNS). Para tanto, utilizou-se o código computacional Incompact3D, baseado na solução das equações governantes do escoamento assumindo a hipótese de Boussinesq para fluidos incompressíveis. Os efeitos de estratificação devem-se a diferenças na concentração de partículas suspensas e a salinidade dissolvida no escoamento. As simulações numéricas foram realizadas nas configurações bi- e tri-dimensionais de um canal contendo um fluido com salinidade dissolvida onde há a entrada de outro fluido com partículas em suspensão. A fim de observar a relação do tamanho dos sedimentos bem como a sua influência na coluna de água, foram realizadas doze simulações com a variação destes parâmetros, considerando três diferentes números de Richardson e três diferentes velocidades de queda de partículas. Outras três simulações numéricas são apresentadas, com a finalidade de estudar diferentes condições iniciais e de entrada do problema. Os resultados mostram que o escoamento apresenta maior sensibilidade com relação à variação da velocidade de queda enquanto o número de Richardson da partícula é pouco influente. Observa-se ainda que as condições iniciais influenciam no tempo necessário para que o escoamento se torne estatisticamente estacionário.","tags":["Xcompact3d"],"title":"Simulação numérica de escoamentos estratificados por partículas em suspensão e salinidade","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"936945c39701263ff8a691972d30dc06","permalink":"https://www.fschuch.com/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"1cbdeb1165fdf4841e39ed8818bbf647","permalink":"https://www.fschuch.com/project/jobbergate/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/jobbergate/","section":"project","summary":"Jobbergate é um sistema usado para gerenciar aplicações reutilizáveis por meio da geração de scripts específicos de submissão, que podem ser enviados via Slurm para execução em um cluster.","tags":["HPC","Python","Slurm","Jobbergate"],"title":"Jobbergate","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1751736705,"objectID":"b9a957dcd41bfd5342d2f0d51c379682","permalink":"https://www.fschuch.com/project/xcompact3d/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/xcompact3d/","section":"project","summary":"Aplicação acadêmica de alta ordem para a resolução das equações de Navier-Stokes e transporte de escalares, desenvolvido para super-computadores.","tags":["CFD","Fortran","HPC","Xcompact3d"],"title":"Xcompact3d","type":"project"}]