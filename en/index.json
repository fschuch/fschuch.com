[{"authors":["admin"],"categories":null,"content":"I have the experience of applying and also developing computational tools that are able to solve complex problems, besides processing, visualizing, and communicating the data produced by these solutions. They are often powered by High-Performance Computing (HPC).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1751736705,"objectID":"d2786ecec31efa109e957a3463269b31","permalink":"https://www.fschuch.com/en/author/felipe-n.-schuch/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/felipe-n.-schuch/","section":"authors","summary":"I have the experience of applying and also developing computational tools that are able to solve complex problems, besides processing, visualizing, and communicating the data produced by these solutions. They are often powered by High-Performance Computing (HPC).","tags":null,"title":"Felipe N. Schuch","type":"authors"},{"authors":null,"categories":null,"content":"Table of Contents  Introduction Methodology  Localization Style Dimensions Format   Conclusion    Introduction The synthesis and analysis of data and results in graphical form is a topic of interest for professionals from the most diverse areas, whether in the production of technical/scientific, educational content, or for digital media outreach. A good figure will attract the attention of your target audience.\nThere are four topics that, in my opinion, directly influence the final result of the plots that will be produced, especially when we talk about publication quality. They are:\n Localization: Numerical formatting should be in accordance with the language for which you\u0026rsquo;re producing content, whether in formatting dates, currency, or even the decimal separator; Style: Here various visual aspects are defined, such as the plot\u0026rsquo;s color scheme, axes and background, font, and other elements. It\u0026rsquo;s important to maintain consistency across the various plots that will constitute the same document; Dimensions: The definition of the figure\u0026rsquo;s width and height, as well as font size, should be consistent with the type of content where the plot will be inserted, whether in slides, poster, report, article, social media posts and many others; Format: The format in which figures will be saved. Vector options are preferable because they maintain good visual presentation even on high-resolution screens or prints, or when figures are enlarged.   Methodology The points above will be addressed in Python, or more specifically, in the Matplotlib package, which is a 2D plotting library that produces publication-quality figures in a variety of print formats and interactive environments across multiple platforms. Matplotlib can be used in Python scripts, Python and IPython shells, Jupyter Notebook, web application servers, and four graphical user interface toolkits. Matplotlib tries to make easy things easy and hard things possible. You can generate plots, histograms, power spectra, bar charts, error plots, scatter plots, etc., with just a few lines of code.\nAdditionally, Matplotlib plotting functions are integrated with major data management solutions in Python, such as NumPy, Pandas, Xarray, Dask and many others.\nRefer to the Matplotlib documentation for the best way to install it on your system. We can import it into our code with:\nimport matplotlib.pyplot as plt  Now let\u0026rsquo;s specifically address each topic listed for producing publication-quality figures.\nLocalization If your interest is to produce content in English, I suggest you skip to the next topic. Otherwise, we can use the locale package to ensure consistency of our figures with the standards of Portuguese, for example, or really any other language. To do so, we can import the package and set the default language as Portuguese:\nimport locale locale.setlocale(locale.LC_ALL, \u0026quot;pt_BR.utf8\u0026quot;)  All customizable parameters are stored in the dictionary plt.rcParams, a complete view is available on its Documentation page, but don\u0026rsquo;t worry, the main points will be demonstrated here.\nThe next step is to inform that we want to use another language for notation on the plot axes, for example, using , as decimal separator, we do this with the following code:\nplt.rcParams.update( { 'axes.formatter.use_locale' : True, } )  It doesn\u0026rsquo;t make sense to confuse the audience with different decimal separators if we can easily solve this with three lines of code, right?\nNotice that this definition is only valid for figure axes, not modifying the behavior of Python\u0026rsquo;s core itself, for example:\nvalue = 0.67 print(value)  0.67  Note that the print still uses the dot as decimal separator. For prints, annotations or legends in figures, we can use the locale.str() method to automatically format floating-point numbers:\nprint(locale.str(value))  0,67  This can be a good practice, since you just need to return one line of code to English (locale.setlocale(locale.LC_ALL, \u0026quot;en_US.utf8\u0026quot;)), and all the rest of the code will behave appropriately.\nIt\u0026rsquo;s also possible to easily format monetary data:\nprint(locale.currency(value))  'R$ 0,67'  And date formatting, with the time package, see:\nfrom time import gmtime, strftime strftime(\u0026quot;%a, %d %b %Y %H:%M:%S +0000\u0026quot;, gmtime())  'Wed, 14 Oct 2020 22:31:50 +0000'  Style Now let\u0026rsquo;s talk about figure style, including color sequence, axis style, background color, presence or absence of grid, as well as its own style, annotation formatting and many other details.\nA series of styles are already prepared and included in the library, and all of them are available in Documentation - Matplotlib. From there, I took some to exemplify the range of possibilities we have at our disposal:\n              \nWe indicate the use of a style by its name, and the following command:\nplt.style.use('ggplot')  It\u0026rsquo;s also possible to combine various styles in a list, to produce unique results:\nplt.style.use(['ggplot', 'dark_background'])  Note that styles further to the right will overwrite parameters previously defined by styles to the left, so the order in which they are provided can change the final result.\nYou can still customize each aspect of the plots individually, for more details, I suggest consulting the Documentation - Matplotlib. If you want to return to the original parameters, use:\nplt.rcdefaults()  Dimensions Another essential point: the relationship between figure size and font size. When we talk about publication quality, the texts and numbers in plots should be exactly the same size as the rest of the document where they are inserted.\nThe ideal here is the precise definition of the width and height you want for the figure, so that it can be inserted in the final document at a 1:1 scale, without any distortion.\nThere\u0026rsquo;s a Python package of my authorship that facilitates this task, figure-scale. More details can be found in its Documentation, but here we\u0026rsquo;ll see a usage example.\nFirst, we need to install the package:\npip install figure-scale  The FigureScale class is the main component of the package. It allows you to define figure dimensions in whatever way is most convenient for your case:\n Width and Height: Specify both dimensions explicitly; Width and Aspect Ratio: Specify the width and let the height be calculated from the aspect ratio; Height and Aspect Ratio: Specify the height and let the width be calculated from the aspect ratio.  All dimensions can be specified in various units. Let\u0026rsquo;s explore each approach:\nimport figure_scale as fs size_a = fs.FigureScale(units=\u0026quot;mm\u0026quot;, width=100, height=100) size_b = fs.FigureScale(units=\u0026quot;mm\u0026quot;, width=100, aspect=1.0) size_c = fs.FigureScale(units=\u0026quot;mm\u0026quot;, height=100, aspect=1.0)  Let\u0026rsquo;s detail each parameter:\n width is the usable page width, that is, the page width minus both margins. Or the column width, for cases where this applies. In $\\LaTeX$ documents, this value can be obtained with the command \\the\\columnwidth; height can be used for absolute height adjustment, if fine-tuning is desired. In $\\LaTeX$ documents, this value can be obtained with the command \\the\\textheight; aspect defines the figure height as a relative value in relation to width. For example, aspect=1.0 will create a square figure, while aspect=9.0/16.0 will create the right proportion for wide-screen displays; units represents the length unit for width and height, some of the supported options are \u0026ldquo;in\u0026rdquo; (inch), \u0026ldquo;mm\u0026rdquo;, \u0026ldquo;cm\u0026rdquo; and \u0026ldquo;pt\u0026rdquo; (typographic points, used in $\\LaTeX$). Thus, the object performs the proper unit conversion, since Matplotlib expects this definition in inches.  Note that only two of the three parameters width, height and aspect are necessary, the third will be calculated automatically from the other two. The FigureScale class implements the Sequence protocol, making it acceptable as an argument for the figsize parameter in any Matplotlib function that accepts it, such as plt.subplots(), plt.figure() and others.\nSee how we can now precisely define the standard we want for dimensions and font size:\nplt.rcParams.update( { # 'figure.figsize' : fs.FigureScale(units='mm', width=160, aspect=1), # \u0026quot;axes.labelsize\u0026quot;: 12, \u0026quot;font.size\u0026quot;: 12, \u0026quot;legend.fontsize\u0026quot;: 12, \u0026quot;xtick.labelsize\u0026quot;: 12, \u0026quot;ytick.labelsize\u0026quot;: 12, } )  It\u0026rsquo;s possible to later make a custom adjustment for each figure, for example:\nfig, axes = plt.subplots(figsize=fs.FigureScale(units='mm', width=160, aspect=1))  All my technical/scientific production has been done in $\\LaTeX$, which I certainly recommend. In fact, this could be a topic for another post in the near future. If this isn\u0026rsquo;t your case, it might be time to proceed to the next topic. Either way, I\u0026rsquo;ll share some other adjustments for reference:\n  Article with Elsevier\u0026rsquo;s two-column template:\nplt.rcParams.update( { 'figure.figsize' : fs.FigureScale(units='pt', width=238.25444, aspect=3/4), # \u0026quot;axes.labelsize\u0026quot;: 8, \u0026quot;font.size\u0026quot;: 8, \u0026quot;legend.fontsize\u0026quot;: 8, \u0026quot;xtick.labelsize\u0026quot;: 8, \u0026quot;ytick.labelsize\u0026quot;: 8 } )    Technical report, Dissertation or Thesis with abnTeX2:\nplt.rcParams.update( { 'figure.figsize' : fs.FigureScale(units='pt', width=455.0, aspect=3/4), # \u0026quot;axes.labelsize\u0026quot;: 12, \u0026quot;font.size\u0026quot;: 12, \u0026quot;legend.fontsize\u0026quot;: 12, \u0026quot;xtick.labelsize\u0026quot;: 12, \u0026quot;ytick.labelsize\u0026quot;: 12, } )    A0 size poster with beamer (and this template):\nplt.rcParams.update( { 'figure.figsize' : fs.FigureScale(units='pt', width=2376.3973*.75, aspect=9/16), # \u0026quot;axes.labelsize\u0026quot;: 24, \u0026quot;font.size\u0026quot;: 24, \u0026quot;legend.fontsize\u0026quot;: 24, \u0026quot;xtick.labelsize\u0026quot;: 24, \u0026quot;ytick.labelsize\u0026quot;: 24, } )    Slide presentation with beamer (and the Focus v2.6 theme):\nplt.rcParams.update( { 'figure.figsize' : fs.FigureScale(units='pt', width=412.56497, aspect=9/16), } )    In $\\LaTeX$, you can be sure everything worked out when the figure is included with scale=1, and the dimensions and font size look appropriate, for example:\n\\includegraphics[scale=1]{\u0026lt;figure_name\u0026gt;}   Format Finally, we have the format in which the plots will be saved. They can be basically divided into two large groups, and we have a code block to exemplify:\nimport numpy as np x = np.linspace(0.0, 2.0 * np.pi) y = np.sin(x) for f in ['jpg', 'svg']: plt.plot(x,y, label = 'Label') plt.legend() plt.savefig('example_line.'+f, format=f)    Raster format: The figure consists of an array of pixels (or matrix), which has a defined size, for example 240 x 120 pixels. If we want to enlarge it, we\u0026rsquo;ll see each small pixel, in a somewhat squared effect. In this group we have, for example, JPG and PNG formats, see the result:\n  Raster format figure 768 x 576 pixels (jpg).  The figure quality is controlled by the number of pixels, or the dpi parameter (dots per inch). Increasing dpi increases image quality, but also increases its disk space;\n  Vector Format: Here, the figure is composed of vectors, using mathematical elements to compose the complete figure. Unlike the previous group, it doesn\u0026rsquo;t lose quality when enlarged. As examples we have SVG and PDF formats, see the figure:\n  Vector format figure (svg).    But after all, which one to choose? The answer is: it depends.\nI\u0026rsquo;d say vector options are preferable (svg for web, PDF for technical production) because they maintain good visual presentation even on high-resolution screens or prints, or when figures are enlarged. However, there are applications that simply don\u0026rsquo;t accept vector formats (like some social networks), so we can switch to raster format (jpg or png). Another challenge for vector format is when we have a high number of vector artifacts. Regardless of the type of plot, as the amount of data increases from hundreds, to thousands and millions of points, it might be that the space the vector figure occupies on disk is, after all, impractical.\nNote however that there\u0026rsquo;s an intermediate approach, methods in Matplotlib that allow converting vector elements to raster representation, called rasterization. To exemplify this, we have a modified code block from Documentation - Matplotlib, see the code and resulting figure:\nimport numpy as np import matplotlib.pyplot as plt d = np.arange(100).reshape(10, 10) x, y = np.meshgrid(np.arange(11), np.arange(11)) theta = 0.25*np.pi xx = x*np.cos(theta) - y*np.sin(theta) yy = x*np.sin(theta) + y*np.cos(theta) fig, (ax1, ax2, ax3) = plt.subplots(1, 3) ax1.set_aspect(1) ax1.pcolormesh(xx, yy, d) ax1.text(0.5, 0.5, \u0026quot;Text\u0026quot;, alpha=0.2, va=\u0026quot;center\u0026quot;, ha=\u0026quot;center\u0026quot;, size=50, transform=ax1.transAxes) ax1.set_title(\u0026quot;No Rasterization\u0026quot;) ax2.set_aspect(1) ax2.pcolormesh(xx, yy, d, zorder=-15) ax2.text(0.5, 0.5, \u0026quot;Text\u0026quot;, alpha=0.2, zorder=5, va=\u0026quot;center\u0026quot;, ha=\u0026quot;center\u0026quot;, size=50, transform=ax2.transAxes) ax2.set_title(\u0026quot;Rasterization z$\u0026lt;-10$\u0026quot;) ax2.set_rasterization_zorder(-10) ax3.set_aspect(1) ax3.pcolormesh(xx, yy, d) ax3.text(0.5, 0.5, \u0026quot;Text\u0026quot;, alpha=0.2, va=\u0026quot;center\u0026quot;, ha=\u0026quot;center\u0026quot;, size=50, transform=ax3.transAxes) ax3.set_title(\u0026quot;Rasterization\u0026quot;) ax3.set_rasterized(True) plt.savefig(\u0026quot;test_rasterization.pdf\u0026quot;, dpi=150) plt.savefig(\u0026quot;test_rasterization.eps\u0026quot;, dpi=150) if not plt.rcParams[\u0026quot;text.usetex\u0026quot;]: plt.savefig(\u0026quot;test_rasterization.svg\u0026quot;)    We see above a vector figure with three sub-plots:\n In the left element, we have the purely vector figure (No Rasterization), notice the good visual quality even when enlarged; The figure on the right was converted to raster format (Rasterization) with the line ax3.set_rasterized(True), including title, coordinates, annotation and the pcolormesh, even though the figure was saved as svg. Notice how it was totally represented pixel by pixel; In the center we have an intermediate solution. In this case, only elements with zorder1 less than -10 were transformed with the line ax2.set_rasterization_zorder(-10), in this case we have the pcolormesh. Title, coordinates and annotation remained vectorial, and thus, we can get the best of both worlds.  The effective choice about which elements to convert is again a compromise between image quality and its disk size, and this certainly depends on each application, or even personal preference. Note that dpi is still a valid parameter for elements converted to pixels.\nFinally, we can define these parameters to be applied as default in our code as follows:\nplt.rcParams.update( { 'figure.dpi' : 240, 'savefig.format' : 'pdf', # 'text.usetex' : True, 'text.latex.preamble' : \u0026quot;\\\\usepackage{icomma}\u0026quot;, } )  The text.usetex option is particularly useful for those who use $\\LaTeX$, allowing you to include equations as annotations, title or as label for coordinates. The option 'text.latex.preamble' : \u0026quot;\\\\usepackage{icomma}\u0026quot; is a bonus, this eliminates the space inserted in math mode after each comma, which are certainly not welcome when we talk about publication quality.\nConclusion The presentation of high-quality results is a fundamental point to attract engagement and attention from your audience. Here it was demonstrated how attention to details and a few lines of code can have a huge impact on the presentation of results in graphical format. Finally, I hope that this account of mine about producing figures in Python and Matplotlib will be useful to you as a starting point and motivation to continue studying the topic.\n  The zorder parameter controls the order in which each plot element will be displayed, that is, text with zorder=5 will be displayed over the pcolormesh figure with zorder=-15. For more information, consult the Documentation - Matplotlib.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":1751673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"f4f614a8e4a264978b40a727b493de46","permalink":"https://www.fschuch.com/en/blog/2025/07/05/publication-quality-plots-in-python-with-matplotlib/","publishdate":"2025-07-05T00:00:00Z","relpermalink":"/en/blog/2025/07/05/publication-quality-plots-in-python-with-matplotlib/","section":"post","summary":"Regardless of the type of content you're working on—whether technical, scientific, educational, or for social media—there are four key topics that directly influence the quality of the plots you're producing: Localization, dimensions, style, and format. All are covered in detail in this post.","tags":["Matplotlib","LaTeX","Python"],"title":"Publication-Quality Plots in Python with Matplotlib","type":"post"},{"authors":null,"categories":null,"content":"","date":1693612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"664b91942dbd4424518f774af0b41272","permalink":"https://www.fschuch.com/en/project/figure-scale/","publishdate":"2023-09-02T00:00:00Z","relpermalink":"/en/project/figure-scale/","section":"project","summary":"A Python package designed to help you create publication-quality figures with precise size control in Matplotlib","tags":["Python"],"title":"Figure Scale","type":"project"},{"authors":null,"categories":null,"content":"","date":1693612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"e841e49c080c9d96b85e84eaee2beb14","permalink":"https://www.fschuch.com/en/project/wizard-template/","publishdate":"2023-09-02T00:00:00Z","relpermalink":"/en/project/wizard-template/","section":"project","summary":"A general-purpose template that aims to provide a magical start to any Python project","tags":["Python"],"title":"Wizard Template","type":"project"},{"authors":["A.E. Giannenas","N. Bempedelis","Felipe N. Schuch","S. Laizet"],"categories":null,"content":"","date":1662336e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"3cba36753b4e3e87eb3f64edb04594ee","permalink":"https://www.fschuch.com/en/publication/2022-flow-turbulence-and-combustion/","publishdate":"2022-09-05T00:00:00Z","relpermalink":"/en/publication/2022-flow-turbulence-and-combustion/","section":"publication","summary":"The aim of the present numerical study is to show that the recently developed Alternating Direction Reconstruction Immersed Boundary Method (ADR-IBM) (Giannenas and Laizet in Appl Math Model 99:606–627, 2021) can be used for Fluid–Structure Interaction (FSI) problems and can be combined with an Actuator Line Model (ALM) and a Computer-Aided Design (CAD) interface for high-fidelity simulations of fluid flow problems with rotors and geometrically complex immersed objects. The method relies on 1D cubic spline interpolations to reconstruct an artificial flow field inside the immersed object while imposing the appropriate boundary conditions on the boundaries of the object. The new capabilities of the method are demonstrated with the following flow configurations: a turbulent channel flow with the wall modelled as an immersed boundary, Vortex Induced Vibrations (VIVs) of one-degree-of-freedom (2D) and two-degree-of-freedom (3D) cylinders, a helicopter rotor and a multi-rotor unmanned aerial vehicle in hover and forward motion. These simulations are performed with the high-order fluid flow solver Incompact3d which is based on a 2D domain decomposition in order to exploit modern CPU-based supercomputers. It is shown that the ADR-IBM can be used for the study of FSI problems and for high-fidelity simulations of incompressible turbulent flows around moving complex objects with rotors.","tags":["Xcompact3d"],"title":"A Cartesian Immersed Boundary Method Based on 1D Flow Reconstructions for High-Fidelity Simulations of Incompressible Turbulent Flows Around Moving Objects","type":"publication"},{"authors":["Felipe N. Schuch","E. Meiburg","J.H. Silvestrini"],"categories":null,"content":"","date":1625529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"c796aa0baf5d9fb331fcc592cf7b3187","permalink":"https://www.fschuch.com/en/publication/2021-computers-and-geosciences/","publishdate":"2021-07-06T00:00:00Z","relpermalink":"/en/publication/2021-computers-and-geosciences/","section":"publication","summary":"Hyperpycnal flows are observed when the density of a fluid entering into a quiescent environment is greater than that of the ambient fluid.\tThis difference can be due to salinity, temperature, concentration, turbidity, or a combination of them. Over a sloping bottom, the inflowing momentum decreases progressively until a critical stage is reached where the inflow plunges underneath the ambient and flows adjacent to the bed as an underflow density current. In the present work, a new equation is proposed in order to predict the critical depth for plunging, i.e., the plunging criterion. It differs from previous studies since it includes the role of the settling velocity and the bed slope. The high spatiotemporal resolution from twelve original numerical simulations allows us to validate the initial hypotheses established, in addition to numerical and experimental data available in the literature, and good agreement is found between them. A negative value for the mixing coefficient was observed for the first time for the hyperpycnal flow in a tilted channel. This indicates that if the settling velocity of the suspended material is high enough, the submerged flow may lose fluid to the environment (detrainment), instead of incorporating it. The proposed plunging criterion may assist in the design of future experimental or numerical works.","tags":["Plunging Flow","Xcompact3d"],"title":"Plunging condition for particle-laden flows over sloping bottoms: three-dimensional turbulence-resolving simulations","type":"publication"},{"authors":null,"categories":null,"content":"","date":1616159700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"b824c98951d0b43bae75648f0a9762a0","permalink":"https://www.fschuch.com/en/talk/python-and-xcompact3d/","publishdate":"2021-03-17T12:00:00-03:00","relpermalink":"/en/talk/python-and-xcompact3d/","section":"event","summary":"","tags":["CFD","HPC","Python","Xcompact3d"],"title":"Python and XCompact3d","type":"event"},{"authors":null,"categories":null,"content":"","date":1615564500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"2d975415386fcc292ed092b4a95ea33a","permalink":"https://www.fschuch.com/en/talk/sandbox-flow-configuration-a-rapid-prototyping-tool-inside-xcompact3d/","publishdate":"2021-03-09T15:00:00-03:00","relpermalink":"/en/talk/sandbox-flow-configuration-a-rapid-prototyping-tool-inside-xcompact3d/","section":"event","summary":"","tags":["CFD","HPC","Python","Xcompact3d"],"title":"Sandbox flow configuration: A rapid prototyping tool inside XCompact3d","type":"event"},{"authors":["Felipe N. Schuch","F.D. Vianna","A. Mombach","J.H. Silvestrini"],"categories":null,"content":"Outline Beginners may face many barriers to entry in a Navier-Stokes solver, for instance:\n The domain decomposition for parallel computation in a distributed-memory system; Coding, compiling, testing and debugging in programming languages like Fortran or C; The fear of lower anything in the code; Stability of different numerical methods; Lack of documentation and others.  This work aims to break these barriers by coupling a sandbox environment into the solver.\nTo this end, the high-order Navier-Stokes solver Xcompact3d was modified to accept the entire initial set-up from an external source, including physical and numerical parameters, initial and boundary conditions, and a solid geometry that can be inserted with Immersed Boundary Method (IBM). The initial set-up, in turn, is provided from a Jupyter Notebook, taking advantage of the built-in documentation with markdown cells (easily including figures and Latex equations), visualization and interactivity with widgets and plotting libraries, besides the versatility and readability of Python coding. Additionally, the input parameters can be checked for consistency and compatibility. Previous knowledge of NumPy and Matplotlib is enough to start with the exemplified flow configurations. However, there is no limitation to extend it to more advantaged tools like Pandas, Xarray, Dask, Numba, Holoview, Plotly and many others from the Jupyter ecosystem. In fact, the Jupyter CFD Sandbox was incorporated into the Python package Xcompact3d-toolbox.\nThe outcome of the presented framework benefits users from different levels:\n For students in computational fluid dynamics, it provides direct hands-on experience and a safe place for practising and learning; For advanced users and code developers, it works as a rapid prototyping tool to test concepts and then compare results to validate any future implementations at the numerical solver.  Furthermore, it is a useful advance in terms of research reproducibility and can be ported to any other numerical solver, let we know if you do so.\nTutorials and exemplified flow configurations are available at Xcompact3d-toolbox\u0026rsquo;s Documentation.\n","date":1602460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"67ee92f474a3295a39db56c3da26df21","permalink":"https://www.fschuch.com/en/publication/2020-jupytercon/","publishdate":"2020-09-02T17:46:50-03:00","relpermalink":"/en/publication/2020-jupytercon/","section":"publication","summary":"This work aims to break many of the barriers to entry in a Navier-Stokes solver by coupling it to a Jupyter sandbox environment. For students in computational fluid dynamics, it provides direct hands-on experience and a safe place for practising and learning, while for advanced users and code developers, it works as a rapid prototyping tool.","tags":["CFD","Python","Xcompact3d"],"title":"A Jupyter sandbox environment coupled into the high-order Navier-Stokes solver Xcompact3d","type":"publication"},{"authors":["Felipe N. Schuch","J.H. Silvestrini","E. Meiburg","S. Laizet"],"categories":null,"content":" To appear soon at EPTT 2020.   ","date":1600646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"b0dab88b656ea1b7e50adb45ab37c8db","permalink":"https://www.fschuch.com/en/publication/2020-eptt/","publishdate":"2020-09-02T17:26:12-03:00","relpermalink":"/en/publication/2020-eptt/","section":"publication","summary":"Theoretical and experimental interest in transport and deposition of sediments from rivers to oceans has increased rapidly over the last two decades. The marine ecosystem is strongly affected by mixing at river mouths, with for instance anthropogenic actions like pollutant spreading. Particle-laden flows entering a lighter ambient fluid (hyperpycnal flows) can plunge at a sufficient depth, and their deposits might preserve a remarkable record across a variety of climatic and tectonic settings. Numerical simulations play an essential role in this context since they provide information on all flow variables for any point of time and space. This work offers valuable Spatio-temporal information generated by turbulence-resolving 3D simulations of poly-disperse hyperpycnal plumes over a tilted bed. The simulations are performed with the high-order flow solver Xcompact3d, which solves the incompressible Navier-Stokes equations on a Cartesian mesh using high-order finite-difference schemes. Five cases are presented, with different values for flow discharge and sediment concentration at the inlet. A detailed comparison with experimental data and analytical models is already available in the literature. The main objective of this work is to present a new data-set that shows the entire three-dimensional Spatio-temporal evolution of the plunge phenomenon and all the relevant quantities of interest.","tags":["Turbidity Current","Plunging Flow","Computational Fluid Dynamics","Large-Eddy Simulation","Xcompact3d"],"title":"The Plunging of Hyperpycnal Plumes on Tilted Bed by Three-Dimensional Large-Eddy Simulations","type":"publication"},{"authors":null,"categories":null,"content":"","date":1597363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"be3690399cb2e7a79592085f6c32f44b","permalink":"https://www.fschuch.com/en/project/xcompact3d-toolbox/","publishdate":"2020-08-14T00:00:00Z","relpermalink":"/en/project/xcompact3d-toolbox/","section":"project","summary":"Python package with a set of tools for pre and postprocessing prepared for the high-order Navier-Stokes solver Xcompact3d.","tags":["Xcompact3d","Python"],"title":"Xcompact3d Toolbox","type":"project"},{"authors":["P. Bartholomew","G. Deskos","R.A.S. Frantz","Felipe N. Schuch","E. Lamballais","S. Laizet"],"categories":null,"content":"","date":159192e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"827688e1f41b4b9945b4122576c309c8","permalink":"https://www.fschuch.com/en/publication/2020-softwarex/","publishdate":"2020-06-12T00:00:00Z","relpermalink":"/en/publication/2020-softwarex/","section":"publication","summary":"Xcompact3D is a Fortran 90–95 open-source framework designed for fast and accurate simulations of turbulent flows, targeting CPU-based supercomputers. It is an evolution of the flow solver Incompact3D which was initially designed in France in the mid-90’s for serial processors to solve the incompressible Navier–Stokes equations. Incompact3D was then ported to parallel High Performance Computing (HPC) systems in the early 2010’s. Very recently the capabilities of Incompact3D have been extended so that it can now tackle more flow regimes (from incompressible flows to compressible flows at low Mach numbers), resulting in the design of a new user-friendly framework called Xcompact3D. The present manuscript presents an overview of Xcompact3D  with a particular focus on its functionalities, its ready-to-run simulations and a few case studies to demonstrate its impact.","tags":["Xcompact3d"],"title":"Xcompact3D: An open-source framework for solving turbulence problems on a Cartesian mesh","type":"publication"},{"authors":["Felipe N. Schuch"],"categories":null,"content":"","date":1585612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"2fa956bf6a4b092c59acf101b7121490","permalink":"https://www.fschuch.com/en/publication/2020-phd-thesis/","publishdate":"2020-03-31T00:00:00Z","relpermalink":"/en/publication/2020-phd-thesis/","section":"publication","summary":"Hyperpycnal flows are observed when the density of a fluid entering in a quiescent basin is greater than that in the ambient fluid. This difference can be due to temperature, salinity, turbidity, concentration, or a combination of them. When the inflow momentum decreases, it eventually plunges under the ambient fluid and flows along the bed as an underflow density current. This study is relevant in terms of the health of ecosystems in the regions of river deltas, in the management and operation of reservoirs and in the field of geology, since old sand deposits can preserve records of climatic and tectonic environments, in addition to become important hydrocarbon reservoirs. In the present work, 3D numerical simulations are performed for the hyperpycnal flow evolving over the bed of a tilted channel. Using numerical techniques designed for supercomputers, the incompressible Navier-Stokes and transport equations are solved to numerically reproduce the experiments of Lamb et al. (2010). This study focuses on the presentation and validation of a new numerical framework for the correct reproduction and analysis of the plunging phenomenon and its associated features. A good agreement is found between the experimental data of Lamb et al. (2010), the analytical model of Parker e Toniolo (2007) and the presented simulations. A new equation is proposed in order to predict the critical depth for plunging, including the role of the settling velocity and the bed slope. The high spatiotemporal resolution of the numerical simulations allows to verify the initial hypotheses established and a good agreement is found not only for the observed stationary plunging position, but also for the temporal evolution until reaching such a position. A negative value for the mixing coefficient was observed for the first time for the hyperpycnal flow in a tilted channel. This indicates that if the settling velocity of the suspended material is high enough, the submerged flow may lose fluid to the environment (dentrainment), instead of incorporating. Finally, a new scenario takes into consideration the interstitial inflowing density slightly different from the ambient, that is changed from fresh to salt water. Results show that the ambient stratification is not relevant when there is no settling velocity, as long as the density difference stays constant. On the other hand, a new dynamic is observed at the plunging zone and downstream of it when in the presence of sedimentation, evidenced by the upwards convection and intensified mixing between both fluids.","tags":["Plunging flow","Turbidity current","Large-eddy simulation","Plunging criteria","Xcompact3d"],"title":"Analysis of the Plunging of Hyperpycnal Flows on Tilted bed by Large-Eddy Simulations","type":"publication"},{"authors":["Felipe N. Schuch","F.D. Vianna","M. Pinho","J.H. Silvestrini"],"categories":null,"content":"","date":1575849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"050d8d9ab2d39ec213bdc52b28a23175","permalink":"https://www.fschuch.com/en/publication/2019-agu-fall-meeting/","publishdate":"2019-12-09T00:00:00Z","relpermalink":"/en/publication/2019-agu-fall-meeting/","section":"publication","summary":"Hyperpycnal flows are produced when the density of a fluid flowing in a relatively quiescent basin is greater than the density of the fluid in the basin. The density differences can be due to the difference in temperatures, salinity, turbidity, concentration, or a combination of them. Turbulence-resolved numerical simulations of such flows, in particular DNS (Direct Numerical Simulations), generate vasts amounts of resulting data. In the case of poli-disperse particle laden gravity currents simulations, where several sediments diameters are considered, very detailed data of the concentration field is available near bed. It can be post processed and analysed as a deposition map of one geological event. Traditional visualization tools lack the geological visual metaphor, and a new visual and interactive tool is proposed in this work. The aim of this new tool is to provide a better way to visualize numerical simulation results of particle laden gravity currents, plotting the results with the visual resemblance of a stratigraphic image. Since numerical simulation results usually have better spatio-temporal resolution compared to traditional stratigraphy, as the resolution depends exclusively on the amount of computing power available and it gets higher each day, the proposed interactive tool let the user visualize how the deposition map evolves in time and space. This tool can be employed to analyse the link between the deposition map and the turbulent flow that produced it, and the influence of all governing parameters. Numerical data was provided by Incompact3d, a code based on a Boussinesq system for incompressible fluids, designed for supercomputers. However this particular approach is a data driven post processing tool, thus it should be compatible with any numerical solver.","tags":["Xcompact3d"],"title":"An interactive tool for stratigraphic visualization applied to turbulence-resolved numerical simulations of turbidity currents","type":"publication"},{"authors":null,"categories":null,"content":"","date":1563494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"ba73fe592b569e3c527a12c21cccbc60","permalink":"https://www.fschuch.com/en/project/aprenda.py/","publishdate":"2019-07-19T00:00:00Z","relpermalink":"/en/project/aprenda.py/","section":"project","summary":"It is a STEM initiative that teaches Python coding applied to problem-solving, specially designed for engineering students.","tags":["Python"],"title":"Aprenda.py","type":"project"},{"authors":[],"categories":[],"content":"Python and XCompact3d XCompact3d 2021 Online Developer Meeting Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n Hi, my name is Felipe; Today I gonna talk about Python and XCompact3d; Starting with a quick introduction; Then I gonna show a little bit of what I\u0026rsquo;ve been doing in this TOPIC; And finally, I will bring some points for discussion here with you, especially AIMING to improve the synergy between Python and XCompact.    Introduction  Why Python?  Computational cost vs Cost for development; Faster to Prototype ideas; Code interactively using IPython and Jupyter; It is a great tool for pre and post-processing.   I don\u0026rsquo;t know if everyone here already uses Python, so I gonna start with Why Python; Many people MAY SAY it is a terrible tool because it DOESN\u0026rsquo;T RUN SO fast as other alternatives; But to THOSE people I say, we need to look at the big picture, lets also talk about the COST for development, HUMAN RESOURCES; Here is where Python is really good; Together with the INTERACTIVE tools like Jupyter, Python is a very popular CHOICE for data science; And in our case, it\u0026rsquo;s a great tool for pre and post-processing.    Why Numpy?  It is a Python library that provides a multidimensional array object and an assortment of routines for fast operations on arrays; Much faster option, because it runs in optimized, pre-compiled C code; With Numpy, we have the best of two worlds, the performance of compiled code in the background, together with the flexibility of Python code for the user.  See https://numpy.org\n And now, Why Numpy? It provides multidimensional ARRAY operations in Python; It is much faster than pure Python, because it runs in OPTIMIZED, pre-compiled C code; With Numpy, we have the best of two WORLDS, the performance of compiled code, together with the flexibility of Python CODE FOR THE USER.    Numpy - Example x = np.linspace(start=0., stop=2*np.pi, num=50) y = np.linspace(start=0., stop=2*np.pi, num=50) ux = np.sin(x[:,np.newaxis])*np.cos(y[np.newaxis,:]) uy = -np.cos(x[:,np.newaxis])*np.sin(y[np.newaxis,:]) int = np.trapz(np.trapz(ux, x=x, axis=0), x=y, axis=0) plt.streamplot(x,y,ux.T,uy.T) plt.xlabel(r\u0026quot;$x_1$\u0026quot;); plt.ylabel(r\u0026quot;$x_2$\u0026quot;);   This is a little workflow using Numpy;  We start here setting two vectors, they will work as our coordinates, x and y; Now you see that booth ux and uy are 2D, but Numpy doesn\u0026rsquo;t know it, so we should inform it using this np.newaxis notation; And we can compute a integration in this plane, but it is up to the user to keep track of the coordinates and the number of each AXIS. The plot is just for reference;   But WHO am I to complain about Numpy?  It is the core of the scientific ecosystem in Python; I Just wanna show you that we can use Numpy in a better way;      Why Xarray?  Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like multidimensional arrays, which allows for a more intuitive, more concise, and less error-prone developer experience; Besides, it is integrated to other tools for:  Plotting (matplotlib, HoloViews and others); Parallel computing (Dask); I/O (NetCDF).    See http://xarray.pydata.org\n WITH Xarray. It introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy arrays, which allows for a more intuitive, more CONCISE, and LESS ERROR-PRONE DEVELOPER experience:  Xarray can do axis alignment and broadcast AUTOMATICALLY for any array operation;   Besides, it\u0026rsquo;s integrated with other tools for Plotting, Parallel computing and I/O.    Xarray - Example dataset = xr.Dataset( coords={ \u0026quot;y\u0026quot;: np.linspace(start=0.0, stop=2 * np.pi, num=50), \u0026quot;x\u0026quot;: np.linspace(start=0.0, stop=2 * np.pi, num=50), } ) dataset[\u0026quot;ux\u0026quot;] = np.sin(dataset[\u0026quot;x\u0026quot;]) * np.cos(dataset[\u0026quot;y\u0026quot;]) dataset[\u0026quot;uy\u0026quot;] = -np.cos(dataset[\u0026quot;x\u0026quot;]) * np.sin(dataset[\u0026quot;y\u0026quot;]) dataset  \u0026lt;xarray.Dataset\u0026gt; Dimensions: (x: 50, y: 50) Coordinates: * y (y) float64 0.0 0.1282 0.2565 0.3847 ... 5.899 6.027 6.155 6.283 * x (x) float64 0.0 0.1282 0.2565 0.3847 ... 5.899 6.027 6.155 6.283 Data variables: ux (x, y) float64 0.0 0.0 0.0 0.0 ... -2.369e-16 -2.429e-16 -2.449e-16 uy (x, y) float64 -0.0 -0.1279 -0.2537 ... 0.2537 0.1279 2.449e-16  Note: This is just the string representation, the dataset will look even better in HTML when running in Jupyter.\n See this example using xarray; We start with the dataset OBJECT, informing the coordinates in this DICT-LIKE constructor; Now we can access the coordinates by THEIR name, and with it, xarray knows this result should be 2D; We can investigate the dataset, its dimensions, coordinates and variables, ALL TOGETHER in a single object; We will see more examples applied to xcompact soon;    XCompact3d-toolbox https://xcompact3d-toolbox.readthedocs.io\n The physical and computational parameters are built on top of traitlets:  IPywidgets for a friendly user interface;   Data structure is provided by xarray, again with:  Plotting (matplotlib, HoloViews and others); Parallel computing (Dask); I/O (NetCDF).     But first, lets talk about the toolbox; It is a Package designed to handle pre and post-processing in Python; Actually, it is more like a Python WRAPPER, because it RELIES HEAVILY on other Python tools; For instance, the physical and computational parameters are built on top of TRAITLETS;  Together with a friendly user interface in IPywidgets;   And the Data structure is provided by Xarray, again with support for Plotting, Parallel computing and I/O;    Parameters' consistency with Traitlets \u0026gt;\u0026gt;\u0026gt; prm = x3d.Parameters(loadfile=\u0026quot;example.i3d\u0026quot;) \u0026gt;\u0026gt;\u0026gt; # Type checking \u0026gt;\u0026gt;\u0026gt; prm.iibm = 10.0 TraitError: The 'iibm' trait of a Parameters instance expected an int, not the float 10.0. \u0026gt;\u0026gt;\u0026gt; # Limits are imposed \u0026gt;\u0026gt;\u0026gt; prm.iibm = 5 # \u0026lt;--- This can be only 0, 1 or 2, as x3d expects TraitError: The value of the 'iibm' trait of a Parameters instance should not be greater than 2, but a value of 5 was specified  \u0026gt;\u0026gt;\u0026gt; # On change validation \u0026gt;\u0026gt;\u0026gt; prm.nx = 93 TraitError: Invalid value for mesh points (nx) \u0026gt;\u0026gt;\u0026gt; prm.nx = 17 \u0026gt;\u0026gt;\u0026gt; # On chance callbacks \u0026gt;\u0026gt;\u0026gt; print(prm.nclx1, prm.nclxn, prm.nx, prm.dx) 2 2 17 0.0625 \u0026gt;\u0026gt;\u0026gt; prm.nclx1 = 0 # \u0026lt;--- Setting periodic BC \u0026gt;\u0026gt;\u0026gt; print(prm.nclx1, prm.nclxn, prm.nx, prm.dx) 0 0 16 0.0625   With Traitlets, the parameters can be checked for consistence; The GOAL here is to anticipate some user mistakes; For instance:  The parameters are type checked; We can impose some boundaries; We can see some on CHANGE validations; And onchange callbacks;   So, with it, we make sure that the parameters file will be compatible with xcompact3d;    User Interface with IPywidgets (try it online)  [Try it online](https://xcompact3d-toolbox.readthedocs.io/en/latest/tutorial/parameters.html#). --  And all the behaviors we saw in the command line are also available at the user interface; As you can see, we ensure that booth boundaries in one direction will be periodic or not at the same time, and the number of MESH POINTS goes BACK and FORWARD properly; You can see the estimation for size in disk changing as well; -It is pretty cool, you can try it online in this link.    XCompact3d-toolbox - Example prm = x3d.Parameters(loadfile=\u0026quot;input.i3d\u0026quot;) ds = xr.Dataset() # Make sure to have enough memory! for var in \u0026quot;ux uy uz pp\u0026quot;.split(): ds[var] = prm.read_all_fields(f\u0026quot;./data/3d_snapshots/{var}-*.bin\u0026quot;) ds[\u0026quot;phi\u0026quot;] = xr.concat([prm.read_all_fields(f\u0026quot;./data/3d_snapshots/phi{n+1}-*.bin\u0026quot;) for n in range(prm.numscalar)], \u0026quot;n\u0026quot;,).assign_coords(n=(\u0026quot;n\u0026quot;, range(prm.numscalar))) ds  \u0026lt;xarray.Dataset\u0026gt; Dimensions: (n: 5, t: 76, x: 721, y: 49, z: 721) Coordinates: * x (x) float32 0.0 0.02083 0.04167 0.0625 ... 14.94 14.96 14.98 15.0 * z (z) float32 0.0 0.02083 0.04167 0.0625 ... 14.94 14.96 14.98 15.0 * y (y) float32 0.0 0.02083 0.04167 0.0625 ... 0.9375 0.9583 0.9792 1.0 * n (n) int32 0 1 2 3 4 * t (t) float64 0.0 0.4 0.8 1.2 1.6 2.0 ... 28.4 28.8 29.2 29.6 30.0 Data variables: phi (n, t, x, y, z) float32 dask.array\u0026lt;chunksize=(5, 1, 721, 49, 721), meta=np.ndarray\u0026gt; ux (t, x, y, z) float32 dask.array\u0026lt;chunksize=(1, 721, 49, 721), meta=np.ndarray\u0026gt; uy (t, x, y, z) float32 dask.array\u0026lt;chunksize=(1, 721, 49, 721), meta=np.ndarray\u0026gt; uz (t, x, y, z) float32 dask.array\u0026lt;chunksize=(1, 721, 49, 721), meta=np.ndarray\u0026gt; pp (t, x, y, z) float32 dask.array\u0026lt;chunksize=(1, 721, 49, 721), meta=np.ndarray\u0026gt;   Now we have a real case using a xarray dataset; This is from a polidispersed Turbidity Current in Axisymmetric Configuration; We start with an empty dataset, and them populate it with all the variables from our simulation; You see here the three velocity components and pressure; With toolbox, we can read all files at once; Besides five scalar fractions are concatenated in just one array with this command here; And finally, we can see the dataset, with:  5 scalar fractions, from 76 snapshots in time, with this spatial resolution; The coordinates are also INCLUDED. With xarray, we can do many operations calling the coordinates by name, it is very powerful; and we see the five variables.   For me, it is really impressive to have ALL data AVAILABLE FOR US at once here in this single object; But JUST MAKE SURE to have have enough memory for it! Now, lets see how to use it    Xarray - Working with coordinates ds.phi.sel(t=10.0).mean(\u0026quot;y\u0026quot;).plot(col=\u0026quot;n\u0026quot;)  ds['suspended'] = ds.phi.integrate([\u0026quot;x\u0026quot;, \u0026quot;y\u0026quot;, \u0026quot;z\u0026quot;]); ds.suspended.plot(hue=\u0026quot;n\u0026quot;)  ds['w1'] = ds.uz.differentiate(\u0026quot;y\u0026quot;) - ds.uy.x3d.first_derivative(\u0026quot;z\u0026quot;)   In the first example:  From the dataset, we select the scalar; I\u0026rsquo;m choosing JUST where time is equals to 10.0; Computing a vertical average calling the coordinate by its name; And finally a plot for reference, presenting each scalar fraction in a different figure; The settling velocity is different for each fraction, so that is why the concentration is decreasing from LEFT to RIGHT;   In the second line, I\u0026rsquo;m showing how to compute the suspended material, it is defined as the volumetric INTEGRATION of the concentration fields, we can code it in this way, and again a plot for reference; And the last code shows how to compute the first component of VORTICITY;  It is equal to duz / dy SUBTRACTING duy / dz; We can use the standard second order scheme from xarray; Or the high order alternative from the toolbox;   From my experience working with xarray, we can solve more complicated PROBLEMS with FEWER lines of code; Besides, calling the coordinates by their name, makes our code VERY READABLE, AND CONSEQUENTLY, it is easier to collaborate, share and maintain;    Could we handle larger-than-memory Datasets?   Yes, if the files were written as NetCDF:\nds = xr.open_mfdataset(\u0026quot;./data/3d_snapshots/*.nc\u0026quot;)    Actually, it is just what we did! In the previous example we handled a 66,5GB dataset in a 8GB virtual machine;\n  Let\u0026rsquo;s consider implementing I/O with NetCDF at XCompact3d?\n  Note: I\u0026rsquo;ve written a script to convert raw binaries to NetCDF, in order to test this concept.\n But, how about this question? Can we handle larger-than-memory Datasets? Yes, we can, and we just did it; The example WE JUST SAW WAS A 60 GB dataset, working on a 8 GB virtual machine in our campus, that I accessed remotely; I wrote a script to convert the RAW BINARIES to NetCDF, aiming to test this CONCEPT; And now you tell me, would you like to work in this way?  Opening the entire dataset with just one command line? It uses lazy computation, so the data will only be transfered to the memory when demanded;   Which leads to another question: Let’s consider implementing I/O with NetCDF at XCompact3d?    Integrating Python and XCompact3d  Now talking more specifically about the integrating between Python and XCompact3d    F2PY - Fortran to Python interface generator ! xcompact3d.f90 | mpirun -n 4 ./xcompact3d program xcompact3d use core implicit none call init_xcompact3d() call main_loop() call finalise_xcompact3d() end program xcompact3d  # xcompact3d.py | mpirun -n 4 python xcompact3d.py from xcompact3d import core if __name__ == '__main__': core.init_xcompact3d() core.main_loop() core.finalise_xcompact3d()  Note: This example actually works, and with no performance penalty.\n F2PY is a tool from the Scipy / Numpy universe, it is a FORTRAN TO PYTHON INTERFACE GENERATOR; And this is a working prototype; I just rearranged a little the FORTRAN code, putting everything in this module called core, so we can still run it; F2PY produces the Python interface; And now we can access the same module core here in Python, and we can, actually, run the simulation WITH NO PERFORMANCE PENALTY; Because we are running with the exactly same compiled code; AND, AFTER TESTING IT, A HAD SOME IDEAS.    Overview / Objectives  Make key subroutines available in Python; Testing them individually with unittest will increase XCompact3d\u0026rsquo;s maintainability; Distributing the compiled code with pip may increase our user base.   Using F2PY, we could make some key subroutines available in Python:  For the simulation itself, but also post-processing;   We could test them with UNITARY TEST, increasing the codes MAINTAINABILITY; We could distribute the compiled code, in order to increase our user base; And all of this with no significant change at the fortran code; So, of course, it would be still possible to download the code from source, compile it, and keep our WORKFLOW just as it is today, but OPENING SOME new possibilities.    F2PY - Fortran to Python interface generator The next steep from xcompact3d import core, solver if __name__ == \u0026quot;__main__\u0026quot;: core.init_xcompact3d() my_own_initial_conditions() # Low cost, very customizable while solver.is_running: my_own_boundary_conditions() # Low cost, very customizable solver.advance_time() # High performance with Fortran code my_own_postprocessing() # Low cost, very customizable core.finalise_xcompact3d()  Note 1: Here we have every Python tool at our disposal, like modules for optimization, control, visualization, machine learning, I/O, GPU accelerated computing (CuPy), etc. Note 2: It results in a very customizable interface without affecting the main code in Fortran.\n This is how I plan the next step; We could make more routines available, for instance, open up the main loop;  There is here at the begging, lets say, my own boundary conditions coded in Python, very customizable; From the solver, we call advance_time with the performance and scalability that we are USED to; After that, we could call on board postprocessing, again, very customizable in Python.   The main point here is that we have EVERY Python tool at our DISPOSAL, like modules for optimization, control, visualization, machine learning, I/O, maybe some GPU accelerated computing and many others. It results in a very flexible interface without affecting the main code in Fortran.    It is time to discuss the conclusions  Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n 🏠 fschuch.com ✉ felipe.schuch@edu.pucrs.br\n www.fschuch.com/en/slides/2021-x3d-showcase --  THAT IS IT, I have no conclusion, because I think we could discuss IT NOW; So, Please, let me know what do you think about it.   ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"073cf2d757d52e94fba68ad2f1269cc0","permalink":"https://www.fschuch.com/en/slides/2021-x3d-dev-meeting/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/en/slides/2021-x3d-dev-meeting/","section":"slides","summary":"Python and XCompact3d XCompact3d 2021 Online Developer Meeting Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n Hi, my name is Felipe; Today I gonna talk about Python and XCompact3d; Starting with a quick introduction; Then I gonna show a little bit of what I\u0026rsquo;ve been doing in this TOPIC; And finally, I will bring some points for discussion here with you, especially AIMING to improve the synergy between Python and XCompact.","tags":[],"title":"Python and XCompact3d","type":"slides"},{"authors":[],"categories":[],"content":"Sandbox flow configuration: A rapid prototyping tool inside XCompact3d  Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n Hi, my name is Felipe; I\u0026rsquo;m glad to be here today REPRESENTING our LAB; LaSET is the CFD LAB here at PUC rio grande do sul, And this is our work: Sandbox flow configuration: A rapid prototyping tool inside XCompact3d    Motivation  Starting with the motivation for this work, there are two main points to highlight      How can we speed up our workflow?\n  Can we improve the learning curve for beginners in our code?\n    The first is:\n How can we speed up our workflow? I mean, the iterations here the scientific PROCESS; But more specifically, How can we speed up the iterations here in the simulation cycle.    and the second point:\n Can we improve the learning curve for beginners in our code? And especially, how to help them to code new flow configurations, going beyond the benchmark cases.      Identifying the main challenges  Using parallel computation in a distributed-memory system and Message Passing Interface;   Illustration of the 2D domain decomposition from 2DECOMP\u0026amp;FFT. \n Coding, compiling, testing, debugging and handling I/O in Fortran.   This leads us to identify the main challenges in our workflow, if we would like to make it easier for beginners and faster for developers; I would say, the PARALLEL DECOMPOSITION IS GREAT for performance and scalability, but it takes a while to master allocation, transpositions and all the MPI calls; Besides that, coding, compiling, testing, debugging and handling I/O in Fortran is not so easy, it is another point that we would like to improve.    Methodology  The PROBLEMS WERE identified, now, lets see how to solve them!    Sandbox Flow Configuration (BC-Sandbox.f90)\n The initial set-up is imported from external files; The choice of the external tool is up to the user:  Fortran, Matlab, Octave, R, Julia; Python with just Numpy or more specific tools (Py4Incompact3D or Xcompact3d-toolbox);   It adds no extra dependency to the workflow.   This is the Sandbox Flow configuration. Of course, xcompact3d already reads the PARAMETERS FILE at initialization, but with the new MODULE SANDBOX, the entire initial set-up can be imported from the disk; Using it, we can customize any new flow configuration with no need to RECOMPILE the code every time. The initial set-up includes case specific definitions, like: Initial condition; Boundary conditions; Geometry; Others. It can be provided EXTERNALLY. Our INTENTION was to keep it simple, but using the disk is still very USEFULL, because with it, the choice of what to use as external tool is totally up to the user:  It can be Fortran, Matlab, R, Julia, Python, and many others, as long as you can write binary arrays in the same fashion that xcompact3d would do.   And here we have a good point: This framework can speed up our workflow, and at the same time, there is no extra DEPENDENCIES to install. Besides, the core of the code was UNTOUCHED, so we have the usual performance in the code, combined with FLEXIBILITY for initial definitions; In this way, we use the right tool for the right task.    Variables handled by Sandbox  Initial condition for velocity and scalar field(s); Inflow profiles for velocity and scalar field(s) (if nclx1=nclxS1=2); Top and bottom boundary values for scalar field(s) (if nclyS1=2 or nclySn=2); Customized operator for the imposition of constant flow rate (if nclx1=nclxn=0); $\\epsilon$ array, describing the solid geometry for IBM (if iibm $\\ne$ 0).  See README for more details.\n Here we see what we can do with sandbox:  We should always specify the initial condition for velocity and the scalar fields; But the other arrays are just demanded in specific situations: Like, we can specify inflow profiles for velocity and scalar if we use Dirichlet boundary condition where x is equals to 0; We can also set scalar values at the bottom and top boundaries if we use Dirichlet; We can specify a customized operator if we want to impose a constant flow rate in a periodic flow; And we set a epsilon array if using Immersed Boundary Method.      An example using Python and Numpy import numpy as np ux = np.zeros(shape=(nx, ny, nz), dtype=np.float64) uy = np.zeros_like(ux) uz = np.zeros_like(ux) phi = np.zeros(shape=(nx, ny, nz, numscalar), dtype=np.float64) # Sequence of operations to set the initial condition ux.T.tofile('./data/ux.bin') uy.T.tofile('./data/uy.bin') uz.T.tofile('./data/uz.bin') for n in range(numscalar): phi[:,:,:,n].T.tofile('./data/phi{}.bin'.format(n+1))  Note: The initial set-up can be provided from any other language, as long as the files are written as raw binaries (compatible with 2DECOMP\u0026amp;FFT) and the filenames are correct.\n Here is an example of how to set the initial condition in Python with Numpy; We initialize the arrays with the right shape and data type; Then, we take advantage of Python\u0026rsquo;s flexibility and readability to set the values for our flow configuration; Besides, we can combine with other tools to plot, compute and test our set-up. And finally, we write them to the disk, so they will be available for the module sandbox.    Cases Covered by Sandbox    Case IC BC FRC IBM LMN     Channel-Flow ✔️  ✔️     Cylinder ✔️ ✔️  ✔️    Lock-exchange ✔️ ✔️   ⚠️   Periodic Hill ✔️  ✔️ ✔️    Taylor–Green vortex ✔️       TBL ✔️ ⚠️ ⚠️      Note: Initial Condition (IC); Boundary Conditions (BC); Flow rate Control (FRC); Immersed Boundary Method (IBM); Low Mach Number (LMN).\n Here we see an estimation of the cases covered by sandbox at this moment; We can simulate Channel-flow, flow around a cylinder, Periodic Hill and TGV; Density current in the lock-exchange will work too, as long as we are not using the low mach number approach, it was not implemented in the module yet; Well, it is a work in progress; And the turbulent boundary layer demands more specific definitions of boundary conditions and flow rate control, so it is also not supported. But, like I told you, it is just an estimation, because now we can play around and modify any of these cases.   .bin` | (nx, ny, nz) | `numscalar $$ 0` | --- ### It supports Boundary Condition | Filename | Shape | Demanded | | ----------- | ------| -------- | | `bxx1.bin` | (ny, nz) | `nclx1=2` | | `bxy1.bin` | (ny, nz) | `nclx1=2` | | `bxz1.bin` | (ny, nz) | `nclx1=2` | | `bxphi1.bin` | (ny, nz) | `nclxS1=2` | | `byphi1.bin` | (nx, nz) | `nclyS1=2` | | `byphin.bin` | (nx, nz) | `nclySn=2` | --- ### It supports other arrays | Filename | Description | Demanded | | ----------- | ----------- | -------- | | `geometry.bin` | $\\epsilon$ array set to 1 inside the solid and zero otherwise | `iibm $\\ne$ 0` | | `vol_frc.bin` | Customized operator to impose constant flow rate | `nclx1=nclxn=0` | --- --  Case Study  For example, we are going to merge the periodic channel and the flow around a cylinder\u0026hellip;    Periodic Heat Exchanger  Periodic boundary conditions in x and z; A cylinder at the center with low temperature; No-slip conditions for velocity at top and bottom, besides, high temperature at the walls.   Besides combining it with HEAT TRANSFER, in what I called, The Period Heat Exchanger. We have periodic boundary conditions in the streamwise and spanwise directions; A cylinder at the center of the domain with its dimensionless temperature fixed at zero; And no-slip BC at the bottom and top walls, and their temperature fixed in one. Lets see how to code it!    Initialization \u0026gt;\u0026gt;\u0026gt; import xcompact3d_toolbox as x3d \u0026gt;\u0026gt;\u0026gt; import xcompact3d_toolbox.sandbox \u0026gt;\u0026gt;\u0026gt; prm = x3d.Parameters(loadfile='input.i3d') \u0026gt;\u0026gt;\u0026gt; dataset = x3d.sandbox.init_dataset(prm) \u0026gt;\u0026gt;\u0026gt; dataset  \u0026lt;xarray.Dataset\u0026gt; Dimensions: (n: 1, x: 128, y: 129, z: 8) Coordinates: * x (x) float64 0.0 0.04688 0.09375 0.1406 ... 5.812 5.859 5.906 5.953 * y (y) float64 0.0 0.04688 0.09375 0.1406 ... 5.859 5.906 5.953 6.0 * z (z) float64 0.0 0.04688 0.09375 0.1406 0.1875 0.2344 0.2812 0.3281 * n (n) int32 0 Data variables: byphi1 (n, x, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 byphin (n, x, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 ux (x, y, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 uy (x, y, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 uz (x, y, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 phi (n, x, y, z) float64 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 vol_frc (x, y, z) float64 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0   I\u0026rsquo;m using xcompact3d-toolbox just because I\u0026rsquo;m more familiar with it; We start here importing the Package; Lets say that we already had set all the correct parameters at the input file, so now we load it; And we start the dataset. It is returned to us with the proper dimensions, coordinates and the SEVEN data variables that we are going to work with now    Boundary Conditions High temperature at the bottom and top walls:\n$$ \\Theta(x,y=0,z,t) = 1 $$\n$$ \\Theta(x,y=L_y,z,t) = 1 $$\n\u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;byphi1\u0026quot;] += 1.0 \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;byphin\u0026quot;] += 1.0   We start setting the temperature as one at the bottom and top walls, like specified for our new flow configuration;    Initial Condition \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;ux\u0026quot;] += velocity_profile + random_noise \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;uy\u0026quot;] += random_noise \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;uz\u0026quot;] += random_noise \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;phi\u0026quot;] += 1.0  Note: Part of the code was not presented, for simplicity.\n Now, lets set the initial condition for the streamwise velocity as this vertical profile in addition to some random noise, and just random noise for uy and uz; And the initial temperature will be one everywhere.    Geometry \u0026gt;\u0026gt;\u0026gt; epsi = x3d.sandbox.init_epsi(prm) \u0026gt;\u0026gt;\u0026gt; for array in epsi.values(): ... array = array.geo.cylinder(x=prm.xlx / 2.0, y=prm.yly / 2.0) ... \u0026gt;\u0026gt;\u0026gt; epsi[\u0026quot;epsi\u0026quot;].isel(z=0).plot()   Now it is time to set the geometry, a cylinder in the center of the domain. Notice that xcompact3d-toolbox includes methods to DRAW many standards geometries. Here we are using the cylinder, we just have to specify its center AND WE ARE GOOD TO GO.    Flow rate Control \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;vol_frc\u0026quot;] += prm.dy / prm.yly / prm.nx / prm.nz \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;vol_frc\u0026quot;][dict(y=0)] *= 0.5 \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;vol_frc\u0026quot;][dict(y=-1)] *= 0.5 \u0026gt;\u0026gt;\u0026gt; dataset[\u0026quot;vol_frc\u0026quot;] = dataset.vol_frc.where(epsi == False, 0.0) \u0026gt;\u0026gt;\u0026gt; dataset.vol_frc.isel(z=0).plot()  Note: The code will compute the stream-wise flow rate as int = sum(vol_frc * ux), and correct the stream-wise velocity as ux = ux / int.\n Since the domain is periodic in x, we need to specify a forcing term to maintain a constant flow rate, As you see here, xcompact3d will compute the flow rate with this integration, so we can CUSTOMIZE this operator for the volumetric integration; This one will give us a unitary value per HEIGHT unit, and will include an average in x and z. We multiply both top and bottom plane by half because of the composed trapezoidal rule for integration; And of course, we can disconsider the cylinder when integrating.     Now we save the arrays to the disk: \u0026gt;\u0026gt;\u0026gt; dataset.x3d.write(prm) \u0026gt;\u0026gt;\u0026gt; x3d.gene_epsi_3D(epsi, prm)   And run the simulation: mpirun -n [number of cores] ./xcompact3d |tee log.out   There is no need to recompile the code every time; We can code, test, plot and debug the initial set-up interactively in a Jupyter Notebook (or any other computational tool).   Now it is time to write all the variables to the disk and run the simulation; Notice that there is no need to RECOMPILE the code every time; And we can code, test, plot and debug the initial set-up using any computational tool, like a Jupyter Notebook, and make it very INTERACTIVE;    Periodic Heat Exchanger\n View the code online.\n Here we see an animation of the case that we just coded, the periodic heat exchanger; It is just a toy model, the Reynolds Number is very low, but you are invited to access the complete code here in this link, and play around with the parameters and definitions; You can access the slides using the QR CODE at the end of this talk. Any way, I have a few more examples to show to you\u0026hellip;     View the code online.\n We are looking in a top view, that is presenting the depth-averaged concentration of the turbidity current in asymmetric configuration. This one is just like Ricardo explained to us earlier in HIS talk, but this time the denser fluid starts here at the bottom left corner and can spread in more directions. We can see the lobes-and-clefts near the front, how some rings are formed in the body and them they break down, and many other nice features.     View the code online.\n End the last example is the flow around a square with passive scalar as a visualization tool. Here at the inlet we have this smooth step function for the passive scalar, as a result, we can see this nice pattern downstream due to the turbulence; As always, everything is very CUSTOMIZABLE. We could change the position of the square, we could include more squares; change the number os steeps here at the inlet;    Bonus  And I have a special bonus for you    User Interface with IPywidgets (try it online)\n [Try it online](https://xcompact3d-toolbox.readthedocs.io/en/latest/tutorial/parameters.html#). --  I\u0026rsquo;ve talked about improving the learning curve for beginners in our code, and here is another initiative. We have this user interface with IPywidgets under development in our LAB; Using it, we can enforce the right relationship between the parameters, just to make sure they are compatible with xcompact3d; You can see here that we ensure that booth boundaries in one direction will be periodic or not, and the number of mesh points goes BACK and FORWARD properly. There are more features, but I will leave the link here, so you can try it.    Conclusion  The outcome of this work benefits users from different levels:  For students in CFD, it provides direct hands-on experience and a safe place for practising and learning; For advanced users and code developers, it works as a rapid prototyping tool; Furthermore, it is a useful advance in terms of research reproducibility.  Note: module sandbox is still in pre-release (fschuch/Xcompact3d).\n To conclude this talk, we EXPECT to help USER from different levels with our framework;  For students in CFD, it provides direct hands-on experience and a safe place for practising and learning; For advanced users and code developers, it works as a rapid prototyping tool; Furthermore, it is a useful advance in terms of research reproducibility, because now it is easier to create, collaborate and share any new flow configuration.      Questions?  Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n 🏠 fschuch.com ✉ felipe.schuch@edu.pucrs.br\n www.fschuch.com/en/slides/2021-x3d-showcase --  THAT IS IT, tank you very much for your ATTENTION; I\u0026rsquo;m ready to take any questions now.   ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"20eb7637c67ce93dcdf96a6b01bec1e7","permalink":"https://www.fschuch.com/en/slides/2021-x3d-showcase/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/en/slides/2021-x3d-showcase/","section":"slides","summary":"Sandbox flow configuration: A rapid prototyping tool inside XCompact3d  Felipe N. Schuch, LaSET, School of Technology, PUCRS.\n Hi, my name is Felipe; I\u0026rsquo;m glad to be here today REPRESENTING our LAB; LaSET is the CFD LAB here at PUC rio grande do sul, And this is our work: Sandbox flow configuration: A rapid prototyping tool inside XCompact3d    Motivation  Starting with the motivation for this work, there are two main points to highlight      How can we speed up our workflow?","tags":[],"title":"Sandbox flow configuration: A rapid prototyping tool inside XCompact3d","type":"slides"},{"authors":["Felipe N. Schuch","E. Meiburg","S. Laizet","J.H. Silvestrini"],"categories":null,"content":"","date":15444e5,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"4d047303820859c206c3f7ada82d14cf","permalink":"https://www.fschuch.com/en/publication/2018-agu-fall-meeting/","publishdate":"2018-12-10T00:00:00Z","relpermalink":"/en/publication/2018-agu-fall-meeting/","section":"publication","summary":"","tags":["Xcompact3d"],"title":"Turbulence-Resolving Simulations of the Plunge Phenomenon in a Stratified Ambient","type":"publication"},{"authors":["Felipe N. Schuch","L.C. Pinto","J.H. Silvestrini","S. Laizet"],"categories":null,"content":"","date":1528761600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"b9a8fbe562bc86151905e505444309dd","permalink":"https://www.fschuch.com/en/publication/2018-jgr-ocean/","publishdate":"2018-06-12T00:00:00Z","relpermalink":"/en/publication/2018-jgr-ocean/","section":"publication","summary":"Abstract Hyperpycnal flows are produced when the density of a fluid flowing in a relatively quiescent basin is greater than the density of the fluid in the basin. The density differences can be due to the difference in temperatures, salinity, turbidity, concentration, or a combination of them. When the inflow momentum diminishes, the inflowing fluid eventually plunges under the basin fluid and flows along the bottom floor as an underflow density current. In the present work, 3-D turbulence-resolving simulations are performed for an hyperpycnal flow evolving at the bottom floor of a tilted channel. Using advanced numerical techniques designed for supercomputers, the incompressible Navier-Stokes and transport equations are solved to reproduce numerically the experiments of [Lamb et al. (2010)](https://doi.org/10.1130/B30125.1) obtained inside a flume with a long tilted ramp. This study focuses on presenting and validating a new numerical framework for the correct reproduction and analysis of the plunge phenomenon and its associated flow features. A very good agreement is found between the experimental data of Lamb et al. (2010), the analytical models of [Parker and Toniolo (2007)](https://doi.org/10.1061/(ASCE)0733-9429(2007)133:6(690)), and the present turbulence-resolving simulations. The mixing process between the ambient fluid and the underflow density current is also analyzed thanks to visualizations of vortical structures at the interface.","tags":["Plunging Flow","Xcompact3d"],"title":"Three‐Dimensional Turbulence‐Resolving Simulations of the Plunge Phenomenon in a Tilted Channel","type":"publication"},{"authors":["Felipe N. Schuch"],"categories":null,"content":"","date":1459382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"18ee40fd458ab8a41ea32b70ea83b092","permalink":"https://www.fschuch.com/en/publication/2016-master-thesis/","publishdate":"2016-03-31T00:00:00Z","relpermalink":"/en/publication/2016-master-thesis/","section":"publication","summary":"The studies on transport mechanics and sediment deposition in bed slope channels has rapidly increased over the last decade, this is associated with the fact that they play a fundamental role on the formation of hydrocarbon reservoirs. This work aims to investigate, through direct numerical simulation, the plunge phenomena dynamics when a heavier density fluid, full of particles, flows into a lower density environment. Simulations were carried out with Incompact3d, a code based on a Boussinesq system for incompressible fluids was utilized. The channel’s entrance sediment concentration and flow rate influence on the plunge point and deposition profiles were investigated. Results are compared with theoretical models and physical experiments.","tags":["Xcompact3d"],"title":"Analisys of hiperpycnal poly-disperse plume by direct numerical simulation","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"5955631fa44bec83922c0c132198c22c","permalink":"https://www.fschuch.com/en/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"a9d490a75735c6c06fd5c9f943a86722","permalink":"https://www.fschuch.com/en/project/jobbergate/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/project/jobbergate/","section":"project","summary":"Jobbergate is a system used to manage reusable applications that can generate specific scripts that may be submitted via Slurm for execution on a cluster.","tags":["HPC","Python","Slurm","Jobbergate"],"title":"Jobbergate","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751736705,"objectID":"500c5818a0309ee79dfb14caf407e4a6","permalink":"https://www.fschuch.com/en/project/xcompact3d/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/project/xcompact3d/","section":"project","summary":"Xcompact3d is a Fortran-MPI based, finite difference high-performance code for solving the incompressible or low Mach number Navier-Stokes equations.","tags":["CFD","Fortran","HPC","Xcompact3d"],"title":"Xcompact3d","type":"project"}]